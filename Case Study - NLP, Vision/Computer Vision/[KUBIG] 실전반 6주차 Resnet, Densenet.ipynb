{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "이미지처리2주차.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMLe7TWtbXcD",
        "colab_type": "text"
      },
      "source": [
        "## Image 처리 2주차\n",
        "\n",
        "참고자료:   \n",
        "https://datascienceschool.net/view-notebook/958022040c544257aa7ba88643d6c032/  \n",
        "https://datascienceschool.net/view-notebook/4ca30ffdf6c0407ab281284459982a25/    \n",
        "https://towardsdatascience.com/review-densenet-image-classification-b6631a8ef803\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcTaL9Mlam-B",
        "colab_type": "text"
      },
      "source": [
        "## Resnet 개념 정리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KF1B9JCxgoHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bfYb-7lap1K",
        "colab_type": "text"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fcx1l7G%2FbtqzR2RurjQ%2FuRBKXJoxhDZdBjqI2BqWnK%2Fimg.png\" width=\"600\" height=\"300\"></center>\n",
        "<p style=\"font-size:120;\"> \n",
        "위 그림을 보면 모델의 깊이가 깊어지면서 top-5 error가 낮아진 것을 확인할 수 있습니다. 그렇다면 단순히 모델의 깊이만을 늘리면 모델을 개선할 수 있지 않을까요? 안타깝게도, 단순히 네트워크를 깊게 만들면, gradient vanishing/exploding 문제 때문에 학습이 잘 이루어지지 않고, 비용함수 값이 수렴하지 않습니다. 이에 대한 해결책으로 정규화 레이어 추가, 가중치 초기화 방법 등이 소개 되었고 꽤 깊은 모델이라도 학습을 수렴시킬 수 있게 되었습니다. \n",
        "\n",
        "하지만 학습이 수렴했다 하더라도 모델의 깊이가 깊어지다 보면 어느 순간 더 얕은 모델의 성능보다 더 나빠지는 현상이 발생합니다. ResNet의 저자들은 컨볼루션 층들과 fully-connected 층들로 20 층의 네트워크와 56층의 네트워크를 각각 만든 다음에 성능을 테스트해보았습니다.</p>\n",
        " </br>\n",
        "<h2>1. Degradation 문제</h2>\n",
        "\n",
        "<center>\n",
        "<img src=\"https://miro.medium.com/max/875/1*4fv-3pCDh2ibQK33oDVFdA.png\" width=\"600\" height=\"300\"></center>\n",
        "<p style=\"font-size:120;\"> 위 그림에서는 20개의 layer를 가진 모델보다 56개의 layer를 가진 모델이 trainig, test error가 모두 낮게 나타남을 보여줍니다. 이를 Degradation 문제라고 하는데, 단순한 과적합 문제와는 다릅니다. 과적합 문제는 테스트 성능에 대한 문제이지만, Degradation은 훈련용 데이터에 대한 성능의 문제이기 때문입니다. ResNet의 저자들은 이 Degradation 문제를 해결하기 위한 구조로 Skip Connection을 제시합니다. </p>\n",
        "</br>\n",
        "<h2>2. Skip Connection</h2>\n",
        "\n",
        "<center>\n",
        "<img src=\"https://datascienceschool.net/upfiles/6182312059774a81a2a26246bd4e83f2.png\" width=\"600\" height=\"300\"></center>\n",
        "\n",
        "<p style=\"font-size:120;\">기존의 뉴럴넷의 학습 목적이 입력 $(x)$ 을 타겟값 $(y)$ 으로 맵핑하는 함수  $H(x)$ 를 찾는 것이라고 한다면, 뉴럴넷은  $H(x)−y$ 를 최소화 하는 방향으로 학습을 진행합니다. 이 때 $x$ 와 짝지어진  $y$ 는 사실  $x$ 를 대변하는 것으로, 특히 이미지 분류 문제에서는 네트워크의 입출력을 의미상 같게끔 맵핑해야 합니다.  \n",
        "\n",
        "그래서 ResNet에서는 관점을 바꿔 네트워크가  $H(x)−x$를 얻는 것으로 목표를 수정하였습니다. 입력과 출력의 잔차를  $F(x)=H(x)−x$ 라고 정의를 하고 네트워크는 이  $F(x)$ 를 찾는 것입니다. 이  $F(x)$ 는 잔차라고 할 수 있고, 이렇게 잔차를 학습하는 것을 Residual learning, Residual mapping이라고 합니다. 결과적으로 출력  $H(x)=F(x)+x$ 가 됩니다. 이렇게 네트워크의 입력과 출력이 더해진 것을 다음 레이러의 입력으로 사용하는 것을 스킵연결(skip connection) 이라고 합니다.\n",
        "\n",
        "기존의 뉴럴넷은  $H(x)$ 가 어떻게든 정답과 같게 만드는 것이 목적이었다면, 이제 입력과 출력 사이의 잔차를 학습하는 것, 즉 최적의 경우 $F(x)=0$ 이 되어야하므로 학습의 목표가 이미 정해져 있기 때문에 학습 속도가 빨라질 것이고, 네트워크가 잔차를 학습하고 나면, 입력값의 작은 변화에도 민감하게 반응 할 것이다라는 것이 ResNet의 가설입니다.</p>\n",
        "</br>\n",
        "\n",
        "<h2>3. ResNet의 구조</h2>\n",
        "<p style=\"font-size:120;\">ResNet의 구조는 크게 Residual Block과 Identity Block으로 이루어져있습니다. 아래 그림과 표는 Residual Block과 Identity Block 그리고 ResNet50의 구조를 간략히 표현한 것입니다. 이때 ResNet50이란 컨볼루션(convolution) 연산과 fully connected layer만 계산했을 때, 총 레이어 갯수가 50개가 되는 ResNet 모델을 뜻합니다.</p>\n",
        "\n",
        "<h2>Identity Block/Residual Block</h2>\n",
        "<center>\n",
        "<img src=\"https://miro.medium.com/max/700/1*BCbJZXwGDtEdytj9ag_YWw.png\"  width=\"600\" height=\"300\"></center>\n",
        "<center>\n",
        "<img src=\"https://miro.medium.com/max/700/1*sb_4xKI_bRoX6jmZcNTRWw.png\n",
        "\"  width=\"600\" height=\"300\"></center>\n",
        "<p style=\"font-size:120;\">위에서 shortcut에 Conv2D와 BatchNorm이 없는 첫번째 그림은 Identity Block, Conv2D와 BatchNorm이 있는 두번째 그림은 Residual Block을 나타냅니다.입력 차원과 출력 차원이 일치하는 Identity Block과 달리 Residual Block은 입력 차원과 출력 차원이 일치하지 않을때 shortcut에 Convolution연산을 도입해 $x$와 $F(x)$의 연산을 가능하게 합니다.  \n",
        "(p.s 데이터사이언스스쿨 문서에는 Residual Block과 Identity Block에 대한 개념을 반대로 설명하는데, 다른 여러 해외 문서들에서는 위와 같이 설명하고 있습니다...참고로 코드는 모두 Identity Block기준으로 작성했습니다.)</p>\n",
        "<center>\n",
        "<img src=\"https://miro.medium.com/max/875/1*BNIFHIv439r83XP5Aw3-yA.png\n",
        "\"  width=\"600\" height=\"300\"></center>\n",
        "<p style=\"font-size:120;\">ResNet50 부터는 연산량의 줄이기 위해 Residual Block 내에, 1x1, 3x3, 1x1 컨볼루션 연산을 쌓았습니다. 1x1 컨볼루션 연산으로 피쳐맵의 갯수를 줄였다가 3x3을 거친 후, 1x1 컨볼루션 연산으로 차원을 늘려줍니다. 이 과정이 병목 같다 하여 병목레이어(bottleneck layer)라고 부릅니다.</p>\n",
        "\n",
        "<h2>ResNet50</h2>\n",
        "\n",
        "|  유형  |입력 크기 | 출력 크기 | 커널 크기 | 횟수 |\n",
        "|:--|:------:|:-------:|:------------:|:-------:|\n",
        "|**입력**|(224,224,3)| |||\n",
        "|**Conv**|(224,224,3)|(112,112,64)|(7,7)||\n",
        "|**maxpool**|(112,112,64)|(55,55,64)|(3,3)||\n",
        "|**Identity Block**|(55,55,64)|(55,55,256)|$\\begin{bmatrix} 1\\times1,64 \\\\ 3\\times3,64 \\\\ 1\\times1,256 \\end{bmatrix}\\;\\;$ |$\\times 3$|\n",
        "|**Residual Block**|(55,55,256)|(28,28,512)|$\\begin{bmatrix} 1\\times1,128 \\\\ 3\\times3,128 \\\\ 1\\times1,512 \\end{bmatrix}\\;\\;$||\n",
        "|**Identity Block**|(28,28,512)|(28,28,512)|$\\begin{bmatrix} 1\\times1,128 \\\\ 3\\times3,128 \\\\ 1\\times1,512  \\end{bmatrix}\\;\\;$|$\\times 3$|\n",
        "|**Residual Block**|(28,28,512)|(14,14,1024)|$\\begin{bmatrix} 1\\times1,256 \\\\ 3\\times3,256 \\\\ 1\\times1,1024 \\end{bmatrix}\\;\\;$|\n",
        "|**Identity Block**|(14,14,1024)|(14,14,1024)|$\\begin{bmatrix} 1\\times1,256 \\\\ 3\\times3,256 \\\\ 1\\times1,1024 \\end{bmatrix}\\;\\;$|$\\times 5$|\n",
        "|**Residual Block**|(14,14,1024)|(7,7,2048)|$\\begin{bmatrix} 1\\times1,512 \\\\ 3\\times3,512 \\\\ 1\\times1,2048 \\end{bmatrix}\\;\\;$|\n",
        "|**Identity Block**|(7,7,2048)|(7,7,2048)|$\\begin{bmatrix} 1\\times1,512 \\\\ 3\\times3,512 \\\\ 1\\times1,2048 \\end{bmatrix}\\;\\;$|$\\times 2$|\n",
        "|**Average pool**|(7,7,2048)|(1,1,2048)|(7,7)|1|\n",
        "|**FCN**|(1,1,2048|(1,1,1000)|||\n",
        "|**softmax**|(1,1,1000)|(1,1,1000)|||\n",
        "\n",
        "\n",
        "<p style=\"font-size:120;\">ResNet에서는  첫번째 레이어(7x7 컨볼루션)를 제외하고는 모든 컨볼루션 연산에 3x3 이하 크기의 커널이 사용되었고, 피쳐맵의 크기가 같은 레이어는 출력 피쳐맵 갯수가 동일합니다. 그리고 피쳐맵의 크기가 반으로 작아지는 경우 출력 피쳐맵의 갯수가 2배가 됩니다. Pooling은 거의 사용되지 않고 컨볼루션 연산의 스트라이드(stride)를 2로 하여 피쳐맵의 크기를 줄였습니다. 이미지가 반으로 작아진 경우, Convolution Block이 사용되며, 입력값을 바로 더하지 않고, 1x1 컨볼루션 연산을 스트라이드 2로 설정하여 피쳐맵의 크기와 갯수를 맞추어준 다음 더해줍니다. 이를 프로젝션 숏컷(projection shortcut)이라고도 합니다.<p>\n",
        "</br> \n",
        "<h2>4. Pre-Activation Residual Unit</h2>\n",
        "<p style=\"font-size:120;\">ResNet 저자들은 후속 논문에서 더 개선된 skip connection 방법을 제시합니다. 기존의 skip connection은 출력과 입력이 더해진 후 활성화 함수(ReLu)를 통과했습니다. 활성화 함수를  $f(\\cdot)$ 이라고 하고, 수식으로 표현하면 $H(x) = f(F(x) + x)$ 가 됩니다. 뒤에 따라오는 비선형 활성화 함수 때문에 다음 레이어의 입력 값에 이전 레이어의 입력이 그대로 반영되지는 않습니다. 하나의 Residual Block만 생각하면 큰 차이가 없겠지만, 이를 여러 개를 연결 하면 차이가 발생할 수도 있습니다. 그래서,  $F(x)$  안에 활성화함수를 반영한 다음  $F(x)$ 와 입력값을 더해줍니다. 수식으로 표현하면, $ H(x)=F(x)+x$ 입니다. 이를 그림으로 나타내면 다음과 같습니다.</p>\n",
        "\n",
        "<center>\n",
        "<img src=\"https://datascienceschool.net/upfiles/226eda2a7b564542bd06d57b5510baa1.png\" width=\"600\" height=\"300\"></center>\n",
        "<p style=\"font-size:120;\">\n",
        "이렇게 바꾸면,  $l+1$ 번째의 레이어의 입력값  $x_{l+1}=x_{l}+F(x_{l})$  로 나타낼 수 있어 수식이 기존보다 더 간단해집니다. 이를 더 연결해 보면, 다음과 같습니다.\n",
        "\n",
        "$x_{l+1} = x_l + F(x_l) = x_{l-1} + F(x_{l-1}) + F(x_l) \\cdots = x_0 + \\displaystyle\\sum_{i=0}^{l-1}F(x_i)$\n",
        "\n",
        "각 레이어간의 관계가 더하기로 표현되기 때문에 수학적으로 좀 더 유용합니다. 그리고 실제로 논문에서의 실험결과를 확인하면 개선된 구조를 사용했을 때, 더 나은 결과를 가져옵니다.</p>\n",
        "</br>\n",
        "\n",
        "<center>\n",
        "<img src=\"https://miro.medium.com/max/875/1*V2FgD6udOE4xJuu_R7L6qA.png\" width=\"600\" height=\"300\"></center>\n",
        "</br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ADloCIwaBj0",
        "colab_type": "text"
      },
      "source": [
        "## Residual Network 구현 및 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp3AmmyhaC_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pxiAwM4aGo4",
        "colab_type": "text"
      },
      "source": [
        "## 하이퍼 파라미터"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6_DX0oyaEss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7nf_mcfaJTF",
        "colab_type": "text"
      },
      "source": [
        "## Residual Unit 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3f_9GjqaIED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResidualUnit(tf.keras.Model):\n",
        "    def __init__(self, filter_in, filter_out, kernel_size):\n",
        "      # batch normalization -> ReLu -> Conv Layer\n",
        "      # 여기서 ReLu 같은 경우는 변수가 없는 Layer이므로 여기서 굳이 initialize 해주지 않는다. (call쪽에서 사용하면 되므로)\n",
        "      super(ResidualUnit, self).__init__()\n",
        "      self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "      self.conv1 =  tf.keras.layers.Conv2D(filter_out, kernel_size, padding='same')\n",
        "\n",
        "      self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "      self.conv2 = tf.keras.layers.Conv2D(filter_out, kernel_size, padding='same')\n",
        "\n",
        "      if filter_in == filter_out:   #input filter랑 output filter 같으면\n",
        "        self.identity = lambda x: x #입력을 그대로 출력\n",
        "      else:\n",
        "        self.identity = tf.keras.layers.Conv2D(filter_out, (1,1), padding='same') #1by1 convolution으로 filter개수 맞춰주기.\n",
        "\n",
        "    # 아래에서 batch normalization은 train할때와 inference할 때 사용하는 것이 달라지므로 옵션을 줄 것이다.\n",
        "    def call(self, x, training=False, mask=None):\n",
        "      h = self.bn1(x, training=training))\n",
        "      h = tf.nn.relu(h)\n",
        "      h = self.conv1(h)\n",
        "\n",
        "      h = self.bn2(x, training=training)\n",
        "      h = tf.nn.relu(h)\n",
        "      h = self.conv2(h)\n",
        "      return self.identity(x) + h\n",
        "      \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pe-PkmBiaNXw",
        "colab_type": "text"
      },
      "source": [
        "## Residual Layer 구현\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zp8Mde8TaMHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResnetLayer(tf.keras.Model):\n",
        "   # 아래 arg 중 filter_in : 처음 입력되는 filter 개수를 의미\n",
        "   # Resnet Layer는 Residual unit이 여러개가 있게끔해주는것이므로\n",
        "   # filters : [32, 32, 32, 32]는 32에서 32로 Residual unit이 연결되는 형태\n",
        "    def __init__(self, filter_in, filters, kernel_size):\n",
        "        super(ResnetLayer, self).__init__()\n",
        "        self.sequence = list()\n",
        "        for f_in, f_out in zip([filter_in]+list(filters), filters):\n",
        "          self.sequence.append(ResidualUnit(f_in,f_out,kernel_size))\n",
        "          # [16] + [32,32,32]\n",
        "          # zip([16,32,32,32],[32,32,32])=> (16,32), (32,32), (32,32). (작은 거 기준)\n",
        "\n",
        "    def call(self, x, training=False, mask=None):\n",
        "        for unit in self.sequence:\n",
        "          # 위의 batch normalization에서 training이 쓰였기에 여기서 넘겨 주어야 한다.\n",
        "          x = unit(x, training=training)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrH89irMaSDo",
        "colab_type": "text"
      },
      "source": [
        "## 모델 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh-EuePSaRUD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNet(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "      super(ResNet, self).__init__()\n",
        "      self.conv1 = tf.keras.layers.Conv2D(8,(3,3),padding='same',activation='relu') #28*28*8\n",
        "\n",
        "      self.res1 = ResnetLayer(8,(16,16),(3,3)) #28*28*16\n",
        "      self.pool1 = tf.keras.layers.MaxPool2D((2,2)) #14*14*16\n",
        "\n",
        "      self.res2 = ResnetLayer(16,(32,32),(3,3)) #14*14*32\n",
        "      self.pool2 = tf.keras.layers.MaxPool2D((2,2)) #7*7*32\n",
        "\n",
        "      self.res3 = ResnetLayer(32,(64,64),(3,3)) #7*7*64\n",
        "      self.flatten = tf.keras.layers.Flatten()\n",
        "      self.dense1 = tf.keras.layers.Dense(128, activation='relu')\n",
        "      self.dense2 = tf.keras.layers.Dense(10, activation='softmax') #class가 10개\n",
        "\n",
        "    def call(self, x, training=False, mask=None):\n",
        "      x = self.conv1(x)\n",
        "\n",
        "      x = self.res1(x, training=training) #resnet은 training을 입력으로 받음\n",
        "      x = self.pool1(x)\n",
        "      x = self.res2(x, training=training) #resnet은 training을 입력으로 받음\n",
        "      x = self.pool2(x)\n",
        "      x = self.res3(x, training=training) #resnet은 training을 입력으로 받음\n",
        "\n",
        "      x = self.flatten(x)\n",
        "      x = self.dense1(x)\n",
        "      return self.dense2(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ta3E7ACZaVaJ",
        "colab_type": "text"
      },
      "source": [
        "## 학습, 테스트 루프 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MD4NZwsaU0b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Implement training loop\n",
        "@tf.function\n",
        "def train_step(model, images, labels, loss_object, optimizer, train_loss, train_accuracy):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(images,training=True) #학습할 땐 training True\n",
        "        loss = loss_object(labels, predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    train_loss(loss)\n",
        "    train_accuracy(labels, predictions)\n",
        "\n",
        "# Implement algorithm test\n",
        "@tf.function\n",
        "def test_step(model, images, labels, loss_object, test_loss, test_accuracy):\n",
        "    predictions = model(images, training=False) #테스트할 땐 training False\n",
        "\n",
        "    t_loss = loss_object(labels, predictions)\n",
        "    test_loss(t_loss)\n",
        "    test_accuracy(labels, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SP1xWxr4aZGX",
        "colab_type": "text"
      },
      "source": [
        "## 데이터셋 준비\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cn--KAi8aa-J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "0370d825-af4a-4bc5-f2ac-5bbd8a3c5c20"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "x_train = x_train[..., tf.newaxis].astype(np.float32)\n",
        "x_test = x_test[..., tf.newaxis].astype(np.float32)\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opmrj5u2acHC",
        "colab_type": "text"
      },
      "source": [
        "## 학습 환경 정의\n",
        "### 모델 생성, 손실함수, 최적화 알고리즘, 평가지표 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBeuYNyvaYH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create model\n",
        "model = ResNet()\n",
        "\n",
        "# Define loss and optimizer\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "# Define performance metrics\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LGrtttmagTX",
        "colab_type": "text"
      },
      "source": [
        "## 학습 루프 동작"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Das4ELi8af6J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "ebb6c187-d072-4ba8-fe55-31badf35f3b9"
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    for images, labels in train_ds:\n",
        "        train_step(model, images, labels, loss_object, optimizer, train_loss, train_accuracy)\n",
        "\n",
        "    for test_images, test_labels in test_ds:\n",
        "        test_step(model, test_images, test_labels, loss_object, test_loss, test_accuracy)\n",
        "\n",
        "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
        "    print(template.format(epoch + 1,\n",
        "                          train_loss.result(),\n",
        "                          train_accuracy.result() * 100,\n",
        "                          test_loss.result(),\n",
        "                          test_accuracy.result() * 100))\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    test_loss.reset_states()\n",
        "    test_accuracy.reset_states()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['res_net/resnet_layer/residual_unit/batch_normalization/gamma:0', 'res_net/resnet_layer/residual_unit/batch_normalization/beta:0', 'res_net/resnet_layer/residual_unit/conv2d_1/kernel:0', 'res_net/resnet_layer/residual_unit/conv2d_1/bias:0', 'res_net/resnet_layer/residual_unit_1/batch_normalization_2/gamma:0', 'res_net/resnet_layer/residual_unit_1/batch_normalization_2/beta:0', 'res_net/resnet_layer/residual_unit_1/conv2d_4/kernel:0', 'res_net/resnet_layer/residual_unit_1/conv2d_4/bias:0', 'res_net/resnet_layer_1/residual_unit_2/batch_normalization_4/gamma:0', 'res_net/resnet_layer_1/residual_unit_2/batch_normalization_4/beta:0', 'res_net/resnet_layer_1/residual_unit_2/conv2d_6/kernel:0', 'res_net/resnet_layer_1/residual_unit_2/conv2d_6/bias:0', 'res_net/resnet_layer_1/residual_unit_3/batch_normalization_6/gamma:0', 'res_net/resnet_layer_1/residual_unit_3/batch_normalization_6/beta:0', 'res_net/resnet_layer_1/residual_unit_3/conv2d_9/kernel:0', 'res_net/resnet_layer_1/residual_unit_3/conv2d_9/bias:0', 'res_net/resnet_layer_2/residual_unit_4/batch_normalization_8/gamma:0', 'res_net/resnet_layer_2/residual_unit_4/batch_normalization_8/beta:0', 'res_net/resnet_layer_2/residual_unit_4/conv2d_11/kernel:0', 'res_net/resnet_layer_2/residual_unit_4/conv2d_11/bias:0', 'res_net/resnet_layer_2/residual_unit_5/batch_normalization_10/gamma:0', 'res_net/resnet_layer_2/residual_unit_5/batch_normalization_10/beta:0', 'res_net/resnet_layer_2/residual_unit_5/conv2d_14/kernel:0', 'res_net/resnet_layer_2/residual_unit_5/conv2d_14/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['res_net/resnet_layer/residual_unit/batch_normalization/gamma:0', 'res_net/resnet_layer/residual_unit/batch_normalization/beta:0', 'res_net/resnet_layer/residual_unit/conv2d_1/kernel:0', 'res_net/resnet_layer/residual_unit/conv2d_1/bias:0', 'res_net/resnet_layer/residual_unit_1/batch_normalization_2/gamma:0', 'res_net/resnet_layer/residual_unit_1/batch_normalization_2/beta:0', 'res_net/resnet_layer/residual_unit_1/conv2d_4/kernel:0', 'res_net/resnet_layer/residual_unit_1/conv2d_4/bias:0', 'res_net/resnet_layer_1/residual_unit_2/batch_normalization_4/gamma:0', 'res_net/resnet_layer_1/residual_unit_2/batch_normalization_4/beta:0', 'res_net/resnet_layer_1/residual_unit_2/conv2d_6/kernel:0', 'res_net/resnet_layer_1/residual_unit_2/conv2d_6/bias:0', 'res_net/resnet_layer_1/residual_unit_3/batch_normalization_6/gamma:0', 'res_net/resnet_layer_1/residual_unit_3/batch_normalization_6/beta:0', 'res_net/resnet_layer_1/residual_unit_3/conv2d_9/kernel:0', 'res_net/resnet_layer_1/residual_unit_3/conv2d_9/bias:0', 'res_net/resnet_layer_2/residual_unit_4/batch_normalization_8/gamma:0', 'res_net/resnet_layer_2/residual_unit_4/batch_normalization_8/beta:0', 'res_net/resnet_layer_2/residual_unit_4/conv2d_11/kernel:0', 'res_net/resnet_layer_2/residual_unit_4/conv2d_11/bias:0', 'res_net/resnet_layer_2/residual_unit_5/batch_normalization_10/gamma:0', 'res_net/resnet_layer_2/residual_unit_5/batch_normalization_10/beta:0', 'res_net/resnet_layer_2/residual_unit_5/conv2d_14/kernel:0', 'res_net/resnet_layer_2/residual_unit_5/conv2d_14/bias:0'] when minimizing the loss.\n",
            "Epoch 1, Loss: 0.13868044316768646, Accuracy: 96.15666961669922, Test Loss: 0.07927223294973373, Test Accuracy: 97.95999908447266\n",
            "Epoch 2, Loss: 0.066693514585495, Accuracy: 98.07666778564453, Test Loss: 0.09668514132499695, Test Accuracy: 97.38999938964844\n",
            "Epoch 3, Loss: 0.05248168483376503, Accuracy: 98.49333190917969, Test Loss: 0.07847493141889572, Test Accuracy: 98.08999633789062\n",
            "Epoch 4, Loss: 0.04680394008755684, Accuracy: 98.75666809082031, Test Loss: 0.04939711093902588, Test Accuracy: 98.68999481201172\n",
            "Epoch 5, Loss: 0.04047749936580658, Accuracy: 98.91500091552734, Test Loss: 0.06690230220556259, Test Accuracy: 98.38999938964844\n",
            "Epoch 6, Loss: 0.036375053226947784, Accuracy: 99.02999877929688, Test Loss: 0.05868223309516907, Test Accuracy: 98.75\n",
            "Epoch 7, Loss: 0.033353984355926514, Accuracy: 99.14500427246094, Test Loss: 0.08613891154527664, Test Accuracy: 97.81999969482422\n",
            "Epoch 8, Loss: 0.02743501029908657, Accuracy: 99.27166748046875, Test Loss: 0.0446171909570694, Test Accuracy: 98.95999908447266\n",
            "Epoch 9, Loss: 0.030793549492955208, Accuracy: 99.1883316040039, Test Loss: 0.056620705872774124, Test Accuracy: 98.75\n",
            "Epoch 10, Loss: 0.023138824850320816, Accuracy: 99.36333465576172, Test Loss: 0.058628324419260025, Test Accuracy: 98.69999694824219\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-VL_NRJKp7G",
        "colab_type": "text"
      },
      "source": [
        "## DenseNet 개념정리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsVj_CJDKwcI",
        "colab_type": "text"
      },
      "source": [
        "<p style=\"font-size:120;\">DenseNet은 2016년에 논문을 통해 발표된 CNN 모델입니다. DenseNet은 ResNet의 skip connection과 다른 Dense connectivity를 제안합니다. 이 모델의 장점으로는 이미지에서 저수준의 특징들이 잘 보존되고, gradient가 수월하게 흘러 gradient vanishing 문제가 발생하지 않으며, 깊이에 비해 파라미터 수가 적기에 연산량이 절약됨과 동시에 적은 데이터셋에서도 비교적 잘 학습이 된다는 점이 있습니다.</p>\n",
        "\n",
        "<h2>1. ResNet과의 비교\n",
        "<center>\n",
        "<img src=\"https://miro.medium.com/max/875/1*4wx7szWCBse9-7eemGQJSw.png\n",
        "\" width=\"600\" height=\"300\"></center>\n",
        "<p style=\"font-size:120;\">앞서 보았듯이 ResNet에서는 Skip connection을 수행하는 Residual Block과 Identity Block이 있었습니다.</p>\n",
        "\n",
        "<center>\n",
        "<img src=\"https://miro.medium.com/max/875/1*rmHdoPjGUjRek6ozH7altw.png\" width=\"600\" height=\"300\"></center>\n",
        "<center>\n",
        "<img src=\"https://miro.medium.com/max/750/1*9ysRPSExk0KvXR0AhNnlAA.gif\n",
        "\" width=\"600\" height=\"300\"></center>\n",
        "\n",
        "<p style=\"font-size:120;\">반면 DenseNet의 핵심은 Dense connectivity 입니다. Dense connectivity 란, 입력값을 계속해서 출력값의 채널 방향으로 합쳐주는 것(Concatenate)인데, 이를  ResNet과 수식으로 비교하면, 다음과 같습니다.\n",
        "<center> \n",
        "${ x }_{ l }={ H }_{ l }({ x }_{ l-1 })+{ x }_{ l-1 }\\quad \\quad { x }_{ l }={ H }_{ l }([{ x }_{ 0 },{ x }_{ 1 },...,{ x }_{ l-1 }])$</center>\n",
        "\n",
        "ResNet의 경우에는 입력이 출력에 더해지는 것이기 때문에 끝에 가서는 최초의 정보가 흐려질 수 밖에 없습니다. 그에 반해 DenseNet의 경우에는 채널 방향으로 그대로 합쳐지는 것이기 때문에 최초의 정보가 비교적 온전히 남아있게 됩니다. </p>\n",
        "\n",
        "</br>\n",
        "\n",
        "<h2>2. DenseNet 구조</h2>\n",
        "<h2>Composition layer</h2>\n",
        "<center>\n",
        "<img src=\"https://miro.medium.com/max/750/1*IwvJGTxBAcb1H5tSJR6Lng.gif\" width=\"600\" height=\"300\"></center>\n",
        "\n",
        "<p style=\"font-size:120;\"> 위 그림은 각각의 composition layer에 대해, Pre-Activation Batch Norm(BN)과 ReLU, 그리고 3×3 Convolution이 $x_0$, $x_1$, $x_2$, $x_3$로 k개의 channel을 가진 $x_4$를 만드는 것을 보여줍니다. 이때  $k$는 growth rate 이라고 하며 실험 결과 k값이 낮아도 state-of-the-art의 결과를 보여준다고 합니다.ResNet과 동일한 Pre-Activation(BatchNorm-ReLu-Conv)구조를 사용하는 것을 볼 수 있습니다. 또한 $H_{l}$은 Batch Norm, ReLu, 그리고 Convolution 연산을 합친 합성 함수(composite function)입니다. </p> \n",
        "\n",
        "\n",
        "<h2>DenseNet-B (Bottleneck Layers)</h2>\n",
        "<center>\n",
        "<img src=\"https://miro.medium.com/max/875/1*dniz8zK2ClBY96ol7YGnJw.png\n",
        "\" width=\"600\" height=\"300\"></center>\n",
        "<p style=\"font-size:120;\"> 그림에서 $l$은 레이어의 개수, $k$는 growth rate을 의미합니다. $l×k$ 크기의 채널을 가진 입력이 BN-ReLU-1×1 Conv을 거쳐 $4×k$크기의 채널을 가지며, BN-ReLU-3×3 Conv 이후 $k$ 크기의 채널을 가지게 됩니다. 역시 ResNet에서 썼던 BottleNeck구조를 동일하게 사용하는 것을 볼 수 있습니다.</p>\n",
        "\n",
        "<h2>Multiple Dense Blocks with Transition Layers</h2>\n",
        "<center>\n",
        "<img src=\"https://miro.medium.com/max/875/1*BJM5Ht9D5HcP5CFpu8bn7g.png\" width=\"600\" height=\"300\"></center>\n",
        "<p style=\"font-size:120;\"> Transition layer는 연속된 Dense Block 사이에 있는 1×1 Convolution과 그 뒤에 이어지는 2×2 average pooling으로니다. 모델을 더 컴팩트하게 만들기 위해서, transition layer에서는 feature map의 수를 줄여주는 작업을 하게 됩니다. 만약 dense block1에서 100x100 size의 feature map을 가지고 있었다면 dense block2에서는 50x50 size의 feature map이 될 것입니다.</p>\n",
        "\n",
        "<h2>DenseNet-121</h2>\n",
        "\n",
        "|  유형  |입력 크기 | 출력 크기 | 커널 크기 | 횟수 |\n",
        "|:--|:------:|:-------:|------------|:-------:|\n",
        "|**입력**|(224,224,3)| |||\n",
        "|**Conv**|(224,224,3)|(112,112,64)|(7,7)||\n",
        "|**maxpool**|(112,112,64)|(56,56,64)|(3,3)||\n",
        "|**Dense Block**|(56,56,64)|(56,56,256)|$\\begin{bmatrix} 1\\times1,128 \\\\ 3\\times3,32 \\end{bmatrix}\\;\\;$ |$\\times 6$|\n",
        "|**Conv**|(56,56,256)|(56,56,128)|(1,1)||\n",
        "|**Average pool**|(56,56,128)|(28,28,128)|(2,2)||\n",
        "|**Dense Block**|(28,28,128)|(28,28,512)|$\\begin{bmatrix} 1\\times1,128 \\\\ 3\\times3,32 \\end{bmatrix}\\;\\;$ |$\\times 12$|\n",
        "|**Conv**|(28,28,512)|(28,28,256)|(1,1)||\n",
        "|**Average pool**|(28,28,256)|(14,14,256)|(2,2)||\n",
        "|**Dense Block**|(14,14,256)|(14,14,1024)|$\\begin{bmatrix} 1\\times1,128 \\\\ 3\\times3,32 \\end{bmatrix}\\;\\;$ |$\\times 24$|\n",
        "|**Conv**|(14,14,1024)|(14,14,512)|$1\\times1,512$||\n",
        "|**Average pool**|(14,14,512)|(7,7,512)|(2,2)||\n",
        "|**Dense Block**|(7,7,512)|(7,7,1024)|$\\begin{bmatrix} 1\\times1,128 \\\\ 3\\times3,32 \\end{bmatrix}\\;\\;$ |$\\times 16$|\n",
        "|**Average pool**|(7,7,1024)|(1,1,1024)|(7,7)|1|\n",
        "|**FCN**|(1,1,2048|(1,1,1000)|||\n",
        "|**softmax**|(1,1,1000)|(1,1,1000)|||\n",
        "\n",
        "\n",
        "<p style=\"font-size:120;\">위의 표는 DenseNet의 구조를 표현한 것입니다. 첫번째 convolution과 maxpooling 연산은 ResNet과 똑같습니다.\n",
        "이후 Dense Block(growth rate=32)과 Transition layer(Conv+Pooling)가 반복되고, 마지막의 fully connected layer와 softmax로 예측을 수행합니다.</p>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSMoI1fRgSvu",
        "colab_type": "text"
      },
      "source": [
        "## Dense Unit 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf991joEgUNU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DenseUnit(tf.keras.Model):\n",
        "    def __init__(self, filter_out, kernel_size):\n",
        "        super(DenseUnit, self).__init__()\n",
        "        # batch normalization -> ReLu -> Conv Layer\n",
        "        # 여기서 ReLu 같은 경우는 변수가 없는 Layer이므로 여기서 굳이 initialize 해주지 않는다. (call쪽에서 사용하면 되므로)\n",
        "        # Pre-activation 구조는 똑같이 가져가되, concatenate 구조로 만들어주어야함에 주의하자!!\n",
        "        self.bn = tf.keras.layers.BatchNormalization()\n",
        "        self.conv = tf.keras.layers.Conv2D(filter_out, kernel_size, padding='same')\n",
        "        self.concat = tf.keras.layers.Concatenate()\n",
        "\n",
        "    def call(self, x, training=False, mask=None): # x: (Batch, H, W, Ch_in)\n",
        "        h = self.bn(x, training=training)\n",
        "        h = tf.nn.relu(h)\n",
        "        h = self.conv(h) # h: (Batch, H, W, filter_output)\n",
        "        return self.concat([x, h]) # (Batch, H, W, (Ch_in + filter_output))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5BUz7uwgagu",
        "colab_type": "text"
      },
      "source": [
        "## Dense Layer 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMtCcFokgbvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DenseLayer(tf.keras.Model):\n",
        "    def __init__(self, num_unit, growth_rate, kernel_size):\n",
        "        super(DenseLayer, self).__init__()\n",
        "        self.sequence = list()\n",
        "        for idx in range(num_unit):\n",
        "            self.sequence.append(DenseUnit(growth_rate, kernel_size))\n",
        "\n",
        "    def call(self, x, training=False, mask=None):\n",
        "        for unit in self.sequence:\n",
        "            x = unit(x, training=training)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAr9GxsYgdYL",
        "colab_type": "text"
      },
      "source": [
        "## Transition Layer 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08ey0OdOgegs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TransitionLayer(tf.keras.Model):\n",
        "    def __init__(self, filters, kernel_size):\n",
        "        super(TransitionLayer, self).__init__()\n",
        "        self.conv = tf.keras.layers.Conv2D(filters, kernel_size, padding='same')\n",
        "        self.pool = tf.keras.layers.MaxPool2D()\n",
        "\n",
        "    def call(self, x, training=False, mask=None):\n",
        "        x = self.conv(x)\n",
        "        return self.pool(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luqJBBufggGM",
        "colab_type": "text"
      },
      "source": [
        "## 모델 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIXqgIuvgfW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DenseNet(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(DenseNet, self).__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv2D(8, (3, 3), padding='same', activation='relu') # 28x28x8\n",
        "        \n",
        "        self.dl1 = DenseLayer(2, 4, (3, 3)) # 28x28x16\n",
        "        self.tr1 = TransitionLayer(16, (3, 3)) # 14x14x16\n",
        "        \n",
        "        self.dl2 = DenseLayer(2, 8, (3, 3)) # 14x14x32\n",
        "        self.tr2 = TransitionLayer(32, (3, 3)) # 7x7x32\n",
        "        \n",
        "        self.dl3 = DenseLayer(2, 16, (3, 3)) # 7x7x64\n",
        "        \n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        self.dense1 = tf.keras.layers.Dense(128, activation='relu')\n",
        "        self.dense2 = tf.keras.layers.Dense(10, activation='softmax')       \n",
        "\n",
        "    def call(self, x, training=False, mask=None):\n",
        "        x = self.conv1(x)\n",
        "        \n",
        "        x = self.dl1(x, training=training)\n",
        "        x = self.tr1(x)\n",
        "        \n",
        "        x = self.dl2(x, training=training)\n",
        "        x = self.tr2(x)\n",
        "        \n",
        "        x = self.dl3(x, training=training)\n",
        "        \n",
        "        x = self.flatten(x)\n",
        "        x = self.dense1(x)\n",
        "        return self.dense2(x)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9eBnTOlgi3g",
        "colab_type": "text"
      },
      "source": [
        "## 학습, 테스트 루프 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyIbLMdDgj1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Implement training loop\n",
        "@tf.function\n",
        "def train_step(model, images, labels, loss_object, optimizer, train_loss, train_accuracy):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(images,training=True)\n",
        "        loss = loss_object(labels, predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    train_loss(loss)\n",
        "    train_accuracy(labels, predictions)\n",
        "\n",
        "# Implement algorithm test\n",
        "@tf.function\n",
        "def test_step(model, images, labels, loss_object, test_loss, test_accuracy):\n",
        "    predictions = model(images, training=False)\n",
        "\n",
        "    t_loss = loss_object(labels, predictions)\n",
        "    test_loss(t_loss)\n",
        "    test_accuracy(labels, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbS0fi2qgmdY",
        "colab_type": "text"
      },
      "source": [
        "## 데이터셋 준비\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwmvLUDPgly4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "x_train = x_train[..., tf.newaxis].astype(np.float32)\n",
        "x_test = x_test[..., tf.newaxis].astype(np.float32)\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PtT8UKtgplh",
        "colab_type": "text"
      },
      "source": [
        "## 학습 환경 정의\n",
        "### 모델 생성, 손실함수, 최적화 알고리즘, 평가지표 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vL9YW6-rgrMf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create model\n",
        "model = DenseNet()\n",
        "\n",
        "# Define loss and optimizer\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "# Define performance metrics\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4GXEkJVgvyn",
        "colab_type": "text"
      },
      "source": [
        "## 학습 루프 동작"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkPsqQUTgu9T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "2cf2df2d-1a39-43fd-fb6a-eb3b5830d056"
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    for images, labels in train_ds:\n",
        "        train_step(model, images, labels, loss_object, optimizer, train_loss, train_accuracy)\n",
        "\n",
        "    for test_images, test_labels in test_ds:\n",
        "        test_step(model, test_images, test_labels, loss_object, test_loss, test_accuracy)\n",
        "\n",
        "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
        "    print(template.format(epoch + 1,\n",
        "                          train_loss.result(),\n",
        "                          train_accuracy.result() * 100,\n",
        "                          test_loss.result(),\n",
        "                          test_accuracy.result() * 100))\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    test_loss.reset_states()\n",
        "    test_accuracy.reset_states()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.11465068906545639, Accuracy: 96.66666412353516, Test Loss: 0.03689467906951904, Test Accuracy: 98.70999908447266\n",
            "Epoch 2, Loss: 0.05480949580669403, Accuracy: 98.42832946777344, Test Loss: 0.0726410448551178, Test Accuracy: 97.95999908447266\n",
            "Epoch 3, Loss: 0.0493825301527977, Accuracy: 98.59832763671875, Test Loss: 0.05287158116698265, Test Accuracy: 98.6500015258789\n",
            "Epoch 4, Loss: 0.03792129084467888, Accuracy: 98.94000244140625, Test Loss: 0.09247693419456482, Test Accuracy: 97.97999572753906\n",
            "Epoch 5, Loss: 0.037888746708631516, Accuracy: 98.94999694824219, Test Loss: 0.0461721308529377, Test Accuracy: 98.79999542236328\n",
            "Epoch 6, Loss: 0.03137879818677902, Accuracy: 99.14666748046875, Test Loss: 0.06637994945049286, Test Accuracy: 98.43999481201172\n",
            "Epoch 7, Loss: 0.030293770134449005, Accuracy: 99.20333862304688, Test Loss: 0.0476214662194252, Test Accuracy: 98.98999786376953\n",
            "Epoch 8, Loss: 0.025852404534816742, Accuracy: 99.36333465576172, Test Loss: 0.062121786177158356, Test Accuracy: 98.77999877929688\n",
            "Epoch 9, Loss: 0.0252300463616848, Accuracy: 99.36500549316406, Test Loss: 0.07558677345514297, Test Accuracy: 98.5199966430664\n",
            "Epoch 10, Loss: 0.025022104382514954, Accuracy: 99.43500518798828, Test Loss: 0.05742451548576355, Test Accuracy: 98.88999938964844\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}