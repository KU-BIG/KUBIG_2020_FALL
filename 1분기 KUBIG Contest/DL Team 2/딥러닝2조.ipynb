{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":5,"outputs":[{"output_type":"stream","text":"/kaggle/input/train-data/Train_data.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/train-data/Train_data.csv\")","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.replace(\"na\",np.NaN)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.iloc[:,2:] = data.iloc[:,2:].astype(\"float32\")","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"데이터의 형태 파악"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"         Unnamed: 0        aa_000        ab_000        ac_000        ad_000  \\\ncount  57000.000000  5.700000e+04  13012.000000  5.376300e+04  4.282200e+04   \nmean   38084.150860  6.130698e+04      0.720719  3.566436e+08  2.009135e+05   \nstd    21920.895362  2.332295e+05      2.987399  7.952168e+08  4.148309e+07   \nmin        1.000000  0.000000e+00      0.000000  0.000000e+00  0.000000e+00   \n25%    19100.750000  8.620000e+02      0.000000  1.600000e+01  2.400000e+01   \n50%    38110.500000  3.084200e+04      0.000000  1.540000e+02  1.260000e+02   \n75%    57059.500000  4.895400e+04      0.000000  9.710000e+02  4.320000e+02   \nmax    75998.000000  4.294967e+07    134.000000  2.130707e+09  8.584298e+09   \n\n            ae_000        af_000        ag_000        ag_001        ag_002  \\\ncount  54580.00000  54580.000000  5.635900e+04  5.635900e+04  5.635900e+04   \nmean       7.03745     11.346574  2.429240e+02  1.384938e+03  1.065763e+04   \nstd      168.33519    211.333908  2.114293e+04  5.793025e+04  1.880938e+05   \nmin        0.00000      0.000000  0.000000e+00  0.000000e+00  0.000000e+00   \n25%        0.00000      0.000000  0.000000e+00  0.000000e+00  0.000000e+00   \n50%        0.00000      0.000000  0.000000e+00  0.000000e+00  0.000000e+00   \n75%        0.00000      0.000000  0.000000e+00  0.000000e+00  0.000000e+00   \nmax    21050.00000  20070.000000  3.376892e+06  1.047252e+07  1.914916e+07   \n\n       ...        ee_002        ee_003        ee_004        ee_005  \\\ncount  ...  5.635600e+04  5.635600e+04  5.635600e+04  5.635600e+04   \nmean   ...  4.559042e+05  2.158420e+05  4.564682e+05  4.062258e+05   \nstd    ...  1.212902e+06  5.665084e+05  1.232304e+06  1.168405e+06   \nmin    ...  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n25%    ...  3.007500e+03  1.184000e+03  2.758000e+03  3.696000e+03   \n50%    ...  2.360090e+05  1.125990e+05  2.231020e+05  1.910740e+05   \n75%    ...  4.403585e+05  2.194610e+05  4.689245e+05  4.046395e+05   \nmax    ...  7.793393e+07  3.775839e+07  9.715238e+07  5.743524e+07   \n\n             ee_006        ee_007        ee_008        ee_009        ef_000  \\\ncount  5.635600e+04  5.635600e+04  5.635600e+04  5.635600e+04  54355.000000   \nmean   3.403512e+05  3.512570e+05  1.401595e+05  8.365227e+03      0.077785   \nstd    1.094184e+06  1.748334e+06  4.724586e+05  4.669516e+04      3.891536   \nmin    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00      0.000000   \n25%    5.380000e+02  1.140000e+02  0.000000e+00  0.000000e+00      0.000000   \n50%    9.390400e+04  4.124500e+04  3.888000e+03  0.000000e+00      0.000000   \n75%    2.768690e+05  1.681080e+05  1.393195e+05  1.966000e+03      0.000000   \nmax    4.215944e+07  1.195801e+08  1.718575e+07  4.570398e+06    482.000000   \n\n             eg_000  \ncount  54356.000000  \nmean       0.179483  \nstd        7.603027  \nmin        0.000000  \n25%        0.000000  \n50%        0.000000  \n75%        0.000000  \nmax     1146.000000  \n\n[8 rows x 171 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>aa_000</th>\n      <th>ab_000</th>\n      <th>ac_000</th>\n      <th>ad_000</th>\n      <th>ae_000</th>\n      <th>af_000</th>\n      <th>ag_000</th>\n      <th>ag_001</th>\n      <th>ag_002</th>\n      <th>...</th>\n      <th>ee_002</th>\n      <th>ee_003</th>\n      <th>ee_004</th>\n      <th>ee_005</th>\n      <th>ee_006</th>\n      <th>ee_007</th>\n      <th>ee_008</th>\n      <th>ee_009</th>\n      <th>ef_000</th>\n      <th>eg_000</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>57000.000000</td>\n      <td>5.700000e+04</td>\n      <td>13012.000000</td>\n      <td>5.376300e+04</td>\n      <td>4.282200e+04</td>\n      <td>54580.00000</td>\n      <td>54580.000000</td>\n      <td>5.635900e+04</td>\n      <td>5.635900e+04</td>\n      <td>5.635900e+04</td>\n      <td>...</td>\n      <td>5.635600e+04</td>\n      <td>5.635600e+04</td>\n      <td>5.635600e+04</td>\n      <td>5.635600e+04</td>\n      <td>5.635600e+04</td>\n      <td>5.635600e+04</td>\n      <td>5.635600e+04</td>\n      <td>5.635600e+04</td>\n      <td>54355.000000</td>\n      <td>54356.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>38084.150860</td>\n      <td>6.130698e+04</td>\n      <td>0.720719</td>\n      <td>3.566436e+08</td>\n      <td>2.009135e+05</td>\n      <td>7.03745</td>\n      <td>11.346574</td>\n      <td>2.429240e+02</td>\n      <td>1.384938e+03</td>\n      <td>1.065763e+04</td>\n      <td>...</td>\n      <td>4.559042e+05</td>\n      <td>2.158420e+05</td>\n      <td>4.564682e+05</td>\n      <td>4.062258e+05</td>\n      <td>3.403512e+05</td>\n      <td>3.512570e+05</td>\n      <td>1.401595e+05</td>\n      <td>8.365227e+03</td>\n      <td>0.077785</td>\n      <td>0.179483</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>21920.895362</td>\n      <td>2.332295e+05</td>\n      <td>2.987399</td>\n      <td>7.952168e+08</td>\n      <td>4.148309e+07</td>\n      <td>168.33519</td>\n      <td>211.333908</td>\n      <td>2.114293e+04</td>\n      <td>5.793025e+04</td>\n      <td>1.880938e+05</td>\n      <td>...</td>\n      <td>1.212902e+06</td>\n      <td>5.665084e+05</td>\n      <td>1.232304e+06</td>\n      <td>1.168405e+06</td>\n      <td>1.094184e+06</td>\n      <td>1.748334e+06</td>\n      <td>4.724586e+05</td>\n      <td>4.669516e+04</td>\n      <td>3.891536</td>\n      <td>7.603027</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>0.000000e+00</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>...</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>19100.750000</td>\n      <td>8.620000e+02</td>\n      <td>0.000000</td>\n      <td>1.600000e+01</td>\n      <td>2.400000e+01</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>...</td>\n      <td>3.007500e+03</td>\n      <td>1.184000e+03</td>\n      <td>2.758000e+03</td>\n      <td>3.696000e+03</td>\n      <td>5.380000e+02</td>\n      <td>1.140000e+02</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>38110.500000</td>\n      <td>3.084200e+04</td>\n      <td>0.000000</td>\n      <td>1.540000e+02</td>\n      <td>1.260000e+02</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>...</td>\n      <td>2.360090e+05</td>\n      <td>1.125990e+05</td>\n      <td>2.231020e+05</td>\n      <td>1.910740e+05</td>\n      <td>9.390400e+04</td>\n      <td>4.124500e+04</td>\n      <td>3.888000e+03</td>\n      <td>0.000000e+00</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>57059.500000</td>\n      <td>4.895400e+04</td>\n      <td>0.000000</td>\n      <td>9.710000e+02</td>\n      <td>4.320000e+02</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>...</td>\n      <td>4.403585e+05</td>\n      <td>2.194610e+05</td>\n      <td>4.689245e+05</td>\n      <td>4.046395e+05</td>\n      <td>2.768690e+05</td>\n      <td>1.681080e+05</td>\n      <td>1.393195e+05</td>\n      <td>1.966000e+03</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>75998.000000</td>\n      <td>4.294967e+07</td>\n      <td>134.000000</td>\n      <td>2.130707e+09</td>\n      <td>8.584298e+09</td>\n      <td>21050.00000</td>\n      <td>20070.000000</td>\n      <td>3.376892e+06</td>\n      <td>1.047252e+07</td>\n      <td>1.914916e+07</td>\n      <td>...</td>\n      <td>7.793393e+07</td>\n      <td>3.775839e+07</td>\n      <td>9.715238e+07</td>\n      <td>5.743524e+07</td>\n      <td>4.215944e+07</td>\n      <td>1.195801e+08</td>\n      <td>1.718575e+07</td>\n      <td>4.570398e+06</td>\n      <td>482.000000</td>\n      <td>1146.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 171 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"   Unnamed: 0 class    aa_000  ab_000  ac_000  ad_000  ae_000  af_000  ag_000  \\\n0       52803   neg   41386.0     NaN   508.0   488.0     0.0     0.0     0.0   \n1       38189   neg   29616.0     NaN  1616.0  1490.0     0.0     0.0     0.0   \n2       23291   neg  241352.0     NaN     NaN     NaN     NaN     NaN     0.0   \n3       16862   neg    8100.0     NaN    86.0    76.0     0.0     0.0     0.0   \n4       14055   neg    2290.0     NaN   636.0   448.0     0.0     0.0     0.0   \n\n   ag_001  ...     ee_002     ee_003     ee_004    ee_005    ee_006    ee_007  \\\n0     0.0  ...   438088.0   202172.0   383094.0  392838.0  228526.0  104226.0   \n1     0.0  ...   145524.0    72858.0   171332.0  308328.0  379466.0  213826.0   \n2     0.0  ...  3617298.0  2477772.0  3631902.0  997462.0  436380.0  202002.0   \n3     0.0  ...    66980.0    36658.0    91898.0   86634.0   60276.0   23616.0   \n4     0.0  ...    11542.0     7394.0    14206.0   69592.0    3108.0     108.0   \n\n     ee_008  ee_009  ef_000  eg_000  \n0  122526.0  6924.0     0.0     0.0  \n1    5764.0   292.0     0.0     0.0  \n2  173850.0  1376.0     NaN     NaN  \n3    7518.0     2.0     0.0     0.0  \n4       6.0     0.0     0.0     0.0  \n\n[5 rows x 172 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>class</th>\n      <th>aa_000</th>\n      <th>ab_000</th>\n      <th>ac_000</th>\n      <th>ad_000</th>\n      <th>ae_000</th>\n      <th>af_000</th>\n      <th>ag_000</th>\n      <th>ag_001</th>\n      <th>...</th>\n      <th>ee_002</th>\n      <th>ee_003</th>\n      <th>ee_004</th>\n      <th>ee_005</th>\n      <th>ee_006</th>\n      <th>ee_007</th>\n      <th>ee_008</th>\n      <th>ee_009</th>\n      <th>ef_000</th>\n      <th>eg_000</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>52803</td>\n      <td>neg</td>\n      <td>41386.0</td>\n      <td>NaN</td>\n      <td>508.0</td>\n      <td>488.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>438088.0</td>\n      <td>202172.0</td>\n      <td>383094.0</td>\n      <td>392838.0</td>\n      <td>228526.0</td>\n      <td>104226.0</td>\n      <td>122526.0</td>\n      <td>6924.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>38189</td>\n      <td>neg</td>\n      <td>29616.0</td>\n      <td>NaN</td>\n      <td>1616.0</td>\n      <td>1490.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>145524.0</td>\n      <td>72858.0</td>\n      <td>171332.0</td>\n      <td>308328.0</td>\n      <td>379466.0</td>\n      <td>213826.0</td>\n      <td>5764.0</td>\n      <td>292.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>23291</td>\n      <td>neg</td>\n      <td>241352.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>3617298.0</td>\n      <td>2477772.0</td>\n      <td>3631902.0</td>\n      <td>997462.0</td>\n      <td>436380.0</td>\n      <td>202002.0</td>\n      <td>173850.0</td>\n      <td>1376.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>16862</td>\n      <td>neg</td>\n      <td>8100.0</td>\n      <td>NaN</td>\n      <td>86.0</td>\n      <td>76.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>66980.0</td>\n      <td>36658.0</td>\n      <td>91898.0</td>\n      <td>86634.0</td>\n      <td>60276.0</td>\n      <td>23616.0</td>\n      <td>7518.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>14055</td>\n      <td>neg</td>\n      <td>2290.0</td>\n      <td>NaN</td>\n      <td>636.0</td>\n      <td>448.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>11542.0</td>\n      <td>7394.0</td>\n      <td>14206.0</td>\n      <td>69592.0</td>\n      <td>3108.0</td>\n      <td>108.0</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 172 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"결측치 처리 "},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.fillna(-1)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(\"Unnamed: 0\",axis=1,inplace=True)","execution_count":12,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"데이터 분리 및 Index 초기화"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trn, val = train_test_split(data, test_size=0.2,shuffle=True, stratify=data[\"class\"], random_state=42)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid = data.iloc[val.index,:]\ntrain = data.iloc[trn.index, :]","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.reset_index(drop=True)\nvalid = valid.reset_index(drop=True)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"  class   aa_000  ab_000  ac_000  ad_000  ae_000  af_000  ag_000  ag_001  \\\n0   neg  46976.0     0.0   128.0   124.0     0.0     0.0     0.0     0.0   \n1   neg  39910.0    -1.0    70.0    66.0     0.0     0.0     0.0     0.0   \n2   neg  43614.0    -1.0   152.0   144.0     0.0     0.0     0.0     0.0   \n3   neg     60.0    -1.0     0.0    -1.0     0.0     0.0     0.0     0.0   \n4   neg  38938.0    -1.0   460.0   150.0     0.0     0.0     0.0     0.0   \n\n   ag_002  ...    ee_002    ee_003    ee_004    ee_005     ee_006    ee_007  \\\n0     0.0  ...  176578.0   80224.0  141948.0  164404.0  1438208.0   32222.0   \n1     0.0  ...  291494.0  110406.0  265298.0  254714.0   232414.0  182932.0   \n2     0.0  ...  314196.0  146948.0  297180.0  274392.0   247178.0  193972.0   \n3     0.0  ...     578.0     190.0     468.0     732.0      138.0       0.0   \n4     0.0  ...  459428.0  220256.0  413674.0  334330.0   196244.0   92842.0   \n\n     ee_008   ee_009  ef_000  eg_000  \n0     520.0      0.0     0.0     0.0  \n1  309914.0    264.0     0.0     0.0  \n2  320904.0  43452.0     0.0     0.0  \n3       0.0      0.0     0.0     0.0  \n4   57548.0    268.0     0.0     0.0  \n\n[5 rows x 171 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>aa_000</th>\n      <th>ab_000</th>\n      <th>ac_000</th>\n      <th>ad_000</th>\n      <th>ae_000</th>\n      <th>af_000</th>\n      <th>ag_000</th>\n      <th>ag_001</th>\n      <th>ag_002</th>\n      <th>...</th>\n      <th>ee_002</th>\n      <th>ee_003</th>\n      <th>ee_004</th>\n      <th>ee_005</th>\n      <th>ee_006</th>\n      <th>ee_007</th>\n      <th>ee_008</th>\n      <th>ee_009</th>\n      <th>ef_000</th>\n      <th>eg_000</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>neg</td>\n      <td>46976.0</td>\n      <td>0.0</td>\n      <td>128.0</td>\n      <td>124.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>176578.0</td>\n      <td>80224.0</td>\n      <td>141948.0</td>\n      <td>164404.0</td>\n      <td>1438208.0</td>\n      <td>32222.0</td>\n      <td>520.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>neg</td>\n      <td>39910.0</td>\n      <td>-1.0</td>\n      <td>70.0</td>\n      <td>66.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>291494.0</td>\n      <td>110406.0</td>\n      <td>265298.0</td>\n      <td>254714.0</td>\n      <td>232414.0</td>\n      <td>182932.0</td>\n      <td>309914.0</td>\n      <td>264.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>neg</td>\n      <td>43614.0</td>\n      <td>-1.0</td>\n      <td>152.0</td>\n      <td>144.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>314196.0</td>\n      <td>146948.0</td>\n      <td>297180.0</td>\n      <td>274392.0</td>\n      <td>247178.0</td>\n      <td>193972.0</td>\n      <td>320904.0</td>\n      <td>43452.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>neg</td>\n      <td>60.0</td>\n      <td>-1.0</td>\n      <td>0.0</td>\n      <td>-1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>578.0</td>\n      <td>190.0</td>\n      <td>468.0</td>\n      <td>732.0</td>\n      <td>138.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>neg</td>\n      <td>38938.0</td>\n      <td>-1.0</td>\n      <td>460.0</td>\n      <td>150.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>459428.0</td>\n      <td>220256.0</td>\n      <td>413674.0</td>\n      <td>334330.0</td>\n      <td>196244.0</td>\n      <td>92842.0</td>\n      <td>57548.0</td>\n      <td>268.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 171 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid.head()","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"  class    aa_000  ab_000  ac_000  ad_000  ae_000  af_000  ag_000   ag_001  \\\n0   neg   39034.0    -1.0   132.0   108.0     0.0     0.0     0.0      0.0   \n1   pos  349286.0    -1.0    -1.0    -1.0    -1.0    -1.0     0.0  26204.0   \n2   neg   32400.0    -1.0   714.0   626.0     0.0     0.0     0.0      0.0   \n3   neg  378224.0    -1.0    36.0    16.0     0.0     0.0     0.0      0.0   \n4   neg   61174.0    -1.0     0.0    -1.0     0.0     0.0     0.0      0.0   \n\n     ag_002  ...     ee_002     ee_003     ee_004     ee_005    ee_006  \\\n0       0.0  ...   154734.0    69690.0   165178.0   133902.0  443552.0   \n1  735690.0  ...  5012822.0  1532928.0  3381640.0  4543016.0  655000.0   \n2       0.0  ...   320846.0   168344.0   408888.0   330388.0  153806.0   \n3       0.0  ...    53412.0    24186.0    43278.0    37390.0   48242.0   \n4       0.0  ...   417030.0   213806.0   466264.0   560570.0  527686.0   \n\n     ee_007    ee_008  ee_009  ef_000  eg_000  \n0  691076.0    6636.0     0.0     0.0     0.0  \n1  207038.0    3480.0     0.0    -1.0    -1.0  \n2   65222.0   52630.0    32.0     0.0     0.0  \n3  293878.0   30980.0   194.0     0.0     0.0  \n4  293296.0  224894.0  2752.0     0.0     0.0  \n\n[5 rows x 171 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>aa_000</th>\n      <th>ab_000</th>\n      <th>ac_000</th>\n      <th>ad_000</th>\n      <th>ae_000</th>\n      <th>af_000</th>\n      <th>ag_000</th>\n      <th>ag_001</th>\n      <th>ag_002</th>\n      <th>...</th>\n      <th>ee_002</th>\n      <th>ee_003</th>\n      <th>ee_004</th>\n      <th>ee_005</th>\n      <th>ee_006</th>\n      <th>ee_007</th>\n      <th>ee_008</th>\n      <th>ee_009</th>\n      <th>ef_000</th>\n      <th>eg_000</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>neg</td>\n      <td>39034.0</td>\n      <td>-1.0</td>\n      <td>132.0</td>\n      <td>108.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>154734.0</td>\n      <td>69690.0</td>\n      <td>165178.0</td>\n      <td>133902.0</td>\n      <td>443552.0</td>\n      <td>691076.0</td>\n      <td>6636.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>pos</td>\n      <td>349286.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>0.0</td>\n      <td>26204.0</td>\n      <td>735690.0</td>\n      <td>...</td>\n      <td>5012822.0</td>\n      <td>1532928.0</td>\n      <td>3381640.0</td>\n      <td>4543016.0</td>\n      <td>655000.0</td>\n      <td>207038.0</td>\n      <td>3480.0</td>\n      <td>0.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>neg</td>\n      <td>32400.0</td>\n      <td>-1.0</td>\n      <td>714.0</td>\n      <td>626.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>320846.0</td>\n      <td>168344.0</td>\n      <td>408888.0</td>\n      <td>330388.0</td>\n      <td>153806.0</td>\n      <td>65222.0</td>\n      <td>52630.0</td>\n      <td>32.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>neg</td>\n      <td>378224.0</td>\n      <td>-1.0</td>\n      <td>36.0</td>\n      <td>16.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>53412.0</td>\n      <td>24186.0</td>\n      <td>43278.0</td>\n      <td>37390.0</td>\n      <td>48242.0</td>\n      <td>293878.0</td>\n      <td>30980.0</td>\n      <td>194.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>neg</td>\n      <td>61174.0</td>\n      <td>-1.0</td>\n      <td>0.0</td>\n      <td>-1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>417030.0</td>\n      <td>213806.0</td>\n      <td>466264.0</td>\n      <td>560570.0</td>\n      <td>527686.0</td>\n      <td>293296.0</td>\n      <td>224894.0</td>\n      <td>2752.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 171 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Target 변수 one-hot encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = train.iloc[:,1:]\ny_train = train[\"class\"]\nx_valid = valid.iloc[:,1:]\ny_valid = valid[\"class\"]\ny_train = y_train.replace({\"neg\" : 0, \"pos\" : 1})\ny_valid = y_valid.replace({\"neg\" : 0, \"pos\" : 1})","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train","execution_count":20,"outputs":[{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"0        0\n1        0\n2        0\n3        0\n4        0\n        ..\n45595    0\n45596    0\n45597    0\n45598    0\n45599    0\nName: class, Length: 45600, dtype: int64"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"비용함수 선언"},{"metadata":{"trusted":true},"cell_type":"code","source":"def cost(y_pred,y_true) : \n    cost = 0\n    for i in range(len(y_pred)) : \n        if y_pred[i] != y_true[i] : \n            if y_true[i] == 1 : \n                cost += 500\n            if y_true[i] == 0 : \n                cost += 10\n    return cost","execution_count":78,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"첫번째 모델 RandomForestClassifer"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(n_jobs=-1, random_state=42)\n#n_jobs 컴퓨터의 코어 사용 ","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf.fit(x_train,y_train)","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"RandomForestClassifier(n_jobs=-1, random_state=42)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_pred = rf.predict(x_valid)","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_pred","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"array([0, 1, 0, ..., 0, 0, 1])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_valid.values\n","execution_count":27,"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"array([0, 1, 0, ..., 0, 0, 1])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"cost(rf_pred,y_valid.values)\n","execution_count":28,"outputs":[{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"27720"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_pred_proba = rf.predict_proba(x_valid)","execution_count":52,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"두번째 모델: XGBoost "},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb = XGBClassifier(max_depth = 10, learning_rate=0.05,n_estimators=1600,tree_method = \"gpu_hist\")\n","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb.fit(x_train,y_train)\n","execution_count":31,"outputs":[{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=0,\n              importance_type='gain', interaction_constraints='',\n              learning_rate=0.05, max_delta_step=0, max_depth=10,\n              min_child_weight=1, missing=nan,\n              monotone_constraints='(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0)',\n              n_estimators=1600, n_jobs=0, num_parallel_tree=1, random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n              tree_method='gpu_hist', validate_parameters=1, verbosity=None)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_pred = xgb.predict(x_valid)","execution_count":32,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cost(xgb_pred,y_valid.values)","execution_count":33,"outputs":[{"output_type":"execute_result","execution_count":33,"data":{"text/plain":"19190"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"3번째 모델 lgb"},{"metadata":{"trusted":true},"cell_type":"code","source":"from lightgbm import LGBMClassifier\n","execution_count":34,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb = LGBMClassifier(boosting_type='gbdt', num_leaves=1024, learning_rate=0.02, n_estimators=1500, device = \"gpu\")\n","execution_count":35,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb.fit(x_train,y_train)\n","execution_count":36,"outputs":[{"output_type":"execute_result","execution_count":36,"data":{"text/plain":"LGBMClassifier(device='gpu', learning_rate=0.02, n_estimators=1500,\n               num_leaves=1024)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_pred = lgb.predict(x_valid)","execution_count":37,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cost(lgb_pred,y_valid.values)","execution_count":38,"outputs":[{"output_type":"execute_result","execution_count":38,"data":{"text/plain":"22200"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_pred_proba = lgb.predict_proba(x_valid)\nxgb_pred_proba = xgb.predict_proba(x_valid)","execution_count":39,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"정규화"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n","execution_count":40,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sc = StandardScaler()","execution_count":41,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.iloc[:,:] = sc.fit_transform(x_train.iloc[:,:])\nx_valid.iloc[:,:] = sc.transform(x_valid.iloc[:,:])","execution_count":42,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"4번째모델 딥러닝모델"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\ndef model_create() : \n    model = Sequential()\n    model.add(Dense(512, input_dim=x_train.shape[1], activation = \"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(384, activation = \"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(2, activation = \"softmax\"))\n    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"sparse_categorical_accuracy\"])\n    return model","execution_count":43,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"KFold를 활용하여 모델 과적합 방지"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nkf = KFold(n_splits=5, shuffle=True, random_state=41)\ni = 1\n# callbacks = [EarlyStopping(monitor='val_loss',patience=3,)]\ncallbacks = [EarlyStopping(monitor='val_loss',patience=5,),\n             ModelCheckpoint(filepath='best_weight.hdf5', verbose=1,\n                             save_best_only=True, mode='auto')]","execution_count":46,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_test = np.zeros((len(x_valid),2) ,dtype = np.float)\nfilepath = './best_weight.hdf5'\nfor train_index, valid_index in kf.split(x_train):\n    X_train, X_valid = x_train.iloc[train_index, :], x_train.iloc[valid_index, :]\n    Y_train, Y_valid = y_train[train_index] ,y_train[valid_index]\n    model = model_create()\n    model.fit(X_train, Y_train, batch_size=512, epochs=1000, verbose=1,validation_data=(X_valid, Y_valid), callbacks = callbacks)\n    model.load_weights(filepath)\n    preds_test_fold = model.predict(x_valid,batch_size = 256, verbose=1)     \n#     preds_test_fold = np.reshape(preds_test_fold, (1299, ))\n    preds_test += preds_test_fold\npreds_test /= 5","execution_count":47,"outputs":[{"output_type":"stream","text":"Epoch 1/1000\n60/72 [========================>.....] - ETA: 0s - loss: 0.1185 - sparse_categorical_accuracy: 0.9731\nEpoch 00001: val_loss improved from inf to 0.04975, saving model to best_weight.hdf5\n72/72 [==============================] - 0s 6ms/step - loss: 0.1104 - sparse_categorical_accuracy: 0.9752 - val_loss: 0.0497 - val_sparse_categorical_accuracy: 0.9884\nEpoch 2/1000\n56/72 [======================>.......] - ETA: 0s - loss: 0.0495 - sparse_categorical_accuracy: 0.9871\nEpoch 00002: val_loss improved from 0.04975 to 0.03836, saving model to best_weight.hdf5\n72/72 [==============================] - 0s 4ms/step - loss: 0.0505 - sparse_categorical_accuracy: 0.9875 - val_loss: 0.0384 - val_sparse_categorical_accuracy: 0.9900\nEpoch 3/1000\n61/72 [========================>.....] - ETA: 0s - loss: 0.0354 - sparse_categorical_accuracy: 0.9897\nEpoch 00003: val_loss improved from 0.03836 to 0.03464, saving model to best_weight.hdf5\n72/72 [==============================] - 0s 4ms/step - loss: 0.0368 - sparse_categorical_accuracy: 0.9896 - val_loss: 0.0346 - val_sparse_categorical_accuracy: 0.9900\nEpoch 4/1000\n61/72 [========================>.....] - ETA: 0s - loss: 0.0331 - sparse_categorical_accuracy: 0.9897\nEpoch 00004: val_loss improved from 0.03464 to 0.03347, saving model to best_weight.hdf5\n72/72 [==============================] - 0s 4ms/step - loss: 0.0325 - sparse_categorical_accuracy: 0.9899 - val_loss: 0.0335 - val_sparse_categorical_accuracy: 0.9897\nEpoch 5/1000\n61/72 [========================>.....] - ETA: 0s - loss: 0.0270 - sparse_categorical_accuracy: 0.9913\nEpoch 00005: val_loss improved from 0.03347 to 0.03226, saving model to best_weight.hdf5\n72/72 [==============================] - 0s 4ms/step - loss: 0.0272 - sparse_categorical_accuracy: 0.9913 - val_loss: 0.0323 - val_sparse_categorical_accuracy: 0.9907\nEpoch 6/1000\n70/72 [============================>.] - ETA: 0s - loss: 0.0246 - sparse_categorical_accuracy: 0.9918\nEpoch 00006: val_loss improved from 0.03226 to 0.03080, saving model to best_weight.hdf5\n72/72 [==============================] - 0s 3ms/step - loss: 0.0252 - sparse_categorical_accuracy: 0.9918 - val_loss: 0.0308 - val_sparse_categorical_accuracy: 0.9913\nEpoch 7/1000\n70/72 [============================>.] - ETA: 0s - loss: 0.0239 - sparse_categorical_accuracy: 0.9920\nEpoch 00007: val_loss improved from 0.03080 to 0.03070, saving model to best_weight.hdf5\n72/72 [==============================] - 0s 3ms/step - loss: 0.0238 - sparse_categorical_accuracy: 0.9920 - val_loss: 0.0307 - val_sparse_categorical_accuracy: 0.9910\nEpoch 8/1000\n67/72 [==========================>...] - ETA: 0s - loss: 0.0218 - sparse_categorical_accuracy: 0.9926\nEpoch 00008: val_loss improved from 0.03070 to 0.02911, saving model to best_weight.hdf5\n72/72 [==============================] - 0s 3ms/step - loss: 0.0217 - sparse_categorical_accuracy: 0.9925 - val_loss: 0.0291 - val_sparse_categorical_accuracy: 0.9918\nEpoch 9/1000\n71/72 [============================>.] - ETA: 0s - loss: 0.0200 - sparse_categorical_accuracy: 0.9932\nEpoch 00009: val_loss improved from 0.02911 to 0.02855, saving model to best_weight.hdf5\n72/72 [==============================] - 0s 3ms/step - loss: 0.0201 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0285 - val_sparse_categorical_accuracy: 0.9924\nEpoch 10/1000\n65/72 [==========================>...] - ETA: 0s - loss: 0.0191 - sparse_categorical_accuracy: 0.9934\nEpoch 00010: val_loss did not improve from 0.02855\n72/72 [==============================] - 0s 3ms/step - loss: 0.0199 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0299 - val_sparse_categorical_accuracy: 0.9922\nEpoch 11/1000\n63/72 [=========================>....] - ETA: 0s - loss: 0.0202 - sparse_categorical_accuracy: 0.9932\nEpoch 00011: val_loss did not improve from 0.02855\n72/72 [==============================] - 0s 3ms/step - loss: 0.0199 - sparse_categorical_accuracy: 0.9933 - val_loss: 0.0293 - val_sparse_categorical_accuracy: 0.9916\nEpoch 12/1000\n61/72 [========================>.....] - ETA: 0s - loss: 0.0188 - sparse_categorical_accuracy: 0.9938\nEpoch 00012: val_loss did not improve from 0.02855\n72/72 [==============================] - 0s 3ms/step - loss: 0.0187 - sparse_categorical_accuracy: 0.9937 - val_loss: 0.0289 - val_sparse_categorical_accuracy: 0.9919\nEpoch 13/1000\n61/72 [========================>.....] - ETA: 0s - loss: 0.0169 - sparse_categorical_accuracy: 0.9940\nEpoch 00013: val_loss did not improve from 0.02855\n72/72 [==============================] - 0s 3ms/step - loss: 0.0177 - sparse_categorical_accuracy: 0.9939 - val_loss: 0.0299 - val_sparse_categorical_accuracy: 0.9919\nEpoch 14/1000\n61/72 [========================>.....] - ETA: 0s - loss: 0.0164 - sparse_categorical_accuracy: 0.9942\nEpoch 00014: val_loss did not improve from 0.02855\n72/72 [==============================] - 0s 3ms/step - loss: 0.0157 - sparse_categorical_accuracy: 0.9944 - val_loss: 0.0290 - val_sparse_categorical_accuracy: 0.9922\n45/45 [==============================] - 0s 994us/step\nEpoch 1/1000\n69/72 [===========================>..] - ETA: 0s - loss: 0.1047 - sparse_categorical_accuracy: 0.9794\nEpoch 00001: val_loss did not improve from 0.02855\n72/72 [==============================] - 0s 5ms/step - loss: 0.1027 - sparse_categorical_accuracy: 0.9796 - val_loss: 0.0412 - val_sparse_categorical_accuracy: 0.9896\nEpoch 2/1000\n69/72 [===========================>..] - ETA: 0s - loss: 0.0458 - sparse_categorical_accuracy: 0.9878\nEpoch 00002: val_loss did not improve from 0.02855\n72/72 [==============================] - 0s 3ms/step - loss: 0.0457 - sparse_categorical_accuracy: 0.9878 - val_loss: 0.0345 - val_sparse_categorical_accuracy: 0.9913\nEpoch 3/1000\n70/72 [============================>.] - ETA: 0s - loss: 0.0346 - sparse_categorical_accuracy: 0.9893\nEpoch 00003: val_loss did not improve from 0.02855\n72/72 [==============================] - 0s 3ms/step - loss: 0.0350 - sparse_categorical_accuracy: 0.9891 - val_loss: 0.0352 - val_sparse_categorical_accuracy: 0.9904\nEpoch 4/1000\n71/72 [============================>.] - ETA: 0s - loss: 0.0280 - sparse_categorical_accuracy: 0.9907\nEpoch 00004: val_loss did not improve from 0.02855\n72/72 [==============================] - 0s 3ms/step - loss: 0.0281 - sparse_categorical_accuracy: 0.9906 - val_loss: 0.0373 - val_sparse_categorical_accuracy: 0.9904\nEpoch 5/1000\n71/72 [============================>.] - ETA: 0s - loss: 0.0286 - sparse_categorical_accuracy: 0.9915\nEpoch 00005: val_loss did not improve from 0.02855\n72/72 [==============================] - 0s 4ms/step - loss: 0.0286 - sparse_categorical_accuracy: 0.9915 - val_loss: 0.0373 - val_sparse_categorical_accuracy: 0.9910\nEpoch 6/1000\n59/72 [=======================>......] - ETA: 0s - loss: 0.0247 - sparse_categorical_accuracy: 0.9916\nEpoch 00006: val_loss did not improve from 0.02855\n72/72 [==============================] - 0s 4ms/step - loss: 0.0237 - sparse_categorical_accuracy: 0.9919 - val_loss: 0.0359 - val_sparse_categorical_accuracy: 0.9905\nEpoch 7/1000\n71/72 [============================>.] - ETA: 0s - loss: 0.0233 - sparse_categorical_accuracy: 0.9925\nEpoch 00007: val_loss did not improve from 0.02855\n72/72 [==============================] - 0s 4ms/step - loss: 0.0236 - sparse_categorical_accuracy: 0.9924 - val_loss: 0.0355 - val_sparse_categorical_accuracy: 0.9918\n45/45 [==============================] - 0s 969us/step\nEpoch 1/1000\n67/72 [==========================>...] - ETA: 0s - loss: 0.1230 - sparse_categorical_accuracy: 0.9720\nEpoch 00001: val_loss did not improve from 0.02855\n72/72 [==============================] - 0s 5ms/step - loss: 0.1189 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.0372 - val_sparse_categorical_accuracy: 0.9893\nEpoch 2/1000\n70/72 [============================>.] - ETA: 0s - loss: 0.0431 - sparse_categorical_accuracy: 0.9881\nEpoch 00002: val_loss did not improve from 0.02855\n72/72 [==============================] - 0s 3ms/step - loss: 0.0429 - sparse_categorical_accuracy: 0.9882 - val_loss: 0.0327 - val_sparse_categorical_accuracy: 0.9888\nEpoch 3/1000\n","name":"stdout"},{"output_type":"stream","text":"69/72 [===========================>..] - ETA: 0s - loss: 0.0380 - sparse_categorical_accuracy: 0.9893\nEpoch 00003: val_loss did not improve from 0.02855\n72/72 [==============================] - 0s 3ms/step - loss: 0.0393 - sparse_categorical_accuracy: 0.9893 - val_loss: 0.0288 - val_sparse_categorical_accuracy: 0.9909\nEpoch 4/1000\n70/72 [============================>.] - ETA: 0s - loss: 0.0305 - sparse_categorical_accuracy: 0.9898\nEpoch 00004: val_loss improved from 0.02855 to 0.02705, saving model to best_weight.hdf5\n72/72 [==============================] - 0s 3ms/step - loss: 0.0304 - sparse_categorical_accuracy: 0.9898 - val_loss: 0.0271 - val_sparse_categorical_accuracy: 0.9911\nEpoch 5/1000\n69/72 [===========================>..] - ETA: 0s - loss: 0.0288 - sparse_categorical_accuracy: 0.9907\nEpoch 00005: val_loss improved from 0.02705 to 0.02541, saving model to best_weight.hdf5\n72/72 [==============================] - 0s 3ms/step - loss: 0.0282 - sparse_categorical_accuracy: 0.9910 - val_loss: 0.0254 - val_sparse_categorical_accuracy: 0.9916\nEpoch 6/1000\n71/72 [============================>.] - ETA: 0s - loss: 0.0240 - sparse_categorical_accuracy: 0.9914\nEpoch 00006: val_loss improved from 0.02541 to 0.02471, saving model to best_weight.hdf5\n72/72 [==============================] - 0s 3ms/step - loss: 0.0240 - sparse_categorical_accuracy: 0.9914 - val_loss: 0.0247 - val_sparse_categorical_accuracy: 0.9918\nEpoch 7/1000\n71/72 [============================>.] - ETA: 0s - loss: 0.0239 - sparse_categorical_accuracy: 0.9918\nEpoch 00007: val_loss did not improve from 0.02471\n72/72 [==============================] - 0s 3ms/step - loss: 0.0238 - sparse_categorical_accuracy: 0.9919 - val_loss: 0.0250 - val_sparse_categorical_accuracy: 0.9918\nEpoch 8/1000\n70/72 [============================>.] - ETA: 0s - loss: 0.0226 - sparse_categorical_accuracy: 0.9922\nEpoch 00008: val_loss improved from 0.02471 to 0.02422, saving model to best_weight.hdf5\n72/72 [==============================] - 0s 3ms/step - loss: 0.0229 - sparse_categorical_accuracy: 0.9922 - val_loss: 0.0242 - val_sparse_categorical_accuracy: 0.9916\nEpoch 9/1000\n70/72 [============================>.] - ETA: 0s - loss: 0.0211 - sparse_categorical_accuracy: 0.9925\nEpoch 00009: val_loss improved from 0.02422 to 0.02372, saving model to best_weight.hdf5\n72/72 [==============================] - 0s 3ms/step - loss: 0.0212 - sparse_categorical_accuracy: 0.9924 - val_loss: 0.0237 - val_sparse_categorical_accuracy: 0.9925\nEpoch 10/1000\n61/72 [========================>.....] - ETA: 0s - loss: 0.0183 - sparse_categorical_accuracy: 0.9940\nEpoch 00010: val_loss did not improve from 0.02372\n72/72 [==============================] - 0s 3ms/step - loss: 0.0187 - sparse_categorical_accuracy: 0.9937 - val_loss: 0.0239 - val_sparse_categorical_accuracy: 0.9920\nEpoch 11/1000\n61/72 [========================>.....] - ETA: 0s - loss: 0.0189 - sparse_categorical_accuracy: 0.9932\nEpoch 00011: val_loss did not improve from 0.02372\n72/72 [==============================] - 0s 3ms/step - loss: 0.0194 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0255 - val_sparse_categorical_accuracy: 0.9928\nEpoch 12/1000\n65/72 [==========================>...] - ETA: 0s - loss: 0.0191 - sparse_categorical_accuracy: 0.9936\nEpoch 00012: val_loss did not improve from 0.02372\n72/72 [==============================] - 0s 3ms/step - loss: 0.0185 - sparse_categorical_accuracy: 0.9938 - val_loss: 0.0248 - val_sparse_categorical_accuracy: 0.9919\nEpoch 13/1000\n70/72 [============================>.] - ETA: 0s - loss: 0.0174 - sparse_categorical_accuracy: 0.9940\nEpoch 00013: val_loss did not improve from 0.02372\n72/72 [==============================] - 0s 3ms/step - loss: 0.0175 - sparse_categorical_accuracy: 0.9940 - val_loss: 0.0264 - val_sparse_categorical_accuracy: 0.9923\nEpoch 14/1000\n49/72 [===================>..........] - ETA: 0s - loss: 0.0168 - sparse_categorical_accuracy: 0.9942\nEpoch 00014: val_loss did not improve from 0.02372\n72/72 [==============================] - 0s 3ms/step - loss: 0.0163 - sparse_categorical_accuracy: 0.9943 - val_loss: 0.0257 - val_sparse_categorical_accuracy: 0.9921\n45/45 [==============================] - 0s 994us/step\nEpoch 1/1000\n68/72 [===========================>..] - ETA: 0s - loss: 0.1058 - sparse_categorical_accuracy: 0.9785\nEpoch 00001: val_loss did not improve from 0.02372\n72/72 [==============================] - 0s 4ms/step - loss: 0.1037 - sparse_categorical_accuracy: 0.9788 - val_loss: 0.0419 - val_sparse_categorical_accuracy: 0.9894\nEpoch 2/1000\n71/72 [============================>.] - ETA: 0s - loss: 0.0456 - sparse_categorical_accuracy: 0.9881\nEpoch 00002: val_loss did not improve from 0.02372\n72/72 [==============================] - 0s 3ms/step - loss: 0.0455 - sparse_categorical_accuracy: 0.9881 - val_loss: 0.0389 - val_sparse_categorical_accuracy: 0.9906\nEpoch 3/1000\n72/72 [==============================] - ETA: 0s - loss: 0.0351 - sparse_categorical_accuracy: 0.9895\nEpoch 00003: val_loss did not improve from 0.02372\n72/72 [==============================] - 0s 3ms/step - loss: 0.0351 - sparse_categorical_accuracy: 0.9895 - val_loss: 0.0455 - val_sparse_categorical_accuracy: 0.9893\nEpoch 4/1000\n70/72 [============================>.] - ETA: 0s - loss: 0.0321 - sparse_categorical_accuracy: 0.9900\nEpoch 00004: val_loss did not improve from 0.02372\n72/72 [==============================] - 0s 3ms/step - loss: 0.0322 - sparse_categorical_accuracy: 0.9899 - val_loss: 0.0440 - val_sparse_categorical_accuracy: 0.9898\nEpoch 5/1000\n72/72 [==============================] - ETA: 0s - loss: 0.0259 - sparse_categorical_accuracy: 0.9919\nEpoch 00005: val_loss did not improve from 0.02372\n72/72 [==============================] - 0s 3ms/step - loss: 0.0259 - sparse_categorical_accuracy: 0.9919 - val_loss: 0.0404 - val_sparse_categorical_accuracy: 0.9907\nEpoch 6/1000\n71/72 [============================>.] - ETA: 0s - loss: 0.0242 - sparse_categorical_accuracy: 0.9918\nEpoch 00006: val_loss did not improve from 0.02372\n72/72 [==============================] - 0s 3ms/step - loss: 0.0242 - sparse_categorical_accuracy: 0.9918 - val_loss: 0.0401 - val_sparse_categorical_accuracy: 0.9908\nEpoch 7/1000\n63/72 [=========================>....] - ETA: 0s - loss: 0.0219 - sparse_categorical_accuracy: 0.9927\nEpoch 00007: val_loss did not improve from 0.02372\n72/72 [==============================] - 0s 3ms/step - loss: 0.0219 - sparse_categorical_accuracy: 0.9928 - val_loss: 0.0431 - val_sparse_categorical_accuracy: 0.9907\n45/45 [==============================] - 0s 1ms/step\nEpoch 1/1000\n70/72 [============================>.] - ETA: 0s - loss: 0.1098 - sparse_categorical_accuracy: 0.9751\nEpoch 00001: val_loss did not improve from 0.02372\n72/72 [==============================] - 0s 5ms/step - loss: 0.1087 - sparse_categorical_accuracy: 0.9753 - val_loss: 0.0350 - val_sparse_categorical_accuracy: 0.9911\nEpoch 2/1000\n67/72 [==========================>...] - ETA: 0s - loss: 0.0509 - sparse_categorical_accuracy: 0.9871\nEpoch 00002: val_loss did not improve from 0.02372\n72/72 [==============================] - 0s 3ms/step - loss: 0.0491 - sparse_categorical_accuracy: 0.9875 - val_loss: 0.0298 - val_sparse_categorical_accuracy: 0.9906\nEpoch 3/1000\n68/72 [===========================>..] - ETA: 0s - loss: 0.0373 - sparse_categorical_accuracy: 0.9891\nEpoch 00003: val_loss did not improve from 0.02372\n72/72 [==============================] - 0s 3ms/step - loss: 0.0366 - sparse_categorical_accuracy: 0.9891 - val_loss: 0.0259 - val_sparse_categorical_accuracy: 0.9913\nEpoch 4/1000\n67/72 [==========================>...] - ETA: 0s - loss: 0.0330 - sparse_categorical_accuracy: 0.9906\nEpoch 00004: val_loss did not improve from 0.02372\n72/72 [==============================] - 0s 3ms/step - loss: 0.0335 - sparse_categorical_accuracy: 0.9903 - val_loss: 0.0280 - val_sparse_categorical_accuracy: 0.9902\nEpoch 5/1000\n71/72 [============================>.] - ETA: 0s - loss: 0.0293 - sparse_categorical_accuracy: 0.9909\nEpoch 00005: val_loss did not improve from 0.02372\n72/72 [==============================] - 0s 3ms/step - loss: 0.0296 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0262 - val_sparse_categorical_accuracy: 0.9913\n","name":"stdout"},{"output_type":"stream","text":"Epoch 6/1000\n71/72 [============================>.] - ETA: 0s - loss: 0.0269 - sparse_categorical_accuracy: 0.9911\nEpoch 00006: val_loss did not improve from 0.02372\n72/72 [==============================] - 0s 3ms/step - loss: 0.0268 - sparse_categorical_accuracy: 0.9911 - val_loss: 0.0238 - val_sparse_categorical_accuracy: 0.9923\nEpoch 7/1000\n70/72 [============================>.] - ETA: 0s - loss: 0.0240 - sparse_categorical_accuracy: 0.9916\nEpoch 00007: val_loss did not improve from 0.02372\n72/72 [==============================] - 0s 3ms/step - loss: 0.0239 - sparse_categorical_accuracy: 0.9916 - val_loss: 0.0240 - val_sparse_categorical_accuracy: 0.9920\nEpoch 8/1000\n68/72 [===========================>..] - ETA: 0s - loss: 0.0234 - sparse_categorical_accuracy: 0.9922\nEpoch 00008: val_loss improved from 0.02372 to 0.02326, saving model to best_weight.hdf5\n72/72 [==============================] - 0s 3ms/step - loss: 0.0233 - sparse_categorical_accuracy: 0.9922 - val_loss: 0.0233 - val_sparse_categorical_accuracy: 0.9929\nEpoch 9/1000\n71/72 [============================>.] - ETA: 0s - loss: 0.0211 - sparse_categorical_accuracy: 0.9926\nEpoch 00009: val_loss improved from 0.02326 to 0.02184, saving model to best_weight.hdf5\n72/72 [==============================] - 0s 3ms/step - loss: 0.0210 - sparse_categorical_accuracy: 0.9927 - val_loss: 0.0218 - val_sparse_categorical_accuracy: 0.9925\nEpoch 10/1000\n70/72 [============================>.] - ETA: 0s - loss: 0.0204 - sparse_categorical_accuracy: 0.9934\nEpoch 00010: val_loss did not improve from 0.02184\n72/72 [==============================] - 0s 3ms/step - loss: 0.0203 - sparse_categorical_accuracy: 0.9935 - val_loss: 0.0225 - val_sparse_categorical_accuracy: 0.9930\nEpoch 11/1000\n70/72 [============================>.] - ETA: 0s - loss: 0.0199 - sparse_categorical_accuracy: 0.9936\nEpoch 00011: val_loss did not improve from 0.02184\n72/72 [==============================] - 0s 3ms/step - loss: 0.0198 - sparse_categorical_accuracy: 0.9936 - val_loss: 0.0237 - val_sparse_categorical_accuracy: 0.9928\nEpoch 12/1000\n70/72 [============================>.] - ETA: 0s - loss: 0.0195 - sparse_categorical_accuracy: 0.9938\nEpoch 00012: val_loss did not improve from 0.02184\n72/72 [==============================] - 0s 3ms/step - loss: 0.0194 - sparse_categorical_accuracy: 0.9938 - val_loss: 0.0237 - val_sparse_categorical_accuracy: 0.9931\nEpoch 13/1000\n64/72 [=========================>....] - ETA: 0s - loss: 0.0197 - sparse_categorical_accuracy: 0.9940\nEpoch 00013: val_loss did not improve from 0.02184\n72/72 [==============================] - 0s 3ms/step - loss: 0.0198 - sparse_categorical_accuracy: 0.9939 - val_loss: 0.0250 - val_sparse_categorical_accuracy: 0.9928\nEpoch 14/1000\n68/72 [===========================>..] - ETA: 0s - loss: 0.0181 - sparse_categorical_accuracy: 0.9935\nEpoch 00014: val_loss did not improve from 0.02184\n72/72 [==============================] - 0s 3ms/step - loss: 0.0179 - sparse_categorical_accuracy: 0.9936 - val_loss: 0.0245 - val_sparse_categorical_accuracy: 0.9928\n45/45 [==============================] - 0s 1ms/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_test","execution_count":48,"outputs":[{"output_type":"execute_result","execution_count":48,"data":{"text/plain":"array([[9.99440551e-01, 5.59492642e-04],\n       [1.08265937e-02, 9.89173388e-01],\n       [9.99998641e-01, 1.36600027e-06],\n       ...,\n       [9.81753695e-01, 1.82463158e-02],\n       [9.99406397e-01, 5.93658397e-04],\n       [8.07391298e-05, 9.99919295e-01]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"cost(np.argmax(preds_test,axis=1),y_valid)","execution_count":49,"outputs":[{"output_type":"execute_result","execution_count":49,"data":{"text/plain":"32310"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_test","execution_count":50,"outputs":[{"output_type":"execute_result","execution_count":50,"data":{"text/plain":"array([[9.99440551e-01, 5.59492642e-04],\n       [1.08265937e-02, 9.89173388e-01],\n       [9.99998641e-01, 1.36600027e-06],\n       ...,\n       [9.81753695e-01, 1.82463158e-02],\n       [9.99406397e-01, 5.93658397e-04],\n       [8.07391298e-05, 9.99919295e-01]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_pred_proba","execution_count":51,"outputs":[{"output_type":"execute_result","execution_count":51,"data":{"text/plain":"array([[9.99999669e-01, 3.31465301e-07],\n       [1.02295124e-07, 9.99999898e-01],\n       [9.99999998e-01, 2.03766330e-09],\n       ...,\n       [9.99999737e-01, 2.62716513e-07],\n       [9.99999919e-01, 8.09649840e-08],\n       [5.07777406e-08, 9.99999949e-01]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_pred = 0.05*rf_pred_proba+ preds_test*0.1 + lgb_pred_proba*0.35 + xgb_pred_proba*0.5","execution_count":84,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmax(final_pred,axis=1)","execution_count":85,"outputs":[{"output_type":"execute_result","execution_count":85,"data":{"text/plain":"array([0, 1, 0, ..., 0, 0, 1])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"cost(np.argmax(final_pred,axis=1),y_valid)","execution_count":86,"outputs":[{"output_type":"execute_result","execution_count":86,"data":{"text/plain":"22180"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat":4,"nbformat_minor":4}