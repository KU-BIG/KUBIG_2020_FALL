{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>class</th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ab_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52803</td>\n",
       "      <td>neg</td>\n",
       "      <td>41386</td>\n",
       "      <td>na</td>\n",
       "      <td>508</td>\n",
       "      <td>488</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>438088</td>\n",
       "      <td>202172</td>\n",
       "      <td>383094</td>\n",
       "      <td>392838</td>\n",
       "      <td>228526</td>\n",
       "      <td>104226</td>\n",
       "      <td>122526</td>\n",
       "      <td>6924</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38189</td>\n",
       "      <td>neg</td>\n",
       "      <td>29616</td>\n",
       "      <td>na</td>\n",
       "      <td>1616</td>\n",
       "      <td>1490</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>145524</td>\n",
       "      <td>72858</td>\n",
       "      <td>171332</td>\n",
       "      <td>308328</td>\n",
       "      <td>379466</td>\n",
       "      <td>213826</td>\n",
       "      <td>5764</td>\n",
       "      <td>292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23291</td>\n",
       "      <td>neg</td>\n",
       "      <td>241352</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3617298</td>\n",
       "      <td>2477772</td>\n",
       "      <td>3631902</td>\n",
       "      <td>997462</td>\n",
       "      <td>436380</td>\n",
       "      <td>202002</td>\n",
       "      <td>173850</td>\n",
       "      <td>1376</td>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16862</td>\n",
       "      <td>neg</td>\n",
       "      <td>8100</td>\n",
       "      <td>na</td>\n",
       "      <td>86</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>66980</td>\n",
       "      <td>36658</td>\n",
       "      <td>91898</td>\n",
       "      <td>86634</td>\n",
       "      <td>60276</td>\n",
       "      <td>23616</td>\n",
       "      <td>7518</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14055</td>\n",
       "      <td>neg</td>\n",
       "      <td>2290</td>\n",
       "      <td>na</td>\n",
       "      <td>636</td>\n",
       "      <td>448</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11542</td>\n",
       "      <td>7394</td>\n",
       "      <td>14206</td>\n",
       "      <td>69592</td>\n",
       "      <td>3108</td>\n",
       "      <td>108</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 class  aa_000 ab_000 ac_000 ad_000 ae_000 af_000 ag_000 ag_001  \\\n",
       "0       52803   neg   41386     na    508    488      0      0      0      0   \n",
       "1       38189   neg   29616     na   1616   1490      0      0      0      0   \n",
       "2       23291   neg  241352     na     na     na     na     na      0      0   \n",
       "3       16862   neg    8100     na     86     76      0      0      0      0   \n",
       "4       14055   neg    2290     na    636    448      0      0      0      0   \n",
       "\n",
       "   ...   ee_002   ee_003   ee_004  ee_005  ee_006  ee_007  ee_008 ee_009  \\\n",
       "0  ...   438088   202172   383094  392838  228526  104226  122526   6924   \n",
       "1  ...   145524    72858   171332  308328  379466  213826    5764    292   \n",
       "2  ...  3617298  2477772  3631902  997462  436380  202002  173850   1376   \n",
       "3  ...    66980    36658    91898   86634   60276   23616    7518      2   \n",
       "4  ...    11542     7394    14206   69592    3108     108       6      0   \n",
       "\n",
       "  ef_000 eg_000  \n",
       "0      0      0  \n",
       "1      0      0  \n",
       "2     na     na  \n",
       "3      0      0  \n",
       "4      0      0  \n",
       "\n",
       "[5 rows x 172 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train data 읽고 확인\n",
    "train_raw = pd.read_csv(\"Train_data.csv\")\n",
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    55934\n",
       "pos     1066\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57000 entries, 0 to 56999\n",
      "Columns: 172 entries, Unnamed: 0 to eg_000\n",
      "dtypes: int64(2), object(170)\n",
      "memory usage: 74.8+ MB\n"
     ]
    }
   ],
   "source": [
    "train_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    98.129825\n",
       "pos     1.870175\n",
       "Name: class, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data imbalance in percentage\n",
    "train_raw['class'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>class</th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ab_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52803</td>\n",
       "      <td>neg</td>\n",
       "      <td>41386</td>\n",
       "      <td>NaN</td>\n",
       "      <td>508</td>\n",
       "      <td>488</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>438088</td>\n",
       "      <td>202172</td>\n",
       "      <td>383094</td>\n",
       "      <td>392838</td>\n",
       "      <td>228526</td>\n",
       "      <td>104226</td>\n",
       "      <td>122526</td>\n",
       "      <td>6924</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38189</td>\n",
       "      <td>neg</td>\n",
       "      <td>29616</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1616</td>\n",
       "      <td>1490</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>145524</td>\n",
       "      <td>72858</td>\n",
       "      <td>171332</td>\n",
       "      <td>308328</td>\n",
       "      <td>379466</td>\n",
       "      <td>213826</td>\n",
       "      <td>5764</td>\n",
       "      <td>292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23291</td>\n",
       "      <td>neg</td>\n",
       "      <td>241352</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3617298</td>\n",
       "      <td>2477772</td>\n",
       "      <td>3631902</td>\n",
       "      <td>997462</td>\n",
       "      <td>436380</td>\n",
       "      <td>202002</td>\n",
       "      <td>173850</td>\n",
       "      <td>1376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16862</td>\n",
       "      <td>neg</td>\n",
       "      <td>8100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>66980</td>\n",
       "      <td>36658</td>\n",
       "      <td>91898</td>\n",
       "      <td>86634</td>\n",
       "      <td>60276</td>\n",
       "      <td>23616</td>\n",
       "      <td>7518</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14055</td>\n",
       "      <td>neg</td>\n",
       "      <td>2290</td>\n",
       "      <td>NaN</td>\n",
       "      <td>636</td>\n",
       "      <td>448</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11542</td>\n",
       "      <td>7394</td>\n",
       "      <td>14206</td>\n",
       "      <td>69592</td>\n",
       "      <td>3108</td>\n",
       "      <td>108</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 class  aa_000 ab_000 ac_000 ad_000 ae_000 af_000 ag_000 ag_001  \\\n",
       "0       52803   neg   41386    NaN    508    488      0      0      0      0   \n",
       "1       38189   neg   29616    NaN   1616   1490      0      0      0      0   \n",
       "2       23291   neg  241352    NaN    NaN    NaN    NaN    NaN      0      0   \n",
       "3       16862   neg    8100    NaN     86     76      0      0      0      0   \n",
       "4       14055   neg    2290    NaN    636    448      0      0      0      0   \n",
       "\n",
       "   ...   ee_002   ee_003   ee_004  ee_005  ee_006  ee_007  ee_008 ee_009  \\\n",
       "0  ...   438088   202172   383094  392838  228526  104226  122526   6924   \n",
       "1  ...   145524    72858   171332  308328  379466  213826    5764    292   \n",
       "2  ...  3617298  2477772  3631902  997462  436380  202002  173850   1376   \n",
       "3  ...    66980    36658    91898   86634   60276   23616    7518      2   \n",
       "4  ...    11542     7394    14206   69592    3108     108       6      0   \n",
       "\n",
       "  ef_000 eg_000  \n",
       "0      0      0  \n",
       "1      0      0  \n",
       "2    NaN    NaN  \n",
       "3      0      0  \n",
       "4      0      0  \n",
       "\n",
       "[5 rows x 172 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=train_raw.replace(\"na\", np.nan)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "810447"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data set from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ab_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>ag_002</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1098</td>\n",
       "      <td>138</td>\n",
       "      <td>412</td>\n",
       "      <td>654</td>\n",
       "      <td>78</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1068</td>\n",
       "      <td>276</td>\n",
       "      <td>1620</td>\n",
       "      <td>116</td>\n",
       "      <td>86</td>\n",
       "      <td>462</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>66002</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>495076</td>\n",
       "      <td>380368</td>\n",
       "      <td>440134</td>\n",
       "      <td>269556</td>\n",
       "      <td>1315022</td>\n",
       "      <td>153680</td>\n",
       "      <td>516</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>59816</td>\n",
       "      <td>na</td>\n",
       "      <td>1010</td>\n",
       "      <td>936</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>540820</td>\n",
       "      <td>243270</td>\n",
       "      <td>483302</td>\n",
       "      <td>485332</td>\n",
       "      <td>431376</td>\n",
       "      <td>210074</td>\n",
       "      <td>281662</td>\n",
       "      <td>3232</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>1814</td>\n",
       "      <td>na</td>\n",
       "      <td>156</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7646</td>\n",
       "      <td>4144</td>\n",
       "      <td>18466</td>\n",
       "      <td>49782</td>\n",
       "      <td>3176</td>\n",
       "      <td>482</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class  aa_000 ab_000 ac_000 ad_000 ae_000 af_000 ag_000 ag_001 ag_002  ...  \\\n",
       "0   neg      60      0     20     12      0      0      0      0      0  ...   \n",
       "1   neg      82      0     68     40      0      0      0      0      0  ...   \n",
       "2   neg   66002      2    212    112      0      0      0      0      0  ...   \n",
       "3   neg   59816     na   1010    936      0      0      0      0      0  ...   \n",
       "4   neg    1814     na    156    140      0      0      0      0      0  ...   \n",
       "\n",
       "   ee_002  ee_003  ee_004  ee_005   ee_006  ee_007  ee_008 ee_009 ef_000  \\\n",
       "0    1098     138     412     654       78      88       0      0      0   \n",
       "1    1068     276    1620     116       86     462       0      0      0   \n",
       "2  495076  380368  440134  269556  1315022  153680     516      0      0   \n",
       "3  540820  243270  483302  485332   431376  210074  281662   3232      0   \n",
       "4    7646    4144   18466   49782     3176     482      76      0      0   \n",
       "\n",
       "  eg_000  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 171 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('aps_failure_test_set.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    15625\n",
       "pos      375\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Train-Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val=train_test_split(train, train[\"class\"], test_size=0.2, random_state=42, stratify=train[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 45600 entries, 36627 to 50505\n",
      "Columns: 172 entries, Unnamed: 0 to eg_000\n",
      "dtypes: int64(2), object(170)\n",
      "memory usage: 60.2+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>class</th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ab_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36627</th>\n",
       "      <td>58126</td>\n",
       "      <td>neg</td>\n",
       "      <td>46976</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>176578</td>\n",
       "      <td>80224</td>\n",
       "      <td>141948</td>\n",
       "      <td>164404</td>\n",
       "      <td>1438208</td>\n",
       "      <td>32222</td>\n",
       "      <td>520</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42898</th>\n",
       "      <td>72727</td>\n",
       "      <td>neg</td>\n",
       "      <td>39910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>291494</td>\n",
       "      <td>110406</td>\n",
       "      <td>265298</td>\n",
       "      <td>254714</td>\n",
       "      <td>232414</td>\n",
       "      <td>182932</td>\n",
       "      <td>309914</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23114</th>\n",
       "      <td>60535</td>\n",
       "      <td>neg</td>\n",
       "      <td>43614</td>\n",
       "      <td>NaN</td>\n",
       "      <td>152</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>314196</td>\n",
       "      <td>146948</td>\n",
       "      <td>297180</td>\n",
       "      <td>274392</td>\n",
       "      <td>247178</td>\n",
       "      <td>193972</td>\n",
       "      <td>320904</td>\n",
       "      <td>43452</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2962</th>\n",
       "      <td>58060</td>\n",
       "      <td>neg</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>578</td>\n",
       "      <td>190</td>\n",
       "      <td>468</td>\n",
       "      <td>732</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45204</th>\n",
       "      <td>57687</td>\n",
       "      <td>neg</td>\n",
       "      <td>38938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>460</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>459428</td>\n",
       "      <td>220256</td>\n",
       "      <td>413674</td>\n",
       "      <td>334330</td>\n",
       "      <td>196244</td>\n",
       "      <td>92842</td>\n",
       "      <td>57548</td>\n",
       "      <td>268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0 class  aa_000 ab_000 ac_000 ad_000 ae_000 af_000 ag_000  \\\n",
       "36627       58126   neg   46976      0    128    124      0      0      0   \n",
       "42898       72727   neg   39910    NaN     70     66      0      0      0   \n",
       "23114       60535   neg   43614    NaN    152    144      0      0      0   \n",
       "2962        58060   neg      60    NaN      0    NaN      0      0      0   \n",
       "45204       57687   neg   38938    NaN    460    150      0      0      0   \n",
       "\n",
       "      ag_001  ...  ee_002  ee_003  ee_004  ee_005   ee_006  ee_007  ee_008  \\\n",
       "36627      0  ...  176578   80224  141948  164404  1438208   32222     520   \n",
       "42898      0  ...  291494  110406  265298  254714   232414  182932  309914   \n",
       "23114      0  ...  314196  146948  297180  274392   247178  193972  320904   \n",
       "2962       0  ...     578     190     468     732      138       0       0   \n",
       "45204      0  ...  459428  220256  413674  334330   196244   92842   57548   \n",
       "\n",
       "      ee_009 ef_000 eg_000  \n",
       "36627      0      0      0  \n",
       "42898    264      0      0  \n",
       "23114  43452      0      0  \n",
       "2962       0      0      0  \n",
       "45204    268      0      0  \n",
       "\n",
       "[5 rows x 172 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ab_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>ag_002</th>\n",
       "      <th>ag_003</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46976</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>176578</td>\n",
       "      <td>80224</td>\n",
       "      <td>141948</td>\n",
       "      <td>164404</td>\n",
       "      <td>1438208</td>\n",
       "      <td>32222</td>\n",
       "      <td>520</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39910</td>\n",
       "      <td>-1</td>\n",
       "      <td>70</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>291494</td>\n",
       "      <td>110406</td>\n",
       "      <td>265298</td>\n",
       "      <td>254714</td>\n",
       "      <td>232414</td>\n",
       "      <td>182932</td>\n",
       "      <td>309914</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43614</td>\n",
       "      <td>-1</td>\n",
       "      <td>152</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>314196</td>\n",
       "      <td>146948</td>\n",
       "      <td>297180</td>\n",
       "      <td>274392</td>\n",
       "      <td>247178</td>\n",
       "      <td>193972</td>\n",
       "      <td>320904</td>\n",
       "      <td>43452</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>578</td>\n",
       "      <td>190</td>\n",
       "      <td>468</td>\n",
       "      <td>732</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38938</td>\n",
       "      <td>-1</td>\n",
       "      <td>460</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>459428</td>\n",
       "      <td>220256</td>\n",
       "      <td>413674</td>\n",
       "      <td>334330</td>\n",
       "      <td>196244</td>\n",
       "      <td>92842</td>\n",
       "      <td>57548</td>\n",
       "      <td>268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45595</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>286</td>\n",
       "      <td>68</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45596</th>\n",
       "      <td>42980</td>\n",
       "      <td>-1</td>\n",
       "      <td>166</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>259926</td>\n",
       "      <td>134328</td>\n",
       "      <td>413012</td>\n",
       "      <td>1089582</td>\n",
       "      <td>25206</td>\n",
       "      <td>18984</td>\n",
       "      <td>14104</td>\n",
       "      <td>1472</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45597</th>\n",
       "      <td>37912</td>\n",
       "      <td>-1</td>\n",
       "      <td>2130706432</td>\n",
       "      <td>1530</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>800648</td>\n",
       "      <td>312142</td>\n",
       "      <td>392076</td>\n",
       "      <td>168164</td>\n",
       "      <td>63434</td>\n",
       "      <td>25862</td>\n",
       "      <td>22036</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45598</th>\n",
       "      <td>33856</td>\n",
       "      <td>-1</td>\n",
       "      <td>1318</td>\n",
       "      <td>1174</td>\n",
       "      <td>192</td>\n",
       "      <td>330</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>409354</td>\n",
       "      <td>477122</td>\n",
       "      <td>142826</td>\n",
       "      <td>110344</td>\n",
       "      <td>488910</td>\n",
       "      <td>2668</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45599</th>\n",
       "      <td>29074</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>299858</td>\n",
       "      <td>167420</td>\n",
       "      <td>413110</td>\n",
       "      <td>332716</td>\n",
       "      <td>108034</td>\n",
       "      <td>28990</td>\n",
       "      <td>7872</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45600 rows × 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aa_000 ab_000      ac_000 ad_000 ae_000 af_000 ag_000 ag_001 ag_002  \\\n",
       "0       46976      0         128    124      0      0      0      0      0   \n",
       "1       39910     -1          70     66      0      0      0      0      0   \n",
       "2       43614     -1         152    144      0      0      0      0      0   \n",
       "3          60     -1           0     -1      0      0      0      0      0   \n",
       "4       38938     -1         460    150      0      0      0      0      0   \n",
       "...       ...    ...         ...    ...    ...    ...    ...    ...    ...   \n",
       "45595      16      0          34      6      0      0      0      0      0   \n",
       "45596   42980     -1         166    128      0      0      0      0      0   \n",
       "45597   37912     -1  2130706432   1530      0      0      0      0      0   \n",
       "45598   33856     -1        1318   1174    192    330      0      0      0   \n",
       "45599   29074     -1           0     -1      0      0      0      0      0   \n",
       "\n",
       "      ag_003  ...  ee_002  ee_003  ee_004   ee_005   ee_006  ee_007  ee_008  \\\n",
       "0          0  ...  176578   80224  141948   164404  1438208   32222     520   \n",
       "1          0  ...  291494  110406  265298   254714   232414  182932  309914   \n",
       "2          0  ...  314196  146948  297180   274392   247178  193972  320904   \n",
       "3          0  ...     578     190     468      732      138       0       0   \n",
       "4          0  ...  459428  220256  413674   334330   196244   92842   57548   \n",
       "...      ...  ...     ...     ...     ...      ...      ...     ...     ...   \n",
       "45595      0  ...     286      68      34        0        0       0       0   \n",
       "45596      0  ...  259926  134328  413012  1089582    25206   18984   14104   \n",
       "45597      0  ...  800648  312142  392076   168164    63434   25862   22036   \n",
       "45598      0  ...  409354  477122  142826   110344   488910    2668     160   \n",
       "45599      0  ...  299858  167420  413110   332716   108034   28990    7872   \n",
       "\n",
       "      ee_009 ef_000 eg_000  \n",
       "0          0      0      0  \n",
       "1        264      0      0  \n",
       "2      43452      0      0  \n",
       "3          0      0      0  \n",
       "4        268      0      0  \n",
       "...      ...    ...    ...  \n",
       "45595      0      0      0  \n",
       "45596   1472      0      0  \n",
       "45597     24      0      0  \n",
       "45598      0      0      6  \n",
       "45599      0      0      0  \n",
       "\n",
       "[45600 rows x 170 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.replace(np.nan, -1) #결측치에 -1 대입\n",
    "X_train01=X_train.drop(['Unnamed: 0', 'class'], axis=1)\n",
    "X_train01.reset_index(drop=True, inplace=True)\n",
    "X_train01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aa_000     int64\n",
       "ab_000    object\n",
       "ac_000    object\n",
       "ad_000    object\n",
       "ae_000    object\n",
       "           ...  \n",
       "ee_007    object\n",
       "ee_008    object\n",
       "ee_009    object\n",
       "ef_000    object\n",
       "eg_000    object\n",
       "Length: 170, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train01.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aa_000    float64\n",
       "ab_000    float64\n",
       "ac_000    float64\n",
       "ad_000    float64\n",
       "ae_000    float64\n",
       "           ...   \n",
       "ee_007    float64\n",
       "ee_008    float64\n",
       "ee_009    float64\n",
       "ef_000    float64\n",
       "eg_000    float64\n",
       "Length: 170, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train01=X_train01.astype(float)\n",
    "X_train01.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36627    neg\n",
       "42898    neg\n",
       "23114    neg\n",
       "2962     neg\n",
       "45204    neg\n",
       "        ... \n",
       "22448    neg\n",
       "5638     neg\n",
       "32020    neg\n",
       "9030     neg\n",
       "50505    neg\n",
       "Name: class, Length: 45600, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling, counts of label '1': 853\n",
      "Before OverSampling, counts of label '0': 44747 \n",
      "\n",
      "After OverSampling, the shape of train_X: (89494, 170)\n",
      "After OverSampling, the shape of train_y: (89494,) \n",
      "\n",
      "After OverSampling, counts of label '1': 44747\n",
      "After OverSampling, counts of label '0': 44747\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train==\"pos\")))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train==\"neg\")))\n",
    "\n",
    "sm = SMOTE(random_state=2)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train01, y_train)\n",
    "\n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res==\"pos\")))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res==\"neg\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ab_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>ag_002</th>\n",
       "      <th>ag_003</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39034</td>\n",
       "      <td>-1</td>\n",
       "      <td>132</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>154734</td>\n",
       "      <td>69690</td>\n",
       "      <td>165178</td>\n",
       "      <td>133902</td>\n",
       "      <td>443552</td>\n",
       "      <td>691076</td>\n",
       "      <td>6636</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>349286</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>26204</td>\n",
       "      <td>735690</td>\n",
       "      <td>6638176</td>\n",
       "      <td>...</td>\n",
       "      <td>5012822</td>\n",
       "      <td>1532928</td>\n",
       "      <td>3381640</td>\n",
       "      <td>4543016</td>\n",
       "      <td>655000</td>\n",
       "      <td>207038</td>\n",
       "      <td>3480</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32400</td>\n",
       "      <td>-1</td>\n",
       "      <td>714</td>\n",
       "      <td>626</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>320846</td>\n",
       "      <td>168344</td>\n",
       "      <td>408888</td>\n",
       "      <td>330388</td>\n",
       "      <td>153806</td>\n",
       "      <td>65222</td>\n",
       "      <td>52630</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>378224</td>\n",
       "      <td>-1</td>\n",
       "      <td>36</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>53412</td>\n",
       "      <td>24186</td>\n",
       "      <td>43278</td>\n",
       "      <td>37390</td>\n",
       "      <td>48242</td>\n",
       "      <td>293878</td>\n",
       "      <td>30980</td>\n",
       "      <td>194</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61174</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>417030</td>\n",
       "      <td>213806</td>\n",
       "      <td>466264</td>\n",
       "      <td>560570</td>\n",
       "      <td>527686</td>\n",
       "      <td>293296</td>\n",
       "      <td>224894</td>\n",
       "      <td>2752</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11395</th>\n",
       "      <td>30818</td>\n",
       "      <td>-1</td>\n",
       "      <td>774</td>\n",
       "      <td>624</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>211896</td>\n",
       "      <td>112548</td>\n",
       "      <td>248956</td>\n",
       "      <td>304754</td>\n",
       "      <td>343216</td>\n",
       "      <td>141470</td>\n",
       "      <td>14940</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11396</th>\n",
       "      <td>62496</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>709166</td>\n",
       "      <td>295914</td>\n",
       "      <td>490402</td>\n",
       "      <td>396500</td>\n",
       "      <td>268468</td>\n",
       "      <td>169826</td>\n",
       "      <td>334658</td>\n",
       "      <td>22344</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11397</th>\n",
       "      <td>175162</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1639368</td>\n",
       "      <td>1118648</td>\n",
       "      <td>2449552</td>\n",
       "      <td>1915304</td>\n",
       "      <td>774144</td>\n",
       "      <td>245922</td>\n",
       "      <td>127348</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11398</th>\n",
       "      <td>63624</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>601960</td>\n",
       "      <td>226666</td>\n",
       "      <td>554386</td>\n",
       "      <td>941358</td>\n",
       "      <td>55188</td>\n",
       "      <td>55874</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11399</th>\n",
       "      <td>1032510</td>\n",
       "      <td>2</td>\n",
       "      <td>7492</td>\n",
       "      <td>1102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7212</td>\n",
       "      <td>303376</td>\n",
       "      <td>2266780</td>\n",
       "      <td>12425434</td>\n",
       "      <td>...</td>\n",
       "      <td>9383928</td>\n",
       "      <td>3999510</td>\n",
       "      <td>7595646</td>\n",
       "      <td>14600942</td>\n",
       "      <td>9247210</td>\n",
       "      <td>2594440</td>\n",
       "      <td>148896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11400 rows × 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        aa_000 ab_000 ac_000 ad_000 ae_000 af_000 ag_000  ag_001   ag_002  \\\n",
       "0        39034     -1    132    108      0      0      0       0        0   \n",
       "1       349286     -1     -1     -1     -1     -1      0   26204   735690   \n",
       "2        32400     -1    714    626      0      0      0       0        0   \n",
       "3       378224     -1     36     16      0      0      0       0        0   \n",
       "4        61174     -1      0     -1      0      0      0       0        0   \n",
       "...        ...    ...    ...    ...    ...    ...    ...     ...      ...   \n",
       "11395    30818     -1    774    624      0      0      0       0        0   \n",
       "11396    62496     -1      0     -1      0      0      0       0        0   \n",
       "11397   175162     -1      0     -1      0      0      0       0        0   \n",
       "11398    63624      0     20     20      0      0      0       0        0   \n",
       "11399  1032510      2   7492   1102      0      0   7212  303376  2266780   \n",
       "\n",
       "         ag_003  ...   ee_002   ee_003   ee_004    ee_005   ee_006   ee_007  \\\n",
       "0             0  ...   154734    69690   165178    133902   443552   691076   \n",
       "1       6638176  ...  5012822  1532928  3381640   4543016   655000   207038   \n",
       "2             0  ...   320846   168344   408888    330388   153806    65222   \n",
       "3             0  ...    53412    24186    43278     37390    48242   293878   \n",
       "4             0  ...   417030   213806   466264    560570   527686   293296   \n",
       "...         ...  ...      ...      ...      ...       ...      ...      ...   \n",
       "11395         0  ...   211896   112548   248956    304754   343216   141470   \n",
       "11396         0  ...   709166   295914   490402    396500   268468   169826   \n",
       "11397         0  ...  1639368  1118648  2449552   1915304   774144   245922   \n",
       "11398         0  ...   601960   226666   554386    941358    55188    55874   \n",
       "11399  12425434  ...  9383928  3999510  7595646  14600942  9247210  2594440   \n",
       "\n",
       "       ee_008 ee_009 ef_000 eg_000  \n",
       "0        6636      0      0      0  \n",
       "1        3480      0     -1     -1  \n",
       "2       52630     32      0      0  \n",
       "3       30980    194      0      0  \n",
       "4      224894   2752      0      0  \n",
       "...       ...    ...    ...    ...  \n",
       "11395   14940      0      0      0  \n",
       "11396  334658  22344      0      0  \n",
       "11397  127348     58      0      0  \n",
       "11398     108      0      0      0  \n",
       "11399  148896      0      0      0  \n",
       "\n",
       "[11400 rows x 170 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val = X_val.replace(np.nan, -1)\n",
    "X_val01=X_val.drop(['Unnamed: 0', 'class'], axis=1)\n",
    "X_val01.reset_index(drop=True, inplace=True)\n",
    "X_val01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aa_000    float64\n",
      "ab_000    float64\n",
      "ac_000    float64\n",
      "ad_000    float64\n",
      "ae_000    float64\n",
      "           ...   \n",
      "ee_007    float64\n",
      "ee_008    float64\n",
      "ee_009    float64\n",
      "ef_000    float64\n",
      "eg_000    float64\n",
      "Length: 170, dtype: object\n"
     ]
    }
   ],
   "source": [
    "X_val01=X_val01.astype(float)\n",
    "print(X_val01.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_jobs=4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_jobs=4)\n",
    "rf.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    11159\n",
       "pos      241\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = rf.predict(X_val01)\n",
    "pd.Series(result).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.7621145374449338\n",
      "accuracy score: 0.9905263157894737\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "print('f1 score:', f1_score(y_val.replace({'neg': 0, 'pos' : 1}), pd.Series(result).replace({'neg': 0, 'pos' : 1})))\n",
    "print('accuracy score:', accuracy_score(y_val.replace({'neg': 0, 'pos' : 1}), pd.Series(result).replace({'neg': 0, 'pos' : 1})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'predicted':result, 'true':y_val})\n",
    "df1.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest 총 비용 : $ 20680\n",
      "positive를 negative로 분류 : $ 20000\n",
      "negative를 positive로 분류 : $ 680\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "j= 0\n",
    "false_neg = 0\n",
    "false_pos = 0\n",
    "\n",
    "for predicted, true in df1.values:\n",
    "    if predicted != true: #예측이 틀렸을 때\n",
    "        if true == 'neg': \n",
    "            i = i+10\n",
    "            false_pos = false_pos+1\n",
    "        else :\n",
    "            j = j+500\n",
    "            false_neg = false_neg+1\n",
    "            \n",
    "print('RandomForest 총 비용 :','$',i+j)\n",
    "print('positive를 negative로 분류 :', '$',false_neg*500)\n",
    "print('negative를 positive로 분류 :', '$', false_pos*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.070202\n",
      "0:\tlearn: 0.5707008\ttotal: 190ms\tremaining: 3m 9s\n",
      "1:\tlearn: 0.4675095\ttotal: 299ms\tremaining: 2m 29s\n",
      "2:\tlearn: 0.3939426\ttotal: 413ms\tremaining: 2m 17s\n",
      "3:\tlearn: 0.3311132\ttotal: 516ms\tremaining: 2m 8s\n",
      "4:\tlearn: 0.2797918\ttotal: 608ms\tremaining: 2m 1s\n",
      "5:\tlearn: 0.2444688\ttotal: 711ms\tremaining: 1m 57s\n",
      "6:\tlearn: 0.2152931\ttotal: 791ms\tremaining: 1m 52s\n",
      "7:\tlearn: 0.1924672\ttotal: 884ms\tremaining: 1m 49s\n",
      "8:\tlearn: 0.1743603\ttotal: 988ms\tremaining: 1m 48s\n",
      "9:\tlearn: 0.1579811\ttotal: 1.08s\tremaining: 1m 47s\n",
      "10:\tlearn: 0.1451951\ttotal: 1.16s\tremaining: 1m 44s\n",
      "11:\tlearn: 0.1342870\ttotal: 1.27s\tremaining: 1m 44s\n",
      "12:\tlearn: 0.1253864\ttotal: 1.37s\tremaining: 1m 44s\n",
      "13:\tlearn: 0.1179149\ttotal: 1.47s\tremaining: 1m 43s\n",
      "14:\tlearn: 0.1116066\ttotal: 1.57s\tremaining: 1m 42s\n",
      "15:\tlearn: 0.1060922\ttotal: 1.67s\tremaining: 1m 42s\n",
      "16:\tlearn: 0.1010870\ttotal: 1.76s\tremaining: 1m 41s\n",
      "17:\tlearn: 0.0972468\ttotal: 1.86s\tremaining: 1m 41s\n",
      "18:\tlearn: 0.0934360\ttotal: 1.96s\tremaining: 1m 41s\n",
      "19:\tlearn: 0.0905174\ttotal: 2.06s\tremaining: 1m 41s\n",
      "20:\tlearn: 0.0852296\ttotal: 2.17s\tremaining: 1m 41s\n",
      "21:\tlearn: 0.0822878\ttotal: 2.28s\tremaining: 1m 41s\n",
      "22:\tlearn: 0.0798026\ttotal: 2.38s\tremaining: 1m 41s\n",
      "23:\tlearn: 0.0758724\ttotal: 2.5s\tremaining: 1m 41s\n",
      "24:\tlearn: 0.0725820\ttotal: 2.63s\tremaining: 1m 42s\n",
      "25:\tlearn: 0.0710684\ttotal: 2.74s\tremaining: 1m 42s\n",
      "26:\tlearn: 0.0700604\ttotal: 2.84s\tremaining: 1m 42s\n",
      "27:\tlearn: 0.0691197\ttotal: 2.95s\tremaining: 1m 42s\n",
      "28:\tlearn: 0.0676906\ttotal: 3.04s\tremaining: 1m 41s\n",
      "29:\tlearn: 0.0657655\ttotal: 3.13s\tremaining: 1m 41s\n",
      "30:\tlearn: 0.0634840\ttotal: 3.23s\tremaining: 1m 40s\n",
      "31:\tlearn: 0.0618822\ttotal: 3.33s\tremaining: 1m 40s\n",
      "32:\tlearn: 0.0609359\ttotal: 3.41s\tremaining: 1m 39s\n",
      "33:\tlearn: 0.0600811\ttotal: 3.49s\tremaining: 1m 39s\n",
      "34:\tlearn: 0.0592110\ttotal: 3.59s\tremaining: 1m 38s\n",
      "35:\tlearn: 0.0583411\ttotal: 3.67s\tremaining: 1m 38s\n",
      "36:\tlearn: 0.0574255\ttotal: 3.76s\tremaining: 1m 37s\n",
      "37:\tlearn: 0.0564511\ttotal: 3.86s\tremaining: 1m 37s\n",
      "38:\tlearn: 0.0554830\ttotal: 3.96s\tremaining: 1m 37s\n",
      "39:\tlearn: 0.0548584\ttotal: 4.04s\tremaining: 1m 36s\n",
      "40:\tlearn: 0.0540035\ttotal: 4.13s\tremaining: 1m 36s\n",
      "41:\tlearn: 0.0534332\ttotal: 4.23s\tremaining: 1m 36s\n",
      "42:\tlearn: 0.0526751\ttotal: 4.32s\tremaining: 1m 36s\n",
      "43:\tlearn: 0.0519192\ttotal: 4.41s\tremaining: 1m 35s\n",
      "44:\tlearn: 0.0512374\ttotal: 4.51s\tremaining: 1m 35s\n",
      "45:\tlearn: 0.0495047\ttotal: 4.6s\tremaining: 1m 35s\n",
      "46:\tlearn: 0.0489252\ttotal: 4.7s\tremaining: 1m 35s\n",
      "47:\tlearn: 0.0479078\ttotal: 4.82s\tremaining: 1m 35s\n",
      "48:\tlearn: 0.0473656\ttotal: 4.92s\tremaining: 1m 35s\n",
      "49:\tlearn: 0.0468486\ttotal: 5s\tremaining: 1m 35s\n",
      "50:\tlearn: 0.0464977\ttotal: 5.08s\tremaining: 1m 34s\n",
      "51:\tlearn: 0.0457132\ttotal: 5.17s\tremaining: 1m 34s\n",
      "52:\tlearn: 0.0452123\ttotal: 5.26s\tremaining: 1m 33s\n",
      "53:\tlearn: 0.0449372\ttotal: 5.33s\tremaining: 1m 33s\n",
      "54:\tlearn: 0.0445454\ttotal: 5.41s\tremaining: 1m 32s\n",
      "55:\tlearn: 0.0437660\ttotal: 5.5s\tremaining: 1m 32s\n",
      "56:\tlearn: 0.0435094\ttotal: 5.57s\tremaining: 1m 32s\n",
      "57:\tlearn: 0.0431490\ttotal: 5.66s\tremaining: 1m 31s\n",
      "58:\tlearn: 0.0427338\ttotal: 5.77s\tremaining: 1m 31s\n",
      "59:\tlearn: 0.0422811\ttotal: 5.85s\tremaining: 1m 31s\n",
      "60:\tlearn: 0.0418657\ttotal: 5.93s\tremaining: 1m 31s\n",
      "61:\tlearn: 0.0414663\ttotal: 6.03s\tremaining: 1m 31s\n",
      "62:\tlearn: 0.0408939\ttotal: 6.12s\tremaining: 1m 30s\n",
      "63:\tlearn: 0.0404410\ttotal: 6.2s\tremaining: 1m 30s\n",
      "64:\tlearn: 0.0401977\ttotal: 6.3s\tremaining: 1m 30s\n",
      "65:\tlearn: 0.0397392\ttotal: 6.38s\tremaining: 1m 30s\n",
      "66:\tlearn: 0.0395174\ttotal: 6.46s\tremaining: 1m 29s\n",
      "67:\tlearn: 0.0390475\ttotal: 6.55s\tremaining: 1m 29s\n",
      "68:\tlearn: 0.0387362\ttotal: 6.63s\tremaining: 1m 29s\n",
      "69:\tlearn: 0.0383176\ttotal: 6.72s\tremaining: 1m 29s\n",
      "70:\tlearn: 0.0380660\ttotal: 6.82s\tremaining: 1m 29s\n",
      "71:\tlearn: 0.0376016\ttotal: 6.91s\tremaining: 1m 29s\n",
      "72:\tlearn: 0.0371628\ttotal: 7s\tremaining: 1m 28s\n",
      "73:\tlearn: 0.0365607\ttotal: 7.08s\tremaining: 1m 28s\n",
      "74:\tlearn: 0.0362724\ttotal: 7.18s\tremaining: 1m 28s\n",
      "75:\tlearn: 0.0361255\ttotal: 7.28s\tremaining: 1m 28s\n",
      "76:\tlearn: 0.0358925\ttotal: 7.37s\tremaining: 1m 28s\n",
      "77:\tlearn: 0.0355575\ttotal: 7.46s\tremaining: 1m 28s\n",
      "78:\tlearn: 0.0354399\ttotal: 7.53s\tremaining: 1m 27s\n",
      "79:\tlearn: 0.0351820\ttotal: 7.61s\tremaining: 1m 27s\n",
      "80:\tlearn: 0.0349025\ttotal: 7.69s\tremaining: 1m 27s\n",
      "81:\tlearn: 0.0346401\ttotal: 7.78s\tremaining: 1m 27s\n",
      "82:\tlearn: 0.0344113\ttotal: 7.86s\tremaining: 1m 26s\n",
      "83:\tlearn: 0.0341992\ttotal: 7.95s\tremaining: 1m 26s\n",
      "84:\tlearn: 0.0339091\ttotal: 8.03s\tremaining: 1m 26s\n",
      "85:\tlearn: 0.0335880\ttotal: 8.12s\tremaining: 1m 26s\n",
      "86:\tlearn: 0.0333941\ttotal: 8.22s\tremaining: 1m 26s\n",
      "87:\tlearn: 0.0331407\ttotal: 8.31s\tremaining: 1m 26s\n",
      "88:\tlearn: 0.0330606\ttotal: 8.4s\tremaining: 1m 25s\n",
      "89:\tlearn: 0.0328808\ttotal: 8.48s\tremaining: 1m 25s\n",
      "90:\tlearn: 0.0325775\ttotal: 8.56s\tremaining: 1m 25s\n",
      "91:\tlearn: 0.0324398\ttotal: 8.64s\tremaining: 1m 25s\n",
      "92:\tlearn: 0.0322812\ttotal: 8.73s\tremaining: 1m 25s\n",
      "93:\tlearn: 0.0320302\ttotal: 8.83s\tremaining: 1m 25s\n",
      "94:\tlearn: 0.0318458\ttotal: 8.91s\tremaining: 1m 24s\n",
      "95:\tlearn: 0.0316791\ttotal: 9s\tremaining: 1m 24s\n",
      "96:\tlearn: 0.0310920\ttotal: 9.08s\tremaining: 1m 24s\n",
      "97:\tlearn: 0.0308277\ttotal: 9.16s\tremaining: 1m 24s\n",
      "98:\tlearn: 0.0306165\ttotal: 9.25s\tremaining: 1m 24s\n",
      "99:\tlearn: 0.0304781\ttotal: 9.34s\tremaining: 1m 24s\n",
      "100:\tlearn: 0.0303625\ttotal: 9.4s\tremaining: 1m 23s\n",
      "101:\tlearn: 0.0302200\ttotal: 9.49s\tremaining: 1m 23s\n",
      "102:\tlearn: 0.0298699\ttotal: 9.61s\tremaining: 1m 23s\n",
      "103:\tlearn: 0.0294846\ttotal: 9.72s\tremaining: 1m 23s\n",
      "104:\tlearn: 0.0293403\ttotal: 9.79s\tremaining: 1m 23s\n",
      "105:\tlearn: 0.0292211\ttotal: 9.88s\tremaining: 1m 23s\n",
      "106:\tlearn: 0.0289616\ttotal: 9.97s\tremaining: 1m 23s\n",
      "107:\tlearn: 0.0287192\ttotal: 10.1s\tremaining: 1m 23s\n",
      "108:\tlearn: 0.0285153\ttotal: 10.1s\tremaining: 1m 22s\n",
      "109:\tlearn: 0.0283019\ttotal: 10.2s\tremaining: 1m 22s\n",
      "110:\tlearn: 0.0281658\ttotal: 10.3s\tremaining: 1m 22s\n",
      "111:\tlearn: 0.0279488\ttotal: 10.4s\tremaining: 1m 22s\n",
      "112:\tlearn: 0.0277968\ttotal: 10.5s\tremaining: 1m 22s\n",
      "113:\tlearn: 0.0275703\ttotal: 10.6s\tremaining: 1m 22s\n",
      "114:\tlearn: 0.0274206\ttotal: 10.7s\tremaining: 1m 21s\n",
      "115:\tlearn: 0.0271891\ttotal: 10.7s\tremaining: 1m 21s\n",
      "116:\tlearn: 0.0267060\ttotal: 10.8s\tremaining: 1m 21s\n",
      "117:\tlearn: 0.0265840\ttotal: 10.9s\tremaining: 1m 21s\n",
      "118:\tlearn: 0.0264817\ttotal: 11s\tremaining: 1m 21s\n",
      "119:\tlearn: 0.0262976\ttotal: 11.1s\tremaining: 1m 21s\n",
      "120:\tlearn: 0.0261763\ttotal: 11.2s\tremaining: 1m 21s\n",
      "121:\tlearn: 0.0259831\ttotal: 11.3s\tremaining: 1m 20s\n",
      "122:\tlearn: 0.0258433\ttotal: 11.3s\tremaining: 1m 20s\n",
      "123:\tlearn: 0.0256143\ttotal: 11.4s\tremaining: 1m 20s\n",
      "124:\tlearn: 0.0255202\ttotal: 11.5s\tremaining: 1m 20s\n",
      "125:\tlearn: 0.0253955\ttotal: 11.6s\tremaining: 1m 20s\n",
      "126:\tlearn: 0.0252638\ttotal: 11.7s\tremaining: 1m 20s\n",
      "127:\tlearn: 0.0250061\ttotal: 11.8s\tremaining: 1m 20s\n",
      "128:\tlearn: 0.0248834\ttotal: 11.9s\tremaining: 1m 20s\n",
      "129:\tlearn: 0.0245746\ttotal: 12s\tremaining: 1m 20s\n",
      "130:\tlearn: 0.0244297\ttotal: 12s\tremaining: 1m 19s\n",
      "131:\tlearn: 0.0243758\ttotal: 12.1s\tremaining: 1m 19s\n",
      "132:\tlearn: 0.0242552\ttotal: 12.2s\tremaining: 1m 19s\n",
      "133:\tlearn: 0.0241964\ttotal: 12.3s\tremaining: 1m 19s\n",
      "134:\tlearn: 0.0240715\ttotal: 12.4s\tremaining: 1m 19s\n",
      "135:\tlearn: 0.0237739\ttotal: 12.5s\tremaining: 1m 19s\n",
      "136:\tlearn: 0.0235592\ttotal: 12.6s\tremaining: 1m 19s\n",
      "137:\tlearn: 0.0234184\ttotal: 12.6s\tremaining: 1m 18s\n",
      "138:\tlearn: 0.0233692\ttotal: 12.7s\tremaining: 1m 18s\n",
      "139:\tlearn: 0.0232844\ttotal: 12.8s\tremaining: 1m 18s\n",
      "140:\tlearn: 0.0231999\ttotal: 12.9s\tremaining: 1m 18s\n",
      "141:\tlearn: 0.0229292\ttotal: 13s\tremaining: 1m 18s\n",
      "142:\tlearn: 0.0227747\ttotal: 13s\tremaining: 1m 18s\n",
      "143:\tlearn: 0.0226784\ttotal: 13.1s\tremaining: 1m 18s\n",
      "144:\tlearn: 0.0226042\ttotal: 13.2s\tremaining: 1m 17s\n",
      "145:\tlearn: 0.0225596\ttotal: 13.3s\tremaining: 1m 17s\n",
      "146:\tlearn: 0.0224421\ttotal: 13.4s\tremaining: 1m 17s\n",
      "147:\tlearn: 0.0223632\ttotal: 13.4s\tremaining: 1m 17s\n",
      "148:\tlearn: 0.0222372\ttotal: 13.5s\tremaining: 1m 17s\n",
      "149:\tlearn: 0.0221618\ttotal: 13.6s\tremaining: 1m 17s\n",
      "150:\tlearn: 0.0219293\ttotal: 13.7s\tremaining: 1m 16s\n",
      "151:\tlearn: 0.0218299\ttotal: 13.8s\tremaining: 1m 16s\n",
      "152:\tlearn: 0.0217195\ttotal: 13.9s\tremaining: 1m 16s\n",
      "153:\tlearn: 0.0216081\ttotal: 13.9s\tremaining: 1m 16s\n",
      "154:\tlearn: 0.0214078\ttotal: 14s\tremaining: 1m 16s\n",
      "155:\tlearn: 0.0212443\ttotal: 14.1s\tremaining: 1m 16s\n",
      "156:\tlearn: 0.0211056\ttotal: 14.2s\tremaining: 1m 16s\n",
      "157:\tlearn: 0.0209188\ttotal: 14.3s\tremaining: 1m 16s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158:\tlearn: 0.0206768\ttotal: 14.4s\tremaining: 1m 15s\n",
      "159:\tlearn: 0.0204996\ttotal: 14.5s\tremaining: 1m 15s\n",
      "160:\tlearn: 0.0204319\ttotal: 14.5s\tremaining: 1m 15s\n",
      "161:\tlearn: 0.0203024\ttotal: 14.6s\tremaining: 1m 15s\n",
      "162:\tlearn: 0.0201139\ttotal: 14.7s\tremaining: 1m 15s\n",
      "163:\tlearn: 0.0200554\ttotal: 14.8s\tremaining: 1m 15s\n",
      "164:\tlearn: 0.0200179\ttotal: 14.9s\tremaining: 1m 15s\n",
      "165:\tlearn: 0.0199508\ttotal: 14.9s\tremaining: 1m 15s\n",
      "166:\tlearn: 0.0198886\ttotal: 15s\tremaining: 1m 15s\n",
      "167:\tlearn: 0.0198518\ttotal: 15.1s\tremaining: 1m 14s\n",
      "168:\tlearn: 0.0198017\ttotal: 15.2s\tremaining: 1m 14s\n",
      "169:\tlearn: 0.0197195\ttotal: 15.3s\tremaining: 1m 14s\n",
      "170:\tlearn: 0.0196323\ttotal: 15.4s\tremaining: 1m 14s\n",
      "171:\tlearn: 0.0195208\ttotal: 15.4s\tremaining: 1m 14s\n",
      "172:\tlearn: 0.0193304\ttotal: 15.5s\tremaining: 1m 14s\n",
      "173:\tlearn: 0.0192713\ttotal: 15.6s\tremaining: 1m 14s\n",
      "174:\tlearn: 0.0191472\ttotal: 15.7s\tremaining: 1m 14s\n",
      "175:\tlearn: 0.0190090\ttotal: 15.8s\tremaining: 1m 14s\n",
      "176:\tlearn: 0.0189078\ttotal: 15.9s\tremaining: 1m 13s\n",
      "177:\tlearn: 0.0187688\ttotal: 16s\tremaining: 1m 13s\n",
      "178:\tlearn: 0.0186659\ttotal: 16.1s\tremaining: 1m 13s\n",
      "179:\tlearn: 0.0185103\ttotal: 16.2s\tremaining: 1m 13s\n",
      "180:\tlearn: 0.0184670\ttotal: 16.3s\tremaining: 1m 13s\n",
      "181:\tlearn: 0.0183352\ttotal: 16.4s\tremaining: 1m 13s\n",
      "182:\tlearn: 0.0181288\ttotal: 16.5s\tremaining: 1m 13s\n",
      "183:\tlearn: 0.0180434\ttotal: 16.6s\tremaining: 1m 13s\n",
      "184:\tlearn: 0.0180156\ttotal: 16.7s\tremaining: 1m 13s\n",
      "185:\tlearn: 0.0179685\ttotal: 16.7s\tremaining: 1m 13s\n",
      "186:\tlearn: 0.0179249\ttotal: 16.8s\tremaining: 1m 13s\n",
      "187:\tlearn: 0.0178632\ttotal: 16.9s\tremaining: 1m 13s\n",
      "188:\tlearn: 0.0178218\ttotal: 17s\tremaining: 1m 12s\n",
      "189:\tlearn: 0.0177179\ttotal: 17.1s\tremaining: 1m 12s\n",
      "190:\tlearn: 0.0175499\ttotal: 17.2s\tremaining: 1m 12s\n",
      "191:\tlearn: 0.0174102\ttotal: 17.3s\tremaining: 1m 12s\n",
      "192:\tlearn: 0.0173467\ttotal: 17.4s\tremaining: 1m 12s\n",
      "193:\tlearn: 0.0172556\ttotal: 17.4s\tremaining: 1m 12s\n",
      "194:\tlearn: 0.0171705\ttotal: 17.5s\tremaining: 1m 12s\n",
      "195:\tlearn: 0.0171381\ttotal: 17.6s\tremaining: 1m 12s\n",
      "196:\tlearn: 0.0169772\ttotal: 17.7s\tremaining: 1m 12s\n",
      "197:\tlearn: 0.0169121\ttotal: 17.8s\tremaining: 1m 12s\n",
      "198:\tlearn: 0.0168335\ttotal: 17.9s\tremaining: 1m 12s\n",
      "199:\tlearn: 0.0167688\ttotal: 18s\tremaining: 1m 11s\n",
      "200:\tlearn: 0.0167149\ttotal: 18.1s\tremaining: 1m 11s\n",
      "201:\tlearn: 0.0166317\ttotal: 18.1s\tremaining: 1m 11s\n",
      "202:\tlearn: 0.0165510\ttotal: 18.2s\tremaining: 1m 11s\n",
      "203:\tlearn: 0.0164869\ttotal: 18.3s\tremaining: 1m 11s\n",
      "204:\tlearn: 0.0163946\ttotal: 18.4s\tremaining: 1m 11s\n",
      "205:\tlearn: 0.0162209\ttotal: 18.5s\tremaining: 1m 11s\n",
      "206:\tlearn: 0.0161889\ttotal: 18.6s\tremaining: 1m 11s\n",
      "207:\tlearn: 0.0161730\ttotal: 18.7s\tremaining: 1m 11s\n",
      "208:\tlearn: 0.0160450\ttotal: 18.8s\tremaining: 1m 11s\n",
      "209:\tlearn: 0.0159906\ttotal: 18.9s\tremaining: 1m 11s\n",
      "210:\tlearn: 0.0158505\ttotal: 19s\tremaining: 1m 10s\n",
      "211:\tlearn: 0.0157989\ttotal: 19.1s\tremaining: 1m 10s\n",
      "212:\tlearn: 0.0157485\ttotal: 19.1s\tremaining: 1m 10s\n",
      "213:\tlearn: 0.0156832\ttotal: 19.2s\tremaining: 1m 10s\n",
      "214:\tlearn: 0.0156369\ttotal: 19.3s\tremaining: 1m 10s\n",
      "215:\tlearn: 0.0155630\ttotal: 19.4s\tremaining: 1m 10s\n",
      "216:\tlearn: 0.0155194\ttotal: 19.4s\tremaining: 1m 10s\n",
      "217:\tlearn: 0.0154653\ttotal: 19.5s\tremaining: 1m 10s\n",
      "218:\tlearn: 0.0154011\ttotal: 19.6s\tremaining: 1m 9s\n",
      "219:\tlearn: 0.0153750\ttotal: 19.7s\tremaining: 1m 9s\n",
      "220:\tlearn: 0.0153165\ttotal: 19.8s\tremaining: 1m 9s\n",
      "221:\tlearn: 0.0152858\ttotal: 19.8s\tremaining: 1m 9s\n",
      "222:\tlearn: 0.0151689\ttotal: 19.9s\tremaining: 1m 9s\n",
      "223:\tlearn: 0.0151213\ttotal: 20s\tremaining: 1m 9s\n",
      "224:\tlearn: 0.0150603\ttotal: 20.1s\tremaining: 1m 9s\n",
      "225:\tlearn: 0.0149473\ttotal: 20.2s\tremaining: 1m 9s\n",
      "226:\tlearn: 0.0148501\ttotal: 20.2s\tremaining: 1m 8s\n",
      "227:\tlearn: 0.0147425\ttotal: 20.3s\tremaining: 1m 8s\n",
      "228:\tlearn: 0.0146868\ttotal: 20.4s\tremaining: 1m 8s\n",
      "229:\tlearn: 0.0146558\ttotal: 20.5s\tremaining: 1m 8s\n",
      "230:\tlearn: 0.0146366\ttotal: 20.6s\tremaining: 1m 8s\n",
      "231:\tlearn: 0.0145617\ttotal: 20.6s\tremaining: 1m 8s\n",
      "232:\tlearn: 0.0144936\ttotal: 20.7s\tremaining: 1m 8s\n",
      "233:\tlearn: 0.0144405\ttotal: 20.8s\tremaining: 1m 8s\n",
      "234:\tlearn: 0.0143635\ttotal: 20.9s\tremaining: 1m 8s\n",
      "235:\tlearn: 0.0143100\ttotal: 21s\tremaining: 1m 7s\n",
      "236:\tlearn: 0.0142693\ttotal: 21.1s\tremaining: 1m 7s\n",
      "237:\tlearn: 0.0142051\ttotal: 21.2s\tremaining: 1m 7s\n",
      "238:\tlearn: 0.0141784\ttotal: 21.3s\tremaining: 1m 7s\n",
      "239:\tlearn: 0.0141121\ttotal: 21.3s\tremaining: 1m 7s\n",
      "240:\tlearn: 0.0140837\ttotal: 21.4s\tremaining: 1m 7s\n",
      "241:\tlearn: 0.0140102\ttotal: 21.5s\tremaining: 1m 7s\n",
      "242:\tlearn: 0.0139893\ttotal: 21.6s\tremaining: 1m 7s\n",
      "243:\tlearn: 0.0139219\ttotal: 21.7s\tremaining: 1m 7s\n",
      "244:\tlearn: 0.0138580\ttotal: 21.8s\tremaining: 1m 7s\n",
      "245:\tlearn: 0.0138333\ttotal: 21.9s\tremaining: 1m 7s\n",
      "246:\tlearn: 0.0137916\ttotal: 22s\tremaining: 1m 6s\n",
      "247:\tlearn: 0.0137611\ttotal: 22.1s\tremaining: 1m 6s\n",
      "248:\tlearn: 0.0137205\ttotal: 22.1s\tremaining: 1m 6s\n",
      "249:\tlearn: 0.0136695\ttotal: 22.2s\tremaining: 1m 6s\n",
      "250:\tlearn: 0.0136456\ttotal: 22.3s\tremaining: 1m 6s\n",
      "251:\tlearn: 0.0136151\ttotal: 22.4s\tremaining: 1m 6s\n",
      "252:\tlearn: 0.0135580\ttotal: 22.5s\tremaining: 1m 6s\n",
      "253:\tlearn: 0.0135058\ttotal: 22.5s\tremaining: 1m 6s\n",
      "254:\tlearn: 0.0134860\ttotal: 22.6s\tremaining: 1m 6s\n",
      "255:\tlearn: 0.0134477\ttotal: 22.7s\tremaining: 1m 6s\n",
      "256:\tlearn: 0.0134008\ttotal: 22.8s\tremaining: 1m 5s\n",
      "257:\tlearn: 0.0133703\ttotal: 22.9s\tremaining: 1m 5s\n",
      "258:\tlearn: 0.0133174\ttotal: 23s\tremaining: 1m 5s\n",
      "259:\tlearn: 0.0132668\ttotal: 23.1s\tremaining: 1m 5s\n",
      "260:\tlearn: 0.0132200\ttotal: 23.2s\tremaining: 1m 5s\n",
      "261:\tlearn: 0.0131444\ttotal: 23.3s\tremaining: 1m 5s\n",
      "262:\tlearn: 0.0131071\ttotal: 23.4s\tremaining: 1m 5s\n",
      "263:\tlearn: 0.0130706\ttotal: 23.5s\tremaining: 1m 5s\n",
      "264:\tlearn: 0.0130590\ttotal: 23.5s\tremaining: 1m 5s\n",
      "265:\tlearn: 0.0130396\ttotal: 23.6s\tremaining: 1m 5s\n",
      "266:\tlearn: 0.0130126\ttotal: 23.7s\tremaining: 1m 5s\n",
      "267:\tlearn: 0.0129787\ttotal: 23.8s\tremaining: 1m 4s\n",
      "268:\tlearn: 0.0129627\ttotal: 23.9s\tremaining: 1m 4s\n",
      "269:\tlearn: 0.0129528\ttotal: 23.9s\tremaining: 1m 4s\n",
      "270:\tlearn: 0.0128230\ttotal: 24s\tremaining: 1m 4s\n",
      "271:\tlearn: 0.0127620\ttotal: 24.1s\tremaining: 1m 4s\n",
      "272:\tlearn: 0.0126677\ttotal: 24.2s\tremaining: 1m 4s\n",
      "273:\tlearn: 0.0126092\ttotal: 24.3s\tremaining: 1m 4s\n",
      "274:\tlearn: 0.0125830\ttotal: 24.4s\tremaining: 1m 4s\n",
      "275:\tlearn: 0.0125587\ttotal: 24.5s\tremaining: 1m 4s\n",
      "276:\tlearn: 0.0124965\ttotal: 24.5s\tremaining: 1m 4s\n",
      "277:\tlearn: 0.0124449\ttotal: 24.6s\tremaining: 1m 3s\n",
      "278:\tlearn: 0.0124060\ttotal: 24.7s\tremaining: 1m 3s\n",
      "279:\tlearn: 0.0123699\ttotal: 24.8s\tremaining: 1m 3s\n",
      "280:\tlearn: 0.0122958\ttotal: 24.9s\tremaining: 1m 3s\n",
      "281:\tlearn: 0.0122676\ttotal: 25s\tremaining: 1m 3s\n",
      "282:\tlearn: 0.0122364\ttotal: 25s\tremaining: 1m 3s\n",
      "283:\tlearn: 0.0121840\ttotal: 25.1s\tremaining: 1m 3s\n",
      "284:\tlearn: 0.0121397\ttotal: 25.2s\tremaining: 1m 3s\n",
      "285:\tlearn: 0.0121258\ttotal: 25.3s\tremaining: 1m 3s\n",
      "286:\tlearn: 0.0121116\ttotal: 25.4s\tremaining: 1m 3s\n",
      "287:\tlearn: 0.0120759\ttotal: 25.5s\tremaining: 1m 2s\n",
      "288:\tlearn: 0.0118940\ttotal: 25.5s\tremaining: 1m 2s\n",
      "289:\tlearn: 0.0118629\ttotal: 25.6s\tremaining: 1m 2s\n",
      "290:\tlearn: 0.0118118\ttotal: 25.7s\tremaining: 1m 2s\n",
      "291:\tlearn: 0.0117420\ttotal: 25.8s\tremaining: 1m 2s\n",
      "292:\tlearn: 0.0117285\ttotal: 25.9s\tremaining: 1m 2s\n",
      "293:\tlearn: 0.0116932\ttotal: 26s\tremaining: 1m 2s\n",
      "294:\tlearn: 0.0116717\ttotal: 26.1s\tremaining: 1m 2s\n",
      "295:\tlearn: 0.0116572\ttotal: 26.1s\tremaining: 1m 2s\n",
      "296:\tlearn: 0.0116121\ttotal: 26.2s\tremaining: 1m 2s\n",
      "297:\tlearn: 0.0115580\ttotal: 26.3s\tremaining: 1m 1s\n",
      "298:\tlearn: 0.0115328\ttotal: 26.4s\tremaining: 1m 1s\n",
      "299:\tlearn: 0.0114908\ttotal: 26.5s\tremaining: 1m 1s\n",
      "300:\tlearn: 0.0114586\ttotal: 26.6s\tremaining: 1m 1s\n",
      "301:\tlearn: 0.0114142\ttotal: 26.6s\tremaining: 1m 1s\n",
      "302:\tlearn: 0.0113782\ttotal: 26.7s\tremaining: 1m 1s\n",
      "303:\tlearn: 0.0113656\ttotal: 26.8s\tremaining: 1m 1s\n",
      "304:\tlearn: 0.0113461\ttotal: 26.9s\tremaining: 1m 1s\n",
      "305:\tlearn: 0.0113237\ttotal: 27s\tremaining: 1m 1s\n",
      "306:\tlearn: 0.0112995\ttotal: 27s\tremaining: 1m 1s\n",
      "307:\tlearn: 0.0112729\ttotal: 27.1s\tremaining: 1m\n",
      "308:\tlearn: 0.0112380\ttotal: 27.2s\tremaining: 1m\n",
      "309:\tlearn: 0.0112191\ttotal: 27.3s\tremaining: 1m\n",
      "310:\tlearn: 0.0111729\ttotal: 27.4s\tremaining: 1m\n",
      "311:\tlearn: 0.0111543\ttotal: 27.5s\tremaining: 1m\n",
      "312:\tlearn: 0.0111218\ttotal: 27.6s\tremaining: 1m\n",
      "313:\tlearn: 0.0111061\ttotal: 27.6s\tremaining: 1m\n",
      "314:\tlearn: 0.0110738\ttotal: 27.7s\tremaining: 1m\n",
      "315:\tlearn: 0.0110373\ttotal: 27.8s\tremaining: 1m\n",
      "316:\tlearn: 0.0109754\ttotal: 27.9s\tremaining: 1m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317:\tlearn: 0.0109399\ttotal: 28s\tremaining: 60s\n",
      "318:\tlearn: 0.0109013\ttotal: 28.1s\tremaining: 59.9s\n",
      "319:\tlearn: 0.0108860\ttotal: 28.1s\tremaining: 59.8s\n",
      "320:\tlearn: 0.0108446\ttotal: 28.2s\tremaining: 59.7s\n",
      "321:\tlearn: 0.0107997\ttotal: 28.3s\tremaining: 59.6s\n",
      "322:\tlearn: 0.0107832\ttotal: 28.4s\tremaining: 59.5s\n",
      "323:\tlearn: 0.0107582\ttotal: 28.5s\tremaining: 59.4s\n",
      "324:\tlearn: 0.0106848\ttotal: 28.6s\tremaining: 59.3s\n",
      "325:\tlearn: 0.0106377\ttotal: 28.7s\tremaining: 59.2s\n",
      "326:\tlearn: 0.0106079\ttotal: 28.7s\tremaining: 59.1s\n",
      "327:\tlearn: 0.0105885\ttotal: 28.8s\tremaining: 59s\n",
      "328:\tlearn: 0.0105650\ttotal: 28.9s\tremaining: 58.9s\n",
      "329:\tlearn: 0.0105503\ttotal: 29s\tremaining: 58.8s\n",
      "330:\tlearn: 0.0105288\ttotal: 29.1s\tremaining: 58.7s\n",
      "331:\tlearn: 0.0105090\ttotal: 29.1s\tremaining: 58.6s\n",
      "332:\tlearn: 0.0104976\ttotal: 29.2s\tremaining: 58.5s\n",
      "333:\tlearn: 0.0104724\ttotal: 29.3s\tremaining: 58.4s\n",
      "334:\tlearn: 0.0104383\ttotal: 29.4s\tremaining: 58.3s\n",
      "335:\tlearn: 0.0103588\ttotal: 29.5s\tremaining: 58.2s\n",
      "336:\tlearn: 0.0103193\ttotal: 29.5s\tremaining: 58.1s\n",
      "337:\tlearn: 0.0103193\ttotal: 29.6s\tremaining: 58s\n",
      "338:\tlearn: 0.0102876\ttotal: 29.7s\tremaining: 58s\n",
      "339:\tlearn: 0.0102370\ttotal: 29.9s\tremaining: 58s\n",
      "340:\tlearn: 0.0102128\ttotal: 30s\tremaining: 57.9s\n",
      "341:\tlearn: 0.0102021\ttotal: 30.1s\tremaining: 57.9s\n",
      "342:\tlearn: 0.0101767\ttotal: 30.2s\tremaining: 57.8s\n",
      "343:\tlearn: 0.0101268\ttotal: 30.3s\tremaining: 57.7s\n",
      "344:\tlearn: 0.0100987\ttotal: 30.4s\tremaining: 57.6s\n",
      "345:\tlearn: 0.0100818\ttotal: 30.4s\tremaining: 57.5s\n",
      "346:\tlearn: 0.0100817\ttotal: 30.5s\tremaining: 57.4s\n",
      "347:\tlearn: 0.0100686\ttotal: 30.6s\tremaining: 57.3s\n",
      "348:\tlearn: 0.0100685\ttotal: 30.7s\tremaining: 57.2s\n",
      "349:\tlearn: 0.0100685\ttotal: 30.7s\tremaining: 57.1s\n",
      "350:\tlearn: 0.0100685\ttotal: 30.8s\tremaining: 57s\n",
      "351:\tlearn: 0.0100685\ttotal: 30.9s\tremaining: 56.8s\n",
      "352:\tlearn: 0.0100684\ttotal: 30.9s\tremaining: 56.7s\n",
      "353:\tlearn: 0.0100684\ttotal: 31s\tremaining: 56.6s\n",
      "354:\tlearn: 0.0100684\ttotal: 31.1s\tremaining: 56.5s\n",
      "355:\tlearn: 0.0100684\ttotal: 31.2s\tremaining: 56.4s\n",
      "356:\tlearn: 0.0100682\ttotal: 31.2s\tremaining: 56.2s\n",
      "357:\tlearn: 0.0100682\ttotal: 31.3s\tremaining: 56.1s\n",
      "358:\tlearn: 0.0100682\ttotal: 31.4s\tremaining: 56s\n",
      "359:\tlearn: 0.0100682\ttotal: 31.4s\tremaining: 55.9s\n",
      "360:\tlearn: 0.0100681\ttotal: 31.5s\tremaining: 55.8s\n",
      "361:\tlearn: 0.0100681\ttotal: 31.6s\tremaining: 55.6s\n",
      "362:\tlearn: 0.0100423\ttotal: 31.7s\tremaining: 55.6s\n",
      "363:\tlearn: 0.0100237\ttotal: 31.7s\tremaining: 55.5s\n",
      "364:\tlearn: 0.0099611\ttotal: 31.8s\tremaining: 55.4s\n",
      "365:\tlearn: 0.0099364\ttotal: 31.9s\tremaining: 55.3s\n",
      "366:\tlearn: 0.0099199\ttotal: 32s\tremaining: 55.2s\n",
      "367:\tlearn: 0.0098806\ttotal: 32.1s\tremaining: 55.1s\n",
      "368:\tlearn: 0.0098567\ttotal: 32.1s\tremaining: 55s\n",
      "369:\tlearn: 0.0098310\ttotal: 32.2s\tremaining: 54.9s\n",
      "370:\tlearn: 0.0098095\ttotal: 32.3s\tremaining: 54.8s\n",
      "371:\tlearn: 0.0097746\ttotal: 32.4s\tremaining: 54.7s\n",
      "372:\tlearn: 0.0097494\ttotal: 32.5s\tremaining: 54.6s\n",
      "373:\tlearn: 0.0097069\ttotal: 32.6s\tremaining: 54.5s\n",
      "374:\tlearn: 0.0096574\ttotal: 32.6s\tremaining: 54.4s\n",
      "375:\tlearn: 0.0096425\ttotal: 32.7s\tremaining: 54.3s\n",
      "376:\tlearn: 0.0095914\ttotal: 32.8s\tremaining: 54.2s\n",
      "377:\tlearn: 0.0095539\ttotal: 32.9s\tremaining: 54.1s\n",
      "378:\tlearn: 0.0095351\ttotal: 33s\tremaining: 54s\n",
      "379:\tlearn: 0.0095001\ttotal: 33.1s\tremaining: 54s\n",
      "380:\tlearn: 0.0094675\ttotal: 33.2s\tremaining: 53.9s\n",
      "381:\tlearn: 0.0094190\ttotal: 33.3s\tremaining: 53.8s\n",
      "382:\tlearn: 0.0093657\ttotal: 33.4s\tremaining: 53.8s\n",
      "383:\tlearn: 0.0093454\ttotal: 33.4s\tremaining: 53.7s\n",
      "384:\tlearn: 0.0092890\ttotal: 33.6s\tremaining: 53.6s\n",
      "385:\tlearn: 0.0092757\ttotal: 33.6s\tremaining: 53.5s\n",
      "386:\tlearn: 0.0092757\ttotal: 33.7s\tremaining: 53.4s\n",
      "387:\tlearn: 0.0092569\ttotal: 33.8s\tremaining: 53.3s\n",
      "388:\tlearn: 0.0092195\ttotal: 33.9s\tremaining: 53.3s\n",
      "389:\tlearn: 0.0091905\ttotal: 34s\tremaining: 53.2s\n",
      "390:\tlearn: 0.0091717\ttotal: 34.1s\tremaining: 53.1s\n",
      "391:\tlearn: 0.0091406\ttotal: 34.2s\tremaining: 53s\n",
      "392:\tlearn: 0.0091022\ttotal: 34.3s\tremaining: 52.9s\n",
      "393:\tlearn: 0.0090888\ttotal: 34.4s\tremaining: 52.9s\n",
      "394:\tlearn: 0.0090791\ttotal: 34.5s\tremaining: 52.8s\n",
      "395:\tlearn: 0.0090492\ttotal: 34.5s\tremaining: 52.7s\n",
      "396:\tlearn: 0.0090383\ttotal: 34.6s\tremaining: 52.6s\n",
      "397:\tlearn: 0.0090116\ttotal: 34.7s\tremaining: 52.5s\n",
      "398:\tlearn: 0.0089672\ttotal: 34.8s\tremaining: 52.4s\n",
      "399:\tlearn: 0.0089402\ttotal: 34.9s\tremaining: 52.4s\n",
      "400:\tlearn: 0.0089284\ttotal: 35s\tremaining: 52.3s\n",
      "401:\tlearn: 0.0088973\ttotal: 35.1s\tremaining: 52.2s\n",
      "402:\tlearn: 0.0088678\ttotal: 35.2s\tremaining: 52.1s\n",
      "403:\tlearn: 0.0088300\ttotal: 35.3s\tremaining: 52s\n",
      "404:\tlearn: 0.0088103\ttotal: 35.3s\tremaining: 51.9s\n",
      "405:\tlearn: 0.0087885\ttotal: 35.4s\tremaining: 51.8s\n",
      "406:\tlearn: 0.0087685\ttotal: 35.5s\tremaining: 51.7s\n",
      "407:\tlearn: 0.0087558\ttotal: 35.6s\tremaining: 51.6s\n",
      "408:\tlearn: 0.0087438\ttotal: 35.7s\tremaining: 51.6s\n",
      "409:\tlearn: 0.0087135\ttotal: 35.8s\tremaining: 51.5s\n",
      "410:\tlearn: 0.0087010\ttotal: 35.8s\tremaining: 51.4s\n",
      "411:\tlearn: 0.0086941\ttotal: 35.9s\tremaining: 51.3s\n",
      "412:\tlearn: 0.0086574\ttotal: 36s\tremaining: 51.2s\n",
      "413:\tlearn: 0.0086394\ttotal: 36.1s\tremaining: 51.1s\n",
      "414:\tlearn: 0.0086255\ttotal: 36.2s\tremaining: 51s\n",
      "415:\tlearn: 0.0086145\ttotal: 36.3s\tremaining: 50.9s\n",
      "416:\tlearn: 0.0086144\ttotal: 36.3s\tremaining: 50.8s\n",
      "417:\tlearn: 0.0085992\ttotal: 36.4s\tremaining: 50.7s\n",
      "418:\tlearn: 0.0085560\ttotal: 36.5s\tremaining: 50.7s\n",
      "419:\tlearn: 0.0085458\ttotal: 36.6s\tremaining: 50.6s\n",
      "420:\tlearn: 0.0085400\ttotal: 36.7s\tremaining: 50.5s\n",
      "421:\tlearn: 0.0085229\ttotal: 36.8s\tremaining: 50.4s\n",
      "422:\tlearn: 0.0085004\ttotal: 36.9s\tremaining: 50.3s\n",
      "423:\tlearn: 0.0085004\ttotal: 37s\tremaining: 50.2s\n",
      "424:\tlearn: 0.0084748\ttotal: 37s\tremaining: 50.1s\n",
      "425:\tlearn: 0.0084638\ttotal: 37.1s\tremaining: 50s\n",
      "426:\tlearn: 0.0084416\ttotal: 37.2s\tremaining: 49.9s\n",
      "427:\tlearn: 0.0084345\ttotal: 37.3s\tremaining: 49.8s\n",
      "428:\tlearn: 0.0084086\ttotal: 37.4s\tremaining: 49.7s\n",
      "429:\tlearn: 0.0083930\ttotal: 37.4s\tremaining: 49.6s\n",
      "430:\tlearn: 0.0083841\ttotal: 37.5s\tremaining: 49.5s\n",
      "431:\tlearn: 0.0083596\ttotal: 37.6s\tremaining: 49.4s\n",
      "432:\tlearn: 0.0083325\ttotal: 37.7s\tremaining: 49.3s\n",
      "433:\tlearn: 0.0083117\ttotal: 37.8s\tremaining: 49.2s\n",
      "434:\tlearn: 0.0082653\ttotal: 37.8s\tremaining: 49.2s\n",
      "435:\tlearn: 0.0082388\ttotal: 37.9s\tremaining: 49.1s\n",
      "436:\tlearn: 0.0082231\ttotal: 38s\tremaining: 49s\n",
      "437:\tlearn: 0.0081995\ttotal: 38.1s\tremaining: 48.9s\n",
      "438:\tlearn: 0.0081203\ttotal: 38.2s\tremaining: 48.8s\n",
      "439:\tlearn: 0.0081076\ttotal: 38.3s\tremaining: 48.7s\n",
      "440:\tlearn: 0.0080966\ttotal: 38.3s\tremaining: 48.6s\n",
      "441:\tlearn: 0.0080828\ttotal: 38.4s\tremaining: 48.5s\n",
      "442:\tlearn: 0.0080440\ttotal: 38.5s\tremaining: 48.4s\n",
      "443:\tlearn: 0.0080147\ttotal: 38.6s\tremaining: 48.3s\n",
      "444:\tlearn: 0.0079878\ttotal: 38.7s\tremaining: 48.2s\n",
      "445:\tlearn: 0.0079833\ttotal: 38.8s\tremaining: 48.1s\n",
      "446:\tlearn: 0.0079644\ttotal: 38.8s\tremaining: 48.1s\n",
      "447:\tlearn: 0.0079359\ttotal: 38.9s\tremaining: 48s\n",
      "448:\tlearn: 0.0078985\ttotal: 39s\tremaining: 47.9s\n",
      "449:\tlearn: 0.0078707\ttotal: 39.1s\tremaining: 47.8s\n",
      "450:\tlearn: 0.0078507\ttotal: 39.2s\tremaining: 47.7s\n",
      "451:\tlearn: 0.0078260\ttotal: 39.3s\tremaining: 47.6s\n",
      "452:\tlearn: 0.0077714\ttotal: 39.4s\tremaining: 47.5s\n",
      "453:\tlearn: 0.0077490\ttotal: 39.4s\tremaining: 47.4s\n",
      "454:\tlearn: 0.0077329\ttotal: 39.5s\tremaining: 47.3s\n",
      "455:\tlearn: 0.0077182\ttotal: 39.6s\tremaining: 47.2s\n",
      "456:\tlearn: 0.0077088\ttotal: 39.7s\tremaining: 47.1s\n",
      "457:\tlearn: 0.0077088\ttotal: 39.7s\tremaining: 47s\n",
      "458:\tlearn: 0.0076913\ttotal: 39.8s\tremaining: 46.9s\n",
      "459:\tlearn: 0.0076800\ttotal: 39.9s\tremaining: 46.9s\n",
      "460:\tlearn: 0.0076630\ttotal: 40s\tremaining: 46.8s\n",
      "461:\tlearn: 0.0076380\ttotal: 40.1s\tremaining: 46.7s\n",
      "462:\tlearn: 0.0076134\ttotal: 40.2s\tremaining: 46.6s\n",
      "463:\tlearn: 0.0075911\ttotal: 40.3s\tremaining: 46.5s\n",
      "464:\tlearn: 0.0075807\ttotal: 40.3s\tremaining: 46.4s\n",
      "465:\tlearn: 0.0075580\ttotal: 40.4s\tremaining: 46.3s\n",
      "466:\tlearn: 0.0075580\ttotal: 40.5s\tremaining: 46.2s\n",
      "467:\tlearn: 0.0075580\ttotal: 40.6s\tremaining: 46.1s\n",
      "468:\tlearn: 0.0075413\ttotal: 40.7s\tremaining: 46.1s\n",
      "469:\tlearn: 0.0075255\ttotal: 40.8s\tremaining: 46s\n",
      "470:\tlearn: 0.0075117\ttotal: 40.8s\tremaining: 45.9s\n",
      "471:\tlearn: 0.0074982\ttotal: 40.9s\tremaining: 45.8s\n",
      "472:\tlearn: 0.0074982\ttotal: 41s\tremaining: 45.7s\n",
      "473:\tlearn: 0.0074729\ttotal: 41.1s\tremaining: 45.6s\n",
      "474:\tlearn: 0.0074422\ttotal: 41.2s\tremaining: 45.5s\n",
      "475:\tlearn: 0.0074308\ttotal: 41.2s\tremaining: 45.4s\n",
      "476:\tlearn: 0.0074203\ttotal: 41.3s\tremaining: 45.3s\n",
      "477:\tlearn: 0.0073932\ttotal: 41.4s\tremaining: 45.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "478:\tlearn: 0.0073815\ttotal: 41.5s\tremaining: 45.1s\n",
      "479:\tlearn: 0.0073107\ttotal: 41.6s\tremaining: 45s\n",
      "480:\tlearn: 0.0073107\ttotal: 41.6s\tremaining: 44.9s\n",
      "481:\tlearn: 0.0072958\ttotal: 41.7s\tremaining: 44.8s\n",
      "482:\tlearn: 0.0072775\ttotal: 41.8s\tremaining: 44.7s\n",
      "483:\tlearn: 0.0072775\ttotal: 41.9s\tremaining: 44.6s\n",
      "484:\tlearn: 0.0072670\ttotal: 41.9s\tremaining: 44.5s\n",
      "485:\tlearn: 0.0072554\ttotal: 42s\tremaining: 44.4s\n",
      "486:\tlearn: 0.0072348\ttotal: 42.1s\tremaining: 44.3s\n",
      "487:\tlearn: 0.0072348\ttotal: 42.2s\tremaining: 44.2s\n",
      "488:\tlearn: 0.0072348\ttotal: 42.3s\tremaining: 44.2s\n",
      "489:\tlearn: 0.0072348\ttotal: 42.3s\tremaining: 44s\n",
      "490:\tlearn: 0.0072151\ttotal: 42.4s\tremaining: 44s\n",
      "491:\tlearn: 0.0071944\ttotal: 42.5s\tremaining: 43.9s\n",
      "492:\tlearn: 0.0071697\ttotal: 42.5s\tremaining: 43.8s\n",
      "493:\tlearn: 0.0071596\ttotal: 42.6s\tremaining: 43.7s\n",
      "494:\tlearn: 0.0071596\ttotal: 42.7s\tremaining: 43.6s\n",
      "495:\tlearn: 0.0071311\ttotal: 42.8s\tremaining: 43.5s\n",
      "496:\tlearn: 0.0071263\ttotal: 42.9s\tremaining: 43.4s\n",
      "497:\tlearn: 0.0071107\ttotal: 42.9s\tremaining: 43.3s\n",
      "498:\tlearn: 0.0071011\ttotal: 43s\tremaining: 43.2s\n",
      "499:\tlearn: 0.0070910\ttotal: 43.1s\tremaining: 43.1s\n",
      "500:\tlearn: 0.0070860\ttotal: 43.2s\tremaining: 43s\n",
      "501:\tlearn: 0.0070860\ttotal: 43.2s\tremaining: 42.9s\n",
      "502:\tlearn: 0.0070859\ttotal: 43.3s\tremaining: 42.8s\n",
      "503:\tlearn: 0.0070858\ttotal: 43.4s\tremaining: 42.7s\n",
      "504:\tlearn: 0.0070858\ttotal: 43.5s\tremaining: 42.6s\n",
      "505:\tlearn: 0.0070744\ttotal: 43.6s\tremaining: 42.5s\n",
      "506:\tlearn: 0.0070621\ttotal: 43.6s\tremaining: 42.4s\n",
      "507:\tlearn: 0.0070240\ttotal: 43.7s\tremaining: 42.3s\n",
      "508:\tlearn: 0.0070045\ttotal: 43.8s\tremaining: 42.2s\n",
      "509:\tlearn: 0.0069857\ttotal: 43.9s\tremaining: 42.2s\n",
      "510:\tlearn: 0.0069762\ttotal: 44s\tremaining: 42.1s\n",
      "511:\tlearn: 0.0069515\ttotal: 44s\tremaining: 42s\n",
      "512:\tlearn: 0.0069179\ttotal: 44.1s\tremaining: 41.9s\n",
      "513:\tlearn: 0.0069097\ttotal: 44.2s\tremaining: 41.8s\n",
      "514:\tlearn: 0.0068891\ttotal: 44.3s\tremaining: 41.7s\n",
      "515:\tlearn: 0.0068720\ttotal: 44.4s\tremaining: 41.6s\n",
      "516:\tlearn: 0.0068638\ttotal: 44.5s\tremaining: 41.5s\n",
      "517:\tlearn: 0.0068638\ttotal: 44.6s\tremaining: 41.5s\n",
      "518:\tlearn: 0.0068514\ttotal: 44.6s\tremaining: 41.4s\n",
      "519:\tlearn: 0.0068278\ttotal: 44.7s\tremaining: 41.3s\n",
      "520:\tlearn: 0.0068123\ttotal: 44.8s\tremaining: 41.2s\n",
      "521:\tlearn: 0.0068035\ttotal: 44.9s\tremaining: 41.1s\n",
      "522:\tlearn: 0.0068035\ttotal: 45s\tremaining: 41s\n",
      "523:\tlearn: 0.0067914\ttotal: 45s\tremaining: 40.9s\n",
      "524:\tlearn: 0.0067767\ttotal: 45.1s\tremaining: 40.8s\n",
      "525:\tlearn: 0.0067587\ttotal: 45.2s\tremaining: 40.7s\n",
      "526:\tlearn: 0.0067423\ttotal: 45.3s\tremaining: 40.6s\n",
      "527:\tlearn: 0.0067423\ttotal: 45.4s\tremaining: 40.5s\n",
      "528:\tlearn: 0.0067423\ttotal: 45.4s\tremaining: 40.5s\n",
      "529:\tlearn: 0.0067422\ttotal: 45.5s\tremaining: 40.4s\n",
      "530:\tlearn: 0.0067422\ttotal: 45.6s\tremaining: 40.3s\n",
      "531:\tlearn: 0.0067422\ttotal: 45.6s\tremaining: 40.2s\n",
      "532:\tlearn: 0.0067422\ttotal: 45.7s\tremaining: 40.1s\n",
      "533:\tlearn: 0.0067315\ttotal: 45.8s\tremaining: 40s\n",
      "534:\tlearn: 0.0067315\ttotal: 45.9s\tremaining: 39.9s\n",
      "535:\tlearn: 0.0067315\ttotal: 45.9s\tremaining: 39.8s\n",
      "536:\tlearn: 0.0067315\ttotal: 46s\tremaining: 39.7s\n",
      "537:\tlearn: 0.0067315\ttotal: 46.1s\tremaining: 39.6s\n",
      "538:\tlearn: 0.0067315\ttotal: 46.1s\tremaining: 39.5s\n",
      "539:\tlearn: 0.0067314\ttotal: 46.2s\tremaining: 39.3s\n",
      "540:\tlearn: 0.0067314\ttotal: 46.3s\tremaining: 39.2s\n",
      "541:\tlearn: 0.0067314\ttotal: 46.3s\tremaining: 39.1s\n",
      "542:\tlearn: 0.0067314\ttotal: 46.4s\tremaining: 39s\n",
      "543:\tlearn: 0.0067314\ttotal: 46.5s\tremaining: 39s\n",
      "544:\tlearn: 0.0067314\ttotal: 46.5s\tremaining: 38.8s\n",
      "545:\tlearn: 0.0067314\ttotal: 46.6s\tremaining: 38.7s\n",
      "546:\tlearn: 0.0067314\ttotal: 46.7s\tremaining: 38.6s\n",
      "547:\tlearn: 0.0067211\ttotal: 46.7s\tremaining: 38.6s\n",
      "548:\tlearn: 0.0067211\ttotal: 46.8s\tremaining: 38.5s\n",
      "549:\tlearn: 0.0067211\ttotal: 46.9s\tremaining: 38.4s\n",
      "550:\tlearn: 0.0067210\ttotal: 47s\tremaining: 38.3s\n",
      "551:\tlearn: 0.0067210\ttotal: 47s\tremaining: 38.2s\n",
      "552:\tlearn: 0.0067210\ttotal: 47.1s\tremaining: 38.1s\n",
      "553:\tlearn: 0.0067024\ttotal: 47.2s\tremaining: 38s\n",
      "554:\tlearn: 0.0067023\ttotal: 47.3s\tremaining: 37.9s\n",
      "555:\tlearn: 0.0067023\ttotal: 47.3s\tremaining: 37.8s\n",
      "556:\tlearn: 0.0066890\ttotal: 47.4s\tremaining: 37.7s\n",
      "557:\tlearn: 0.0066889\ttotal: 47.5s\tremaining: 37.6s\n",
      "558:\tlearn: 0.0066889\ttotal: 47.6s\tremaining: 37.5s\n",
      "559:\tlearn: 0.0066889\ttotal: 47.6s\tremaining: 37.4s\n",
      "560:\tlearn: 0.0066889\ttotal: 47.7s\tremaining: 37.3s\n",
      "561:\tlearn: 0.0066889\ttotal: 47.8s\tremaining: 37.2s\n",
      "562:\tlearn: 0.0066888\ttotal: 47.8s\tremaining: 37.1s\n",
      "563:\tlearn: 0.0066888\ttotal: 47.9s\tremaining: 37s\n",
      "564:\tlearn: 0.0066888\ttotal: 48s\tremaining: 36.9s\n",
      "565:\tlearn: 0.0066888\ttotal: 48s\tremaining: 36.8s\n",
      "566:\tlearn: 0.0066888\ttotal: 48.1s\tremaining: 36.7s\n",
      "567:\tlearn: 0.0066725\ttotal: 48.2s\tremaining: 36.7s\n",
      "568:\tlearn: 0.0066725\ttotal: 48.3s\tremaining: 36.6s\n",
      "569:\tlearn: 0.0066557\ttotal: 48.3s\tremaining: 36.5s\n",
      "570:\tlearn: 0.0066557\ttotal: 48.4s\tremaining: 36.4s\n",
      "571:\tlearn: 0.0066557\ttotal: 48.5s\tremaining: 36.3s\n",
      "572:\tlearn: 0.0066557\ttotal: 48.5s\tremaining: 36.2s\n",
      "573:\tlearn: 0.0066335\ttotal: 48.6s\tremaining: 36.1s\n",
      "574:\tlearn: 0.0066335\ttotal: 48.7s\tremaining: 36s\n",
      "575:\tlearn: 0.0066335\ttotal: 48.8s\tremaining: 35.9s\n",
      "576:\tlearn: 0.0066335\ttotal: 48.9s\tremaining: 35.8s\n",
      "577:\tlearn: 0.0066334\ttotal: 48.9s\tremaining: 35.7s\n",
      "578:\tlearn: 0.0066334\ttotal: 49s\tremaining: 35.6s\n",
      "579:\tlearn: 0.0066334\ttotal: 49.1s\tremaining: 35.5s\n",
      "580:\tlearn: 0.0066334\ttotal: 49.1s\tremaining: 35.4s\n",
      "581:\tlearn: 0.0066334\ttotal: 49.2s\tremaining: 35.3s\n",
      "582:\tlearn: 0.0066334\ttotal: 49.3s\tremaining: 35.2s\n",
      "583:\tlearn: 0.0066334\ttotal: 49.3s\tremaining: 35.1s\n",
      "584:\tlearn: 0.0066334\ttotal: 49.4s\tremaining: 35s\n",
      "585:\tlearn: 0.0066333\ttotal: 49.5s\tremaining: 34.9s\n",
      "586:\tlearn: 0.0066333\ttotal: 49.5s\tremaining: 34.9s\n",
      "587:\tlearn: 0.0066333\ttotal: 49.6s\tremaining: 34.8s\n",
      "588:\tlearn: 0.0066333\ttotal: 49.7s\tremaining: 34.7s\n",
      "589:\tlearn: 0.0066333\ttotal: 49.7s\tremaining: 34.6s\n",
      "590:\tlearn: 0.0066333\ttotal: 49.8s\tremaining: 34.5s\n",
      "591:\tlearn: 0.0066333\ttotal: 49.9s\tremaining: 34.4s\n",
      "592:\tlearn: 0.0066333\ttotal: 49.9s\tremaining: 34.3s\n",
      "593:\tlearn: 0.0066333\ttotal: 50s\tremaining: 34.2s\n",
      "594:\tlearn: 0.0066333\ttotal: 50.1s\tremaining: 34.1s\n",
      "595:\tlearn: 0.0066332\ttotal: 50.2s\tremaining: 34s\n",
      "596:\tlearn: 0.0066332\ttotal: 50.2s\tremaining: 33.9s\n",
      "597:\tlearn: 0.0066332\ttotal: 50.3s\tremaining: 33.8s\n",
      "598:\tlearn: 0.0066332\ttotal: 50.3s\tremaining: 33.7s\n",
      "599:\tlearn: 0.0066332\ttotal: 50.4s\tremaining: 33.6s\n",
      "600:\tlearn: 0.0066332\ttotal: 50.5s\tremaining: 33.5s\n",
      "601:\tlearn: 0.0066332\ttotal: 50.6s\tremaining: 33.4s\n",
      "602:\tlearn: 0.0066332\ttotal: 50.6s\tremaining: 33.3s\n",
      "603:\tlearn: 0.0066332\ttotal: 50.7s\tremaining: 33.2s\n",
      "604:\tlearn: 0.0066332\ttotal: 50.8s\tremaining: 33.1s\n",
      "605:\tlearn: 0.0066332\ttotal: 50.8s\tremaining: 33s\n",
      "606:\tlearn: 0.0066332\ttotal: 50.9s\tremaining: 32.9s\n",
      "607:\tlearn: 0.0066332\ttotal: 51s\tremaining: 32.9s\n",
      "608:\tlearn: 0.0066332\ttotal: 51s\tremaining: 32.8s\n",
      "609:\tlearn: 0.0066332\ttotal: 51.1s\tremaining: 32.7s\n",
      "610:\tlearn: 0.0066331\ttotal: 51.2s\tremaining: 32.6s\n",
      "611:\tlearn: 0.0066331\ttotal: 51.2s\tremaining: 32.5s\n",
      "612:\tlearn: 0.0066331\ttotal: 51.3s\tremaining: 32.4s\n",
      "613:\tlearn: 0.0066331\ttotal: 51.4s\tremaining: 32.3s\n",
      "614:\tlearn: 0.0066331\ttotal: 51.4s\tremaining: 32.2s\n",
      "615:\tlearn: 0.0066331\ttotal: 51.5s\tremaining: 32.1s\n",
      "616:\tlearn: 0.0066331\ttotal: 51.6s\tremaining: 32s\n",
      "617:\tlearn: 0.0066331\ttotal: 51.6s\tremaining: 31.9s\n",
      "618:\tlearn: 0.0066331\ttotal: 51.7s\tremaining: 31.8s\n",
      "619:\tlearn: 0.0066331\ttotal: 51.8s\tremaining: 31.7s\n",
      "620:\tlearn: 0.0066331\ttotal: 51.8s\tremaining: 31.6s\n",
      "621:\tlearn: 0.0066331\ttotal: 51.9s\tremaining: 31.5s\n",
      "622:\tlearn: 0.0066331\ttotal: 52s\tremaining: 31.5s\n",
      "623:\tlearn: 0.0066331\ttotal: 52.1s\tremaining: 31.4s\n",
      "624:\tlearn: 0.0066331\ttotal: 52.1s\tremaining: 31.3s\n",
      "625:\tlearn: 0.0066331\ttotal: 52.2s\tremaining: 31.2s\n",
      "626:\tlearn: 0.0066331\ttotal: 52.3s\tremaining: 31.1s\n",
      "627:\tlearn: 0.0066331\ttotal: 52.3s\tremaining: 31s\n",
      "628:\tlearn: 0.0066331\ttotal: 52.4s\tremaining: 30.9s\n",
      "629:\tlearn: 0.0066331\ttotal: 52.5s\tremaining: 30.8s\n",
      "630:\tlearn: 0.0066331\ttotal: 52.5s\tremaining: 30.7s\n",
      "631:\tlearn: 0.0066331\ttotal: 52.6s\tremaining: 30.6s\n",
      "632:\tlearn: 0.0066331\ttotal: 52.7s\tremaining: 30.6s\n",
      "633:\tlearn: 0.0066331\ttotal: 52.8s\tremaining: 30.5s\n",
      "634:\tlearn: 0.0066331\ttotal: 52.9s\tremaining: 30.4s\n",
      "635:\tlearn: 0.0066331\ttotal: 52.9s\tremaining: 30.3s\n",
      "636:\tlearn: 0.0066330\ttotal: 53s\tremaining: 30.2s\n",
      "637:\tlearn: 0.0066330\ttotal: 53.1s\tremaining: 30.1s\n",
      "638:\tlearn: 0.0066330\ttotal: 53.1s\tremaining: 30s\n",
      "639:\tlearn: 0.0066330\ttotal: 53.2s\tremaining: 29.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640:\tlearn: 0.0066329\ttotal: 53.3s\tremaining: 29.8s\n",
      "641:\tlearn: 0.0066329\ttotal: 53.3s\tremaining: 29.7s\n",
      "642:\tlearn: 0.0066329\ttotal: 53.4s\tremaining: 29.7s\n",
      "643:\tlearn: 0.0066329\ttotal: 53.5s\tremaining: 29.6s\n",
      "644:\tlearn: 0.0066329\ttotal: 53.6s\tremaining: 29.5s\n",
      "645:\tlearn: 0.0066328\ttotal: 53.6s\tremaining: 29.4s\n",
      "646:\tlearn: 0.0066328\ttotal: 53.7s\tremaining: 29.3s\n",
      "647:\tlearn: 0.0066328\ttotal: 53.8s\tremaining: 29.2s\n",
      "648:\tlearn: 0.0066328\ttotal: 53.8s\tremaining: 29.1s\n",
      "649:\tlearn: 0.0066328\ttotal: 53.9s\tremaining: 29s\n",
      "650:\tlearn: 0.0066328\ttotal: 54s\tremaining: 28.9s\n",
      "651:\tlearn: 0.0066328\ttotal: 54s\tremaining: 28.8s\n",
      "652:\tlearn: 0.0066328\ttotal: 54.1s\tremaining: 28.8s\n",
      "653:\tlearn: 0.0066328\ttotal: 54.2s\tremaining: 28.7s\n",
      "654:\tlearn: 0.0066221\ttotal: 54.2s\tremaining: 28.6s\n",
      "655:\tlearn: 0.0066221\ttotal: 54.3s\tremaining: 28.5s\n",
      "656:\tlearn: 0.0066220\ttotal: 54.4s\tremaining: 28.4s\n",
      "657:\tlearn: 0.0066220\ttotal: 54.4s\tremaining: 28.3s\n",
      "658:\tlearn: 0.0066220\ttotal: 54.5s\tremaining: 28.2s\n",
      "659:\tlearn: 0.0066220\ttotal: 54.6s\tremaining: 28.1s\n",
      "660:\tlearn: 0.0066144\ttotal: 54.7s\tremaining: 28s\n",
      "661:\tlearn: 0.0066144\ttotal: 54.7s\tremaining: 27.9s\n",
      "662:\tlearn: 0.0066144\ttotal: 54.8s\tremaining: 27.8s\n",
      "663:\tlearn: 0.0066144\ttotal: 54.9s\tremaining: 27.8s\n",
      "664:\tlearn: 0.0066144\ttotal: 54.9s\tremaining: 27.7s\n",
      "665:\tlearn: 0.0066143\ttotal: 55s\tremaining: 27.6s\n",
      "666:\tlearn: 0.0066143\ttotal: 55s\tremaining: 27.5s\n",
      "667:\tlearn: 0.0066143\ttotal: 55.1s\tremaining: 27.4s\n",
      "668:\tlearn: 0.0066143\ttotal: 55.2s\tremaining: 27.3s\n",
      "669:\tlearn: 0.0066143\ttotal: 55.2s\tremaining: 27.2s\n",
      "670:\tlearn: 0.0066143\ttotal: 55.3s\tremaining: 27.1s\n",
      "671:\tlearn: 0.0066143\ttotal: 55.4s\tremaining: 27s\n",
      "672:\tlearn: 0.0066143\ttotal: 55.4s\tremaining: 26.9s\n",
      "673:\tlearn: 0.0066143\ttotal: 55.5s\tremaining: 26.8s\n",
      "674:\tlearn: 0.0066143\ttotal: 55.6s\tremaining: 26.8s\n",
      "675:\tlearn: 0.0066142\ttotal: 55.6s\tremaining: 26.7s\n",
      "676:\tlearn: 0.0066142\ttotal: 55.7s\tremaining: 26.6s\n",
      "677:\tlearn: 0.0066142\ttotal: 55.8s\tremaining: 26.5s\n",
      "678:\tlearn: 0.0066142\ttotal: 55.8s\tremaining: 26.4s\n",
      "679:\tlearn: 0.0066142\ttotal: 55.9s\tremaining: 26.3s\n",
      "680:\tlearn: 0.0066142\ttotal: 56s\tremaining: 26.2s\n",
      "681:\tlearn: 0.0066142\ttotal: 56s\tremaining: 26.1s\n",
      "682:\tlearn: 0.0066142\ttotal: 56.1s\tremaining: 26s\n",
      "683:\tlearn: 0.0066142\ttotal: 56.2s\tremaining: 26s\n",
      "684:\tlearn: 0.0066141\ttotal: 56.2s\tremaining: 25.9s\n",
      "685:\tlearn: 0.0066141\ttotal: 56.3s\tremaining: 25.8s\n",
      "686:\tlearn: 0.0066141\ttotal: 56.4s\tremaining: 25.7s\n",
      "687:\tlearn: 0.0066141\ttotal: 56.4s\tremaining: 25.6s\n",
      "688:\tlearn: 0.0066141\ttotal: 56.5s\tremaining: 25.5s\n",
      "689:\tlearn: 0.0066141\ttotal: 56.6s\tremaining: 25.4s\n",
      "690:\tlearn: 0.0066141\ttotal: 56.6s\tremaining: 25.3s\n",
      "691:\tlearn: 0.0066140\ttotal: 56.7s\tremaining: 25.2s\n",
      "692:\tlearn: 0.0066140\ttotal: 56.8s\tremaining: 25.1s\n",
      "693:\tlearn: 0.0066140\ttotal: 56.8s\tremaining: 25.1s\n",
      "694:\tlearn: 0.0066140\ttotal: 56.9s\tremaining: 25s\n",
      "695:\tlearn: 0.0066140\ttotal: 57s\tremaining: 24.9s\n",
      "696:\tlearn: 0.0066140\ttotal: 57s\tremaining: 24.8s\n",
      "697:\tlearn: 0.0066140\ttotal: 57.1s\tremaining: 24.7s\n",
      "698:\tlearn: 0.0066140\ttotal: 57.2s\tremaining: 24.6s\n",
      "699:\tlearn: 0.0066140\ttotal: 57.3s\tremaining: 24.5s\n",
      "700:\tlearn: 0.0066139\ttotal: 57.3s\tremaining: 24.5s\n",
      "701:\tlearn: 0.0066139\ttotal: 57.4s\tremaining: 24.4s\n",
      "702:\tlearn: 0.0066139\ttotal: 57.5s\tremaining: 24.3s\n",
      "703:\tlearn: 0.0066139\ttotal: 57.5s\tremaining: 24.2s\n",
      "704:\tlearn: 0.0066139\ttotal: 57.6s\tremaining: 24.1s\n",
      "705:\tlearn: 0.0066139\ttotal: 57.7s\tremaining: 24s\n",
      "706:\tlearn: 0.0066139\ttotal: 57.7s\tremaining: 23.9s\n",
      "707:\tlearn: 0.0066138\ttotal: 57.8s\tremaining: 23.8s\n",
      "708:\tlearn: 0.0066138\ttotal: 57.9s\tremaining: 23.8s\n",
      "709:\tlearn: 0.0066138\ttotal: 58s\tremaining: 23.7s\n",
      "710:\tlearn: 0.0066138\ttotal: 58s\tremaining: 23.6s\n",
      "711:\tlearn: 0.0066138\ttotal: 58.1s\tremaining: 23.5s\n",
      "712:\tlearn: 0.0066138\ttotal: 58.2s\tremaining: 23.4s\n",
      "713:\tlearn: 0.0066138\ttotal: 58.2s\tremaining: 23.3s\n",
      "714:\tlearn: 0.0066138\ttotal: 58.3s\tremaining: 23.2s\n",
      "715:\tlearn: 0.0066138\ttotal: 58.4s\tremaining: 23.2s\n",
      "716:\tlearn: 0.0066138\ttotal: 58.4s\tremaining: 23.1s\n",
      "717:\tlearn: 0.0066138\ttotal: 58.5s\tremaining: 23s\n",
      "718:\tlearn: 0.0066138\ttotal: 58.6s\tremaining: 22.9s\n",
      "719:\tlearn: 0.0066138\ttotal: 58.7s\tremaining: 22.8s\n",
      "720:\tlearn: 0.0066137\ttotal: 58.7s\tremaining: 22.7s\n",
      "721:\tlearn: 0.0066137\ttotal: 58.8s\tremaining: 22.6s\n",
      "722:\tlearn: 0.0066137\ttotal: 58.9s\tremaining: 22.6s\n",
      "723:\tlearn: 0.0066137\ttotal: 58.9s\tremaining: 22.5s\n",
      "724:\tlearn: 0.0066137\ttotal: 59s\tremaining: 22.4s\n",
      "725:\tlearn: 0.0066137\ttotal: 59.1s\tremaining: 22.3s\n",
      "726:\tlearn: 0.0066137\ttotal: 59.2s\tremaining: 22.2s\n",
      "727:\tlearn: 0.0066137\ttotal: 59.2s\tremaining: 22.1s\n",
      "728:\tlearn: 0.0066137\ttotal: 59.3s\tremaining: 22s\n",
      "729:\tlearn: 0.0066137\ttotal: 59.4s\tremaining: 22s\n",
      "730:\tlearn: 0.0066137\ttotal: 59.5s\tremaining: 21.9s\n",
      "731:\tlearn: 0.0066137\ttotal: 59.5s\tremaining: 21.8s\n",
      "732:\tlearn: 0.0066136\ttotal: 59.6s\tremaining: 21.7s\n",
      "733:\tlearn: 0.0066136\ttotal: 59.7s\tremaining: 21.6s\n",
      "734:\tlearn: 0.0066136\ttotal: 59.7s\tremaining: 21.5s\n",
      "735:\tlearn: 0.0066136\ttotal: 59.8s\tremaining: 21.5s\n",
      "736:\tlearn: 0.0066136\ttotal: 59.9s\tremaining: 21.4s\n",
      "737:\tlearn: 0.0066136\ttotal: 60s\tremaining: 21.3s\n",
      "738:\tlearn: 0.0066136\ttotal: 1m\tremaining: 21.2s\n",
      "739:\tlearn: 0.0066136\ttotal: 1m\tremaining: 21.1s\n",
      "740:\tlearn: 0.0066136\ttotal: 1m\tremaining: 21s\n",
      "741:\tlearn: 0.0066136\ttotal: 1m\tremaining: 20.9s\n",
      "742:\tlearn: 0.0066135\ttotal: 1m\tremaining: 20.9s\n",
      "743:\tlearn: 0.0066135\ttotal: 1m\tremaining: 20.8s\n",
      "744:\tlearn: 0.0066135\ttotal: 1m\tremaining: 20.7s\n",
      "745:\tlearn: 0.0066135\ttotal: 1m\tremaining: 20.6s\n",
      "746:\tlearn: 0.0066135\ttotal: 1m\tremaining: 20.5s\n",
      "747:\tlearn: 0.0066135\ttotal: 1m\tremaining: 20.4s\n",
      "748:\tlearn: 0.0066135\ttotal: 1m\tremaining: 20.4s\n",
      "749:\tlearn: 0.0066135\ttotal: 1m\tremaining: 20.3s\n",
      "750:\tlearn: 0.0066135\ttotal: 1m\tremaining: 20.2s\n",
      "751:\tlearn: 0.0066134\ttotal: 1m\tremaining: 20.1s\n",
      "752:\tlearn: 0.0066134\ttotal: 1m 1s\tremaining: 20s\n",
      "753:\tlearn: 0.0066134\ttotal: 1m 1s\tremaining: 19.9s\n",
      "754:\tlearn: 0.0065957\ttotal: 1m 1s\tremaining: 19.9s\n",
      "755:\tlearn: 0.0065739\ttotal: 1m 1s\tremaining: 19.8s\n",
      "756:\tlearn: 0.0065320\ttotal: 1m 1s\tremaining: 19.7s\n",
      "757:\tlearn: 0.0065320\ttotal: 1m 1s\tremaining: 19.6s\n",
      "758:\tlearn: 0.0065320\ttotal: 1m 1s\tremaining: 19.5s\n",
      "759:\tlearn: 0.0065142\ttotal: 1m 1s\tremaining: 19.5s\n",
      "760:\tlearn: 0.0065142\ttotal: 1m 1s\tremaining: 19.4s\n",
      "761:\tlearn: 0.0065142\ttotal: 1m 1s\tremaining: 19.3s\n",
      "762:\tlearn: 0.0065068\ttotal: 1m 1s\tremaining: 19.2s\n",
      "763:\tlearn: 0.0065067\ttotal: 1m 1s\tremaining: 19.1s\n",
      "764:\tlearn: 0.0065067\ttotal: 1m 1s\tremaining: 19s\n",
      "765:\tlearn: 0.0065067\ttotal: 1m 2s\tremaining: 19s\n",
      "766:\tlearn: 0.0064855\ttotal: 1m 2s\tremaining: 18.9s\n",
      "767:\tlearn: 0.0064854\ttotal: 1m 2s\tremaining: 18.8s\n",
      "768:\tlearn: 0.0064854\ttotal: 1m 2s\tremaining: 18.7s\n",
      "769:\tlearn: 0.0064853\ttotal: 1m 2s\tremaining: 18.6s\n",
      "770:\tlearn: 0.0064853\ttotal: 1m 2s\tremaining: 18.5s\n",
      "771:\tlearn: 0.0064853\ttotal: 1m 2s\tremaining: 18.5s\n",
      "772:\tlearn: 0.0064853\ttotal: 1m 2s\tremaining: 18.4s\n",
      "773:\tlearn: 0.0064853\ttotal: 1m 2s\tremaining: 18.3s\n",
      "774:\tlearn: 0.0064853\ttotal: 1m 2s\tremaining: 18.2s\n",
      "775:\tlearn: 0.0064853\ttotal: 1m 2s\tremaining: 18.1s\n",
      "776:\tlearn: 0.0064853\ttotal: 1m 2s\tremaining: 18s\n",
      "777:\tlearn: 0.0064853\ttotal: 1m 2s\tremaining: 18s\n",
      "778:\tlearn: 0.0064853\ttotal: 1m 2s\tremaining: 17.9s\n",
      "779:\tlearn: 0.0064852\ttotal: 1m 3s\tremaining: 17.8s\n",
      "780:\tlearn: 0.0064852\ttotal: 1m 3s\tremaining: 17.7s\n",
      "781:\tlearn: 0.0064852\ttotal: 1m 3s\tremaining: 17.6s\n",
      "782:\tlearn: 0.0064852\ttotal: 1m 3s\tremaining: 17.5s\n",
      "783:\tlearn: 0.0064852\ttotal: 1m 3s\tremaining: 17.5s\n",
      "784:\tlearn: 0.0064852\ttotal: 1m 3s\tremaining: 17.4s\n",
      "785:\tlearn: 0.0064852\ttotal: 1m 3s\tremaining: 17.3s\n",
      "786:\tlearn: 0.0064852\ttotal: 1m 3s\tremaining: 17.2s\n",
      "787:\tlearn: 0.0064851\ttotal: 1m 3s\tremaining: 17.1s\n",
      "788:\tlearn: 0.0064851\ttotal: 1m 3s\tremaining: 17s\n",
      "789:\tlearn: 0.0064851\ttotal: 1m 3s\tremaining: 17s\n",
      "790:\tlearn: 0.0064851\ttotal: 1m 3s\tremaining: 16.9s\n",
      "791:\tlearn: 0.0064851\ttotal: 1m 3s\tremaining: 16.8s\n",
      "792:\tlearn: 0.0064851\ttotal: 1m 3s\tremaining: 16.7s\n",
      "793:\tlearn: 0.0064851\ttotal: 1m 4s\tremaining: 16.6s\n",
      "794:\tlearn: 0.0064851\ttotal: 1m 4s\tremaining: 16.5s\n",
      "795:\tlearn: 0.0064850\ttotal: 1m 4s\tremaining: 16.5s\n",
      "796:\tlearn: 0.0064850\ttotal: 1m 4s\tremaining: 16.4s\n",
      "797:\tlearn: 0.0064850\ttotal: 1m 4s\tremaining: 16.3s\n",
      "798:\tlearn: 0.0064850\ttotal: 1m 4s\tremaining: 16.2s\n",
      "799:\tlearn: 0.0064850\ttotal: 1m 4s\tremaining: 16.1s\n",
      "800:\tlearn: 0.0064850\ttotal: 1m 4s\tremaining: 16s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801:\tlearn: 0.0064850\ttotal: 1m 4s\tremaining: 16s\n",
      "802:\tlearn: 0.0064849\ttotal: 1m 4s\tremaining: 15.9s\n",
      "803:\tlearn: 0.0064849\ttotal: 1m 4s\tremaining: 15.8s\n",
      "804:\tlearn: 0.0064849\ttotal: 1m 4s\tremaining: 15.7s\n",
      "805:\tlearn: 0.0064849\ttotal: 1m 4s\tremaining: 15.6s\n",
      "806:\tlearn: 0.0064849\ttotal: 1m 4s\tremaining: 15.5s\n",
      "807:\tlearn: 0.0064848\ttotal: 1m 5s\tremaining: 15.5s\n",
      "808:\tlearn: 0.0064848\ttotal: 1m 5s\tremaining: 15.4s\n",
      "809:\tlearn: 0.0064848\ttotal: 1m 5s\tremaining: 15.3s\n",
      "810:\tlearn: 0.0064848\ttotal: 1m 5s\tremaining: 15.2s\n",
      "811:\tlearn: 0.0064848\ttotal: 1m 5s\tremaining: 15.1s\n",
      "812:\tlearn: 0.0064848\ttotal: 1m 5s\tremaining: 15.1s\n",
      "813:\tlearn: 0.0064848\ttotal: 1m 5s\tremaining: 15s\n",
      "814:\tlearn: 0.0064848\ttotal: 1m 5s\tremaining: 14.9s\n",
      "815:\tlearn: 0.0064847\ttotal: 1m 5s\tremaining: 14.8s\n",
      "816:\tlearn: 0.0064847\ttotal: 1m 5s\tremaining: 14.7s\n",
      "817:\tlearn: 0.0064847\ttotal: 1m 5s\tremaining: 14.6s\n",
      "818:\tlearn: 0.0064847\ttotal: 1m 5s\tremaining: 14.6s\n",
      "819:\tlearn: 0.0064847\ttotal: 1m 5s\tremaining: 14.5s\n",
      "820:\tlearn: 0.0064847\ttotal: 1m 6s\tremaining: 14.4s\n",
      "821:\tlearn: 0.0064847\ttotal: 1m 6s\tremaining: 14.3s\n",
      "822:\tlearn: 0.0064847\ttotal: 1m 6s\tremaining: 14.2s\n",
      "823:\tlearn: 0.0064847\ttotal: 1m 6s\tremaining: 14.1s\n",
      "824:\tlearn: 0.0064847\ttotal: 1m 6s\tremaining: 14.1s\n",
      "825:\tlearn: 0.0064847\ttotal: 1m 6s\tremaining: 14s\n",
      "826:\tlearn: 0.0064847\ttotal: 1m 6s\tremaining: 13.9s\n",
      "827:\tlearn: 0.0064847\ttotal: 1m 6s\tremaining: 13.8s\n",
      "828:\tlearn: 0.0064846\ttotal: 1m 6s\tremaining: 13.7s\n",
      "829:\tlearn: 0.0064749\ttotal: 1m 6s\tremaining: 13.7s\n",
      "830:\tlearn: 0.0064749\ttotal: 1m 6s\tremaining: 13.6s\n",
      "831:\tlearn: 0.0064749\ttotal: 1m 6s\tremaining: 13.5s\n",
      "832:\tlearn: 0.0064749\ttotal: 1m 6s\tremaining: 13.4s\n",
      "833:\tlearn: 0.0064749\ttotal: 1m 6s\tremaining: 13.3s\n",
      "834:\tlearn: 0.0064749\ttotal: 1m 7s\tremaining: 13.2s\n",
      "835:\tlearn: 0.0064749\ttotal: 1m 7s\tremaining: 13.2s\n",
      "836:\tlearn: 0.0064749\ttotal: 1m 7s\tremaining: 13.1s\n",
      "837:\tlearn: 0.0064749\ttotal: 1m 7s\tremaining: 13s\n",
      "838:\tlearn: 0.0064749\ttotal: 1m 7s\tremaining: 12.9s\n",
      "839:\tlearn: 0.0064749\ttotal: 1m 7s\tremaining: 12.8s\n",
      "840:\tlearn: 0.0064749\ttotal: 1m 7s\tremaining: 12.8s\n",
      "841:\tlearn: 0.0064749\ttotal: 1m 7s\tremaining: 12.7s\n",
      "842:\tlearn: 0.0064749\ttotal: 1m 7s\tremaining: 12.6s\n",
      "843:\tlearn: 0.0064749\ttotal: 1m 7s\tremaining: 12.5s\n",
      "844:\tlearn: 0.0064749\ttotal: 1m 7s\tremaining: 12.4s\n",
      "845:\tlearn: 0.0064749\ttotal: 1m 7s\tremaining: 12.4s\n",
      "846:\tlearn: 0.0064749\ttotal: 1m 7s\tremaining: 12.3s\n",
      "847:\tlearn: 0.0064749\ttotal: 1m 8s\tremaining: 12.2s\n",
      "848:\tlearn: 0.0064749\ttotal: 1m 8s\tremaining: 12.1s\n",
      "849:\tlearn: 0.0064749\ttotal: 1m 8s\tremaining: 12s\n",
      "850:\tlearn: 0.0064749\ttotal: 1m 8s\tremaining: 12s\n",
      "851:\tlearn: 0.0064749\ttotal: 1m 8s\tremaining: 11.9s\n",
      "852:\tlearn: 0.0064749\ttotal: 1m 8s\tremaining: 11.8s\n",
      "853:\tlearn: 0.0064749\ttotal: 1m 8s\tremaining: 11.7s\n",
      "854:\tlearn: 0.0064749\ttotal: 1m 8s\tremaining: 11.6s\n",
      "855:\tlearn: 0.0064749\ttotal: 1m 8s\tremaining: 11.6s\n",
      "856:\tlearn: 0.0064749\ttotal: 1m 8s\tremaining: 11.5s\n",
      "857:\tlearn: 0.0064749\ttotal: 1m 8s\tremaining: 11.4s\n",
      "858:\tlearn: 0.0064749\ttotal: 1m 8s\tremaining: 11.3s\n",
      "859:\tlearn: 0.0064749\ttotal: 1m 9s\tremaining: 11.2s\n",
      "860:\tlearn: 0.0064749\ttotal: 1m 9s\tremaining: 11.2s\n",
      "861:\tlearn: 0.0064749\ttotal: 1m 9s\tremaining: 11.1s\n",
      "862:\tlearn: 0.0064749\ttotal: 1m 9s\tremaining: 11s\n",
      "863:\tlearn: 0.0064749\ttotal: 1m 9s\tremaining: 10.9s\n",
      "864:\tlearn: 0.0064749\ttotal: 1m 9s\tremaining: 10.8s\n",
      "865:\tlearn: 0.0064749\ttotal: 1m 9s\tremaining: 10.8s\n",
      "866:\tlearn: 0.0064749\ttotal: 1m 9s\tremaining: 10.7s\n",
      "867:\tlearn: 0.0064749\ttotal: 1m 9s\tremaining: 10.6s\n",
      "868:\tlearn: 0.0064749\ttotal: 1m 9s\tremaining: 10.5s\n",
      "869:\tlearn: 0.0064749\ttotal: 1m 9s\tremaining: 10.4s\n",
      "870:\tlearn: 0.0064749\ttotal: 1m 9s\tremaining: 10.4s\n",
      "871:\tlearn: 0.0064749\ttotal: 1m 9s\tremaining: 10.3s\n",
      "872:\tlearn: 0.0064749\ttotal: 1m 10s\tremaining: 10.2s\n",
      "873:\tlearn: 0.0064749\ttotal: 1m 10s\tremaining: 10.1s\n",
      "874:\tlearn: 0.0064749\ttotal: 1m 10s\tremaining: 10s\n",
      "875:\tlearn: 0.0064749\ttotal: 1m 10s\tremaining: 9.95s\n",
      "876:\tlearn: 0.0064749\ttotal: 1m 10s\tremaining: 9.87s\n",
      "877:\tlearn: 0.0064749\ttotal: 1m 10s\tremaining: 9.79s\n",
      "878:\tlearn: 0.0064749\ttotal: 1m 10s\tremaining: 9.71s\n",
      "879:\tlearn: 0.0064749\ttotal: 1m 10s\tremaining: 9.63s\n",
      "880:\tlearn: 0.0064749\ttotal: 1m 10s\tremaining: 9.55s\n",
      "881:\tlearn: 0.0064749\ttotal: 1m 10s\tremaining: 9.47s\n",
      "882:\tlearn: 0.0064749\ttotal: 1m 10s\tremaining: 9.39s\n",
      "883:\tlearn: 0.0064749\ttotal: 1m 10s\tremaining: 9.31s\n",
      "884:\tlearn: 0.0064749\ttotal: 1m 11s\tremaining: 9.23s\n",
      "885:\tlearn: 0.0064749\ttotal: 1m 11s\tremaining: 9.15s\n",
      "886:\tlearn: 0.0064749\ttotal: 1m 11s\tremaining: 9.07s\n",
      "887:\tlearn: 0.0064749\ttotal: 1m 11s\tremaining: 8.98s\n",
      "888:\tlearn: 0.0064749\ttotal: 1m 11s\tremaining: 8.9s\n",
      "889:\tlearn: 0.0064749\ttotal: 1m 11s\tremaining: 8.83s\n",
      "890:\tlearn: 0.0064749\ttotal: 1m 11s\tremaining: 8.74s\n",
      "891:\tlearn: 0.0064749\ttotal: 1m 11s\tremaining: 8.67s\n",
      "892:\tlearn: 0.0064749\ttotal: 1m 11s\tremaining: 8.59s\n",
      "893:\tlearn: 0.0064749\ttotal: 1m 11s\tremaining: 8.51s\n",
      "894:\tlearn: 0.0064749\ttotal: 1m 11s\tremaining: 8.43s\n",
      "895:\tlearn: 0.0064749\ttotal: 1m 11s\tremaining: 8.35s\n",
      "896:\tlearn: 0.0064749\ttotal: 1m 11s\tremaining: 8.26s\n",
      "897:\tlearn: 0.0064749\ttotal: 1m 12s\tremaining: 8.18s\n",
      "898:\tlearn: 0.0064749\ttotal: 1m 12s\tremaining: 8.1s\n",
      "899:\tlearn: 0.0064749\ttotal: 1m 12s\tremaining: 8.02s\n",
      "900:\tlearn: 0.0064749\ttotal: 1m 12s\tremaining: 7.94s\n",
      "901:\tlearn: 0.0064749\ttotal: 1m 12s\tremaining: 7.86s\n",
      "902:\tlearn: 0.0064749\ttotal: 1m 12s\tremaining: 7.78s\n",
      "903:\tlearn: 0.0064749\ttotal: 1m 12s\tremaining: 7.7s\n",
      "904:\tlearn: 0.0064749\ttotal: 1m 12s\tremaining: 7.62s\n",
      "905:\tlearn: 0.0064749\ttotal: 1m 12s\tremaining: 7.54s\n",
      "906:\tlearn: 0.0064749\ttotal: 1m 12s\tremaining: 7.46s\n",
      "907:\tlearn: 0.0064749\ttotal: 1m 12s\tremaining: 7.38s\n",
      "908:\tlearn: 0.0064749\ttotal: 1m 12s\tremaining: 7.3s\n",
      "909:\tlearn: 0.0064749\ttotal: 1m 12s\tremaining: 7.22s\n",
      "910:\tlearn: 0.0064749\ttotal: 1m 13s\tremaining: 7.14s\n",
      "911:\tlearn: 0.0064749\ttotal: 1m 13s\tremaining: 7.06s\n",
      "912:\tlearn: 0.0064749\ttotal: 1m 13s\tremaining: 6.98s\n",
      "913:\tlearn: 0.0064749\ttotal: 1m 13s\tremaining: 6.9s\n",
      "914:\tlearn: 0.0064749\ttotal: 1m 13s\tremaining: 6.82s\n",
      "915:\tlearn: 0.0064749\ttotal: 1m 13s\tremaining: 6.74s\n",
      "916:\tlearn: 0.0064749\ttotal: 1m 13s\tremaining: 6.66s\n",
      "917:\tlearn: 0.0064749\ttotal: 1m 13s\tremaining: 6.58s\n",
      "918:\tlearn: 0.0064749\ttotal: 1m 13s\tremaining: 6.5s\n",
      "919:\tlearn: 0.0064749\ttotal: 1m 13s\tremaining: 6.42s\n",
      "920:\tlearn: 0.0064749\ttotal: 1m 13s\tremaining: 6.33s\n",
      "921:\tlearn: 0.0064749\ttotal: 1m 13s\tremaining: 6.25s\n",
      "922:\tlearn: 0.0064749\ttotal: 1m 14s\tremaining: 6.17s\n",
      "923:\tlearn: 0.0064749\ttotal: 1m 14s\tremaining: 6.09s\n",
      "924:\tlearn: 0.0064749\ttotal: 1m 14s\tremaining: 6.01s\n",
      "925:\tlearn: 0.0064749\ttotal: 1m 14s\tremaining: 5.93s\n",
      "926:\tlearn: 0.0064749\ttotal: 1m 14s\tremaining: 5.85s\n",
      "927:\tlearn: 0.0064749\ttotal: 1m 14s\tremaining: 5.77s\n",
      "928:\tlearn: 0.0064749\ttotal: 1m 14s\tremaining: 5.69s\n",
      "929:\tlearn: 0.0064749\ttotal: 1m 14s\tremaining: 5.61s\n",
      "930:\tlearn: 0.0064749\ttotal: 1m 14s\tremaining: 5.53s\n",
      "931:\tlearn: 0.0064749\ttotal: 1m 14s\tremaining: 5.45s\n",
      "932:\tlearn: 0.0064749\ttotal: 1m 14s\tremaining: 5.37s\n",
      "933:\tlearn: 0.0064749\ttotal: 1m 14s\tremaining: 5.29s\n",
      "934:\tlearn: 0.0064749\ttotal: 1m 14s\tremaining: 5.21s\n",
      "935:\tlearn: 0.0064749\ttotal: 1m 15s\tremaining: 5.13s\n",
      "936:\tlearn: 0.0064749\ttotal: 1m 15s\tremaining: 5.05s\n",
      "937:\tlearn: 0.0064749\ttotal: 1m 15s\tremaining: 4.97s\n",
      "938:\tlearn: 0.0064749\ttotal: 1m 15s\tremaining: 4.89s\n",
      "939:\tlearn: 0.0064749\ttotal: 1m 15s\tremaining: 4.81s\n",
      "940:\tlearn: 0.0064749\ttotal: 1m 15s\tremaining: 4.73s\n",
      "941:\tlearn: 0.0064749\ttotal: 1m 15s\tremaining: 4.65s\n",
      "942:\tlearn: 0.0064749\ttotal: 1m 15s\tremaining: 4.57s\n",
      "943:\tlearn: 0.0064749\ttotal: 1m 15s\tremaining: 4.49s\n",
      "944:\tlearn: 0.0064749\ttotal: 1m 15s\tremaining: 4.41s\n",
      "945:\tlearn: 0.0064749\ttotal: 1m 15s\tremaining: 4.33s\n",
      "946:\tlearn: 0.0064749\ttotal: 1m 15s\tremaining: 4.25s\n",
      "947:\tlearn: 0.0064749\ttotal: 1m 15s\tremaining: 4.17s\n",
      "948:\tlearn: 0.0064749\ttotal: 1m 16s\tremaining: 4.09s\n",
      "949:\tlearn: 0.0064749\ttotal: 1m 16s\tremaining: 4.01s\n",
      "950:\tlearn: 0.0064749\ttotal: 1m 16s\tremaining: 3.93s\n",
      "951:\tlearn: 0.0064749\ttotal: 1m 16s\tremaining: 3.85s\n",
      "952:\tlearn: 0.0064749\ttotal: 1m 16s\tremaining: 3.77s\n",
      "953:\tlearn: 0.0064749\ttotal: 1m 16s\tremaining: 3.69s\n",
      "954:\tlearn: 0.0064749\ttotal: 1m 16s\tremaining: 3.61s\n",
      "955:\tlearn: 0.0064749\ttotal: 1m 16s\tremaining: 3.53s\n",
      "956:\tlearn: 0.0064749\ttotal: 1m 16s\tremaining: 3.44s\n",
      "957:\tlearn: 0.0064749\ttotal: 1m 16s\tremaining: 3.37s\n",
      "958:\tlearn: 0.0064749\ttotal: 1m 16s\tremaining: 3.29s\n",
      "959:\tlearn: 0.0064749\ttotal: 1m 16s\tremaining: 3.21s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960:\tlearn: 0.0064749\ttotal: 1m 17s\tremaining: 3.13s\n",
      "961:\tlearn: 0.0064749\ttotal: 1m 17s\tremaining: 3.04s\n",
      "962:\tlearn: 0.0064749\ttotal: 1m 17s\tremaining: 2.96s\n",
      "963:\tlearn: 0.0064749\ttotal: 1m 17s\tremaining: 2.88s\n",
      "964:\tlearn: 0.0064749\ttotal: 1m 17s\tremaining: 2.8s\n",
      "965:\tlearn: 0.0064749\ttotal: 1m 17s\tremaining: 2.72s\n",
      "966:\tlearn: 0.0064749\ttotal: 1m 17s\tremaining: 2.64s\n",
      "967:\tlearn: 0.0064749\ttotal: 1m 17s\tremaining: 2.56s\n",
      "968:\tlearn: 0.0064749\ttotal: 1m 17s\tremaining: 2.48s\n",
      "969:\tlearn: 0.0064749\ttotal: 1m 17s\tremaining: 2.4s\n",
      "970:\tlearn: 0.0064749\ttotal: 1m 17s\tremaining: 2.32s\n",
      "971:\tlearn: 0.0064749\ttotal: 1m 17s\tremaining: 2.24s\n",
      "972:\tlearn: 0.0064749\ttotal: 1m 17s\tremaining: 2.16s\n",
      "973:\tlearn: 0.0064749\ttotal: 1m 18s\tremaining: 2.08s\n",
      "974:\tlearn: 0.0064749\ttotal: 1m 18s\tremaining: 2s\n",
      "975:\tlearn: 0.0064749\ttotal: 1m 18s\tremaining: 1.92s\n",
      "976:\tlearn: 0.0064749\ttotal: 1m 18s\tremaining: 1.84s\n",
      "977:\tlearn: 0.0064749\ttotal: 1m 18s\tremaining: 1.76s\n",
      "978:\tlearn: 0.0064749\ttotal: 1m 18s\tremaining: 1.68s\n",
      "979:\tlearn: 0.0064749\ttotal: 1m 18s\tremaining: 1.6s\n",
      "980:\tlearn: 0.0064749\ttotal: 1m 18s\tremaining: 1.52s\n",
      "981:\tlearn: 0.0064749\ttotal: 1m 18s\tremaining: 1.44s\n",
      "982:\tlearn: 0.0064749\ttotal: 1m 18s\tremaining: 1.36s\n",
      "983:\tlearn: 0.0064749\ttotal: 1m 18s\tremaining: 1.28s\n",
      "984:\tlearn: 0.0064749\ttotal: 1m 18s\tremaining: 1.2s\n",
      "985:\tlearn: 0.0064749\ttotal: 1m 19s\tremaining: 1.12s\n",
      "986:\tlearn: 0.0064749\ttotal: 1m 19s\tremaining: 1.04s\n",
      "987:\tlearn: 0.0064749\ttotal: 1m 19s\tremaining: 962ms\n",
      "988:\tlearn: 0.0064749\ttotal: 1m 19s\tremaining: 881ms\n",
      "989:\tlearn: 0.0064749\ttotal: 1m 19s\tremaining: 801ms\n",
      "990:\tlearn: 0.0064749\ttotal: 1m 19s\tremaining: 721ms\n",
      "991:\tlearn: 0.0064749\ttotal: 1m 19s\tremaining: 641ms\n",
      "992:\tlearn: 0.0064749\ttotal: 1m 19s\tremaining: 561ms\n",
      "993:\tlearn: 0.0064749\ttotal: 1m 19s\tremaining: 481ms\n",
      "994:\tlearn: 0.0064749\ttotal: 1m 19s\tremaining: 401ms\n",
      "995:\tlearn: 0.0064749\ttotal: 1m 19s\tremaining: 320ms\n",
      "996:\tlearn: 0.0064749\ttotal: 1m 19s\tremaining: 240ms\n",
      "997:\tlearn: 0.0064749\ttotal: 1m 19s\tremaining: 160ms\n",
      "998:\tlearn: 0.0064749\ttotal: 1m 20s\tremaining: 80.1ms\n",
      "999:\tlearn: 0.0064749\ttotal: 1m 20s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1d1cd70fc88>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "cat = CatBoostClassifier()\n",
    "cat.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    11159\n",
       "pos      241\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2 = cat.predict(X_val01)\n",
    "pd.Series(result2).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.7929515418502203\n",
      "accuracy score: 0.9917543859649123\n"
     ]
    }
   ],
   "source": [
    "print('f1 score:', f1_score(y_val.replace({'neg': 0, 'pos' : 1}), pd.Series(result2).replace({'neg': 0, 'pos' : 1})))\n",
    "print('accuracy score:', accuracy_score(y_val.replace({'neg': 0, 'pos' : 1}), pd.Series(result2).replace({'neg': 0, 'pos' : 1})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'predicted':result2, 'true':y_val})\n",
    "df2.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost 총 비용 : $ 17110\n",
      "positive를 negative로 분류 : $ 16500\n",
      "negative를 positive로 분류 : $ 610\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "j= 0\n",
    "false_neg = 0\n",
    "false_pos = 0\n",
    "\n",
    "for predicted, true in df2.values:\n",
    "    if predicted != true: #예측이 틀렸을 때\n",
    "        if true == 'neg': \n",
    "            i = i+10\n",
    "            false_pos = false_pos+1\n",
    "        else :\n",
    "            j = j+500\n",
    "            false_neg = false_neg+1\n",
    "            \n",
    "print('CatBoost 총 비용 :','$',i+j)\n",
    "print('positive를 negative로 분류 :', '$',false_neg*500)\n",
    "print('negative를 positive로 분류 :', '$', false_pos*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\n",
    "xgb_model.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    11175\n",
       "pos      225\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result3 = xgb_model.predict(X_val01)\n",
    "pd.Series(result3).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.817351598173516\n",
      "accuracy score: 0.9929824561403509\n"
     ]
    }
   ],
   "source": [
    "print('f1 score:', f1_score(y_val.replace({'neg': 0, 'pos' : 1}), pd.Series(result3).replace({'neg': 0, 'pos' : 1})))\n",
    "print('accuracy score:', accuracy_score(y_val.replace({'neg': 0, 'pos' : 1}), pd.Series(result3).replace({'neg': 0, 'pos' : 1})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame({'predicted':result3, 'true':y_val})\n",
    "df3.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost 총 비용 : $ 17460\n",
      "positive를 negative로 분류 : 34 개 $ 17000\n",
      "negative를 positive로 분류 : 46 개 $ 460\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "j= 0\n",
    "false_neg = 0\n",
    "false_pos = 0\n",
    "\n",
    "for predicted, true in df3.values:\n",
    "    if predicted != true: #예측이 틀렸을 때\n",
    "        if true == 'neg': \n",
    "            i = i+10\n",
    "            false_pos = false_pos+1\n",
    "        else :\n",
    "            j = j+500\n",
    "            false_neg = false_neg+1\n",
    "            \n",
    "print('XGBoost 총 비용 :','$',i+j)\n",
    "print('positive를 negative로 분류 :',false_neg,'개','$',false_neg*500)\n",
    "print('negative를 positive로 분류 :', false_pos,'개', '$', false_pos*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LeeYoungsin\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, log_loss, confusion_matrix,classification_report\n",
    "logistic_clf= LogisticRegression(random_state=0, solver='lbfgs',C=1.0).fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    10762\n",
       "pos      638\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result4= logistic_clf.predict(X_val01)\n",
    "pd.Series(result4).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.45593419506462984\n",
      "accuracy score: 0.9593859649122807\n"
     ]
    }
   ],
   "source": [
    "print('f1 score:', f1_score(y_val.replace({'neg': 0, 'pos' : 1}), pd.Series(result4).replace({'neg': 0, 'pos' : 1})))\n",
    "print('accuracy score:', accuracy_score(y_val.replace({'neg': 0, 'pos' : 1}), pd.Series(result4).replace({'neg': 0, 'pos' : 1})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.DataFrame({'predicted':result4, 'true':y_val})\n",
    "df4.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression 총 비용 : $ 13940\n",
      "positive를 negative로 분류 : $ 9500\n",
      "negative를 positive로 분류 : $ 4440\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "j= 0\n",
    "false_neg = 0\n",
    "false_pos = 0\n",
    "\n",
    "for predicted, true in df4.values:\n",
    "    if predicted != true: #예측이 틀렸을 때\n",
    "        if true == 'neg': \n",
    "            i = i+10\n",
    "            false_pos = false_pos+1\n",
    "        else :\n",
    "            j = j+500\n",
    "            false_neg = false_neg+1\n",
    "            \n",
    "print('Logistic Regression 총 비용 :','$',i+j)\n",
    "print('positive를 negative로 분류 :', '$',false_neg*500)\n",
    "print('negative를 positive로 분류 :', '$', false_pos*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LeeYoungsin\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, multi_class='multinomial')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_reg = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", C=10)\n",
    "softmax_reg.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    10766\n",
       "pos      634\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result5= softmax_reg.predict(X_val01)\n",
    "pd.Series(result5).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.45808736717827625\n",
      "accuracy score: 0.9597368421052631\n"
     ]
    }
   ],
   "source": [
    "print('f1 score:', f1_score(y_val.replace({'neg': 0, 'pos' : 1}), pd.Series(result5).replace({'neg': 0, 'pos' : 1})))\n",
    "print('accuracy score:', accuracy_score(y_val.replace({'neg': 0, 'pos' : 1}), pd.Series(result5).replace({'neg': 0, 'pos' : 1})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.DataFrame({'predicted':result5, 'true':y_val})\n",
    "df5.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SoftMax 총 비용 : $ 13900\n",
      "positive를 negative로 분류 : $ 9500\n",
      "negative를 positive로 분류 : $ 4400\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "j= 0\n",
    "false_neg = 0\n",
    "false_pos = 0\n",
    "\n",
    "for predicted, true in df5.values:\n",
    "    if predicted != true: #예측이 틀렸을 때\n",
    "        if true == 'neg': \n",
    "            i = i+10\n",
    "            false_pos = false_pos+1\n",
    "        else :\n",
    "            j = j+500\n",
    "            false_neg = false_neg+1\n",
    "            \n",
    "print('SoftMax 총 비용 :','$',i+j)\n",
    "print('positive를 negative로 분류 :', '$',false_neg*500)\n",
    "print('negative를 positive로 분류 :', '$', false_pos*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LeeYoungsin\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('linear_svc', LinearSVC(C=0.1, loss='hinge'))])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Linear_svm_clf =Pipeline((\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"linear_svc\", LinearSVC(C=0.1, loss=\"hinge\")),\n",
    "))                                                     \n",
    "Linear_svm_clf.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    10945\n",
       "pos      455\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result6=Linear_svm_clf.predict(X_val01)\n",
    "pd.Series(result6).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.5898203592814372\n",
      "accuracy score: 0.9759649122807017\n"
     ]
    }
   ],
   "source": [
    "print('f1 score:', f1_score(y_val.replace({'neg': 0, 'pos' : 1}), pd.Series(result6).replace({'neg': 0, 'pos' : 1})))\n",
    "print('accuracy score:', accuracy_score(y_val.replace({'neg': 0, 'pos' : 1}), pd.Series(result6).replace({'neg': 0, 'pos' : 1})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = pd.DataFrame({'predicted':result4, 'true':y_val})\n",
    "df6.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC 총 비용 : $ 13940\n",
      "positive를 negative로 분류 : $ 9500\n",
      "negative를 positive로 분류 : $ 4440\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "j= 0\n",
    "false_neg = 0\n",
    "false_pos = 0\n",
    "\n",
    "for predicted, true in df6.values:\n",
    "    if predicted != true: #예측이 틀렸을 때\n",
    "        if true == 'neg': \n",
    "            i = i+10\n",
    "            false_pos = false_pos+1\n",
    "        else :\n",
    "            j = j+500\n",
    "            false_neg = false_neg+1\n",
    "            \n",
    "print('LinearSVC 총 비용 :','$',i+j)\n",
    "print('positive를 negative로 분류 :', '$',false_neg*500)\n",
    "print('negative를 positive로 분류 :', '$', false_pos*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ab_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>ag_002</th>\n",
       "      <th>ag_003</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2682</td>\n",
       "      <td>...</td>\n",
       "      <td>1098</td>\n",
       "      <td>138</td>\n",
       "      <td>412</td>\n",
       "      <td>654</td>\n",
       "      <td>78</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1068</td>\n",
       "      <td>276</td>\n",
       "      <td>1620</td>\n",
       "      <td>116</td>\n",
       "      <td>86</td>\n",
       "      <td>462</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66002</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>199486</td>\n",
       "      <td>...</td>\n",
       "      <td>495076</td>\n",
       "      <td>380368</td>\n",
       "      <td>440134</td>\n",
       "      <td>269556</td>\n",
       "      <td>1315022</td>\n",
       "      <td>153680</td>\n",
       "      <td>516</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59816</td>\n",
       "      <td>-1</td>\n",
       "      <td>1010</td>\n",
       "      <td>936</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>540820</td>\n",
       "      <td>243270</td>\n",
       "      <td>483302</td>\n",
       "      <td>485332</td>\n",
       "      <td>431376</td>\n",
       "      <td>210074</td>\n",
       "      <td>281662</td>\n",
       "      <td>3232</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1814</td>\n",
       "      <td>-1</td>\n",
       "      <td>156</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7646</td>\n",
       "      <td>4144</td>\n",
       "      <td>18466</td>\n",
       "      <td>49782</td>\n",
       "      <td>3176</td>\n",
       "      <td>482</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>81852</td>\n",
       "      <td>-1</td>\n",
       "      <td>2130706432</td>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>632658</td>\n",
       "      <td>273242</td>\n",
       "      <td>510354</td>\n",
       "      <td>373918</td>\n",
       "      <td>349840</td>\n",
       "      <td>317840</td>\n",
       "      <td>960024</td>\n",
       "      <td>25566</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>46</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>266</td>\n",
       "      <td>44</td>\n",
       "      <td>46</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>79636</td>\n",
       "      <td>-1</td>\n",
       "      <td>1670</td>\n",
       "      <td>1518</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>806832</td>\n",
       "      <td>449962</td>\n",
       "      <td>778826</td>\n",
       "      <td>581558</td>\n",
       "      <td>375498</td>\n",
       "      <td>222866</td>\n",
       "      <td>358934</td>\n",
       "      <td>19548</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>110</td>\n",
       "      <td>-1</td>\n",
       "      <td>36</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>588</td>\n",
       "      <td>210</td>\n",
       "      <td>180</td>\n",
       "      <td>544</td>\n",
       "      <td>1004</td>\n",
       "      <td>1338</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>46</td>\n",
       "      <td>10</td>\n",
       "      <td>48</td>\n",
       "      <td>14</td>\n",
       "      <td>42</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows × 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aa_000 ab_000      ac_000 ad_000 ae_000 af_000 ag_000 ag_001 ag_002  \\\n",
       "0          60      0          20     12      0      0      0      0      0   \n",
       "1          82      0          68     40      0      0      0      0      0   \n",
       "2       66002      2         212    112      0      0      0      0      0   \n",
       "3       59816     -1        1010    936      0      0      0      0      0   \n",
       "4        1814     -1         156    140      0      0      0      0      0   \n",
       "...       ...    ...         ...    ...    ...    ...    ...    ...    ...   \n",
       "15995   81852     -1  2130706432    892      0      0      0      0      0   \n",
       "15996      18      0          52     46      8     26      0      0      0   \n",
       "15997   79636     -1        1670   1518      0      0      0      0      0   \n",
       "15998     110     -1          36     32      0      0      0      0      0   \n",
       "15999       8      0           6      4      2      2      0      0      0   \n",
       "\n",
       "       ag_003  ...  ee_002  ee_003  ee_004  ee_005   ee_006  ee_007  ee_008  \\\n",
       "0        2682  ...    1098     138     412     654       78      88       0   \n",
       "1           0  ...    1068     276    1620     116       86     462       0   \n",
       "2      199486  ...  495076  380368  440134  269556  1315022  153680     516   \n",
       "3           0  ...  540820  243270  483302  485332   431376  210074  281662   \n",
       "4           0  ...    7646    4144   18466   49782     3176     482      76   \n",
       "...       ...  ...     ...     ...     ...     ...      ...     ...     ...   \n",
       "15995       0  ...  632658  273242  510354  373918   349840  317840  960024   \n",
       "15996       0  ...     266      44      46      14        2       0       0   \n",
       "15997       0  ...  806832  449962  778826  581558   375498  222866  358934   \n",
       "15998       0  ...     588     210     180     544     1004    1338      74   \n",
       "15999       0  ...      46      10      48      14       42      46       0   \n",
       "\n",
       "      ee_009 ef_000 eg_000  \n",
       "0          0      0      0  \n",
       "1          0      0      0  \n",
       "2          0      0      0  \n",
       "3       3232      0      0  \n",
       "4          0      0      0  \n",
       "...      ...    ...    ...  \n",
       "15995  25566      0      0  \n",
       "15996      0      0      0  \n",
       "15997  19548      0      0  \n",
       "15998      0      0      0  \n",
       "15999      0      0      0  \n",
       "\n",
       "[16000 rows x 170 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test.replace(\"na\", -1)\n",
    "test1 = test.drop(['class'], axis=1)\n",
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aa_000    float64\n",
       "ab_000    float64\n",
       "ac_000    float64\n",
       "ad_000    float64\n",
       "ae_000    float64\n",
       "           ...   \n",
       "ee_007    float64\n",
       "ee_008    float64\n",
       "ee_009    float64\n",
       "ef_000    float64\n",
       "eg_000    float64\n",
       "Length: 170, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1=test1.astype(float)\n",
    "test1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    15618\n",
       "pos      382\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred1 = rf.predict(test1)\n",
    "pd.Series(test_pred1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.9299867899603699\n",
      "accuracy score: 0.9966875\n"
     ]
    }
   ],
   "source": [
    "print('f1 score:', f1_score(test['class'].replace({'neg': 0, 'pos' : 1}), pd.Series(test_pred1).replace({'neg': 0, 'pos' : 1})))\n",
    "print('accuracy score:', accuracy_score(test['class'].replace({'neg': 0, 'pos' : 1}), pd.Series(test_pred1).replace({'neg': 0, 'pos' : 1})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df1 = pd.DataFrame({'predicted':test_pred1, 'true':test['class']})\n",
    "t_df1.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest 총 비용 : $ 11800\n",
      "positive를 negative로 분류 : $ 11500\n",
      "negative를 positive로 분류 : $ 300\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "j= 0\n",
    "false_neg = 0\n",
    "false_pos = 0\n",
    "\n",
    "for predicted, true in t_df1.values:\n",
    "    if predicted != true: #예측이 틀렸을 때\n",
    "        if true == 'neg': \n",
    "            i = i+10\n",
    "            false_pos = false_pos+1\n",
    "        else :\n",
    "            j = j+500\n",
    "            false_neg = false_neg+1\n",
    "            \n",
    "print('RandomForest 총 비용 :','$',i+j)\n",
    "print('positive를 negative로 분류 :', '$',false_neg*500)\n",
    "print('negative를 positive로 분류 :', '$', false_pos*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    15612\n",
       "pos      388\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred2 = cat.predict(test1)\n",
    "pd.Series(test_pred2).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.9226736566186108\n",
      "accuracy score: 0.9963125\n"
     ]
    }
   ],
   "source": [
    "print('f1 score:', f1_score(test['class'].replace({'neg': 0, 'pos' : 1}), pd.Series(test_pred2).replace({'neg': 0, 'pos' : 1})))\n",
    "print('accuracy score:', accuracy_score(test['class'].replace({'neg': 0, 'pos' : 1}), pd.Series(test_pred2).replace({'neg': 0, 'pos' : 1})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df2 = pd.DataFrame({'predicted':test_pred2, 'true':test['class']})\n",
    "t_df2.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost 총 비용 : $ 11860\n",
      "positive를 negative로 분류 : $ 11500\n",
      "negative를 positive로 분류 : $ 360\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "j= 0\n",
    "false_neg = 0\n",
    "false_pos = 0\n",
    "\n",
    "for predicted, true in t_df2.values:\n",
    "    if predicted != true: #예측이 틀렸을 때\n",
    "        if true == 'neg': \n",
    "            i = i+10\n",
    "            false_pos = false_pos+1\n",
    "        else :\n",
    "            j = j+500\n",
    "            false_neg = false_neg+1\n",
    "            \n",
    "print('CatBoost 총 비용 :','$',i+j)\n",
    "print('positive를 negative로 분류 :', '$',false_neg*500)\n",
    "print('negative를 positive로 분류 :', '$', false_pos*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    15628\n",
       "pos      372\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred3 = xgb_model.predict(test1)\n",
    "pd.Series(test_pred3).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.9477911646586344\n",
      "accuracy score: 0.9975625\n"
     ]
    }
   ],
   "source": [
    "print('f1 score:', f1_score(test['class'].replace({'neg': 0, 'pos' : 1}), pd.Series(test_pred3).replace({'neg': 0, 'pos' : 1})))\n",
    "print('accuracy score:', accuracy_score(test['class'].replace({'neg': 0, 'pos' : 1}), pd.Series(test_pred3).replace({'neg': 0, 'pos' : 1})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df3 = pd.DataFrame({'predicted':test_pred3, 'true':test['class']})\n",
    "t_df3.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XG Boost 총 비용 : $ 10680\n",
      "positive를 negative로 분류 : $ 10500\n",
      "negative를 positive로 분류 : $ 180\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "j= 0\n",
    "false_neg = 0\n",
    "false_pos = 0\n",
    "\n",
    "for predicted, true in t_df3.values:\n",
    "    if predicted != true: #예측이 틀렸을 때\n",
    "        if true == 'neg': \n",
    "            i = i+10\n",
    "            false_pos = false_pos+1\n",
    "        else :\n",
    "            j = j+500\n",
    "            false_neg = false_neg+1\n",
    "            \n",
    "print('XG Boost 총 비용 :','$',i+j)\n",
    "print('positive를 negative로 분류 :', '$',false_neg*500)\n",
    "print('negative를 positive로 분류 :', '$', false_pos*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    15061\n",
       "pos      939\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred4 = logistic_clf.predict(test1)\n",
    "pd.Series(test_pred4).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.5144596651445965\n",
      "accuracy score: 0.960125\n"
     ]
    }
   ],
   "source": [
    "print('f1 score:', f1_score(test['class'].replace({'neg': 0, 'pos' : 1}), pd.Series(test_pred4).replace({'neg': 0, 'pos' : 1})))\n",
    "print('accuracy score:', accuracy_score(test['class'].replace({'neg': 0, 'pos' : 1}), pd.Series(test_pred4).replace({'neg': 0, 'pos' : 1})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df4 = pd.DataFrame({'predicted':test_pred4, 'true':test['class']})\n",
    "t_df4.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression 총 비용 : $ 24510\n",
      "positive를 negative로 분류 : $ 18500\n",
      "negative를 positive로 분류 : $ 6010\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "j= 0\n",
    "false_neg = 0\n",
    "false_pos = 0\n",
    "\n",
    "for predicted, true in t_df4.values:\n",
    "    if predicted != true: #예측이 틀렸을 때\n",
    "        if true == 'neg': \n",
    "            i = i+10\n",
    "            false_pos = false_pos+1\n",
    "        else :\n",
    "            j = j+500\n",
    "            false_neg = false_neg+1\n",
    "            \n",
    "print('Logistic Regression 총 비용 :','$',i+j)\n",
    "print('positive를 negative로 분류 :', '$',false_neg*500)\n",
    "print('negative를 positive로 분류 :', '$', false_pos*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    15047\n",
       "pos      953\n",
       "dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred5 = softmax_reg.predict(test1)\n",
    "pd.Series(test_pred5).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.5150602409638554\n",
      "accuracy score: 0.95975\n"
     ]
    }
   ],
   "source": [
    "print('f1 score:', f1_score(test['class'].replace({'neg': 0, 'pos' : 1}), pd.Series(test_pred5).replace({'neg': 0, 'pos' : 1})))\n",
    "print('accuracy score:', accuracy_score(test['class'].replace({'neg': 0, 'pos' : 1}), pd.Series(test_pred5).replace({'neg': 0, 'pos' : 1})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df5 = pd.DataFrame({'predicted':test_pred5, 'true':test['class']})\n",
    "t_df5.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SoftMax 총 비용 : $ 22610\n",
      "positive를 negative로 분류 : $ 16500\n",
      "negative를 positive로 분류 : $ 6110\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "j= 0\n",
    "false_neg = 0\n",
    "false_pos = 0\n",
    "\n",
    "for predicted, true in t_df5.values:\n",
    "    if predicted != true: #예측이 틀렸을 때\n",
    "        if true == 'neg': \n",
    "            i = i+10\n",
    "            false_pos = false_pos+1\n",
    "        else :\n",
    "            j = j+500\n",
    "            false_neg = false_neg+1\n",
    "            \n",
    "print('SoftMax 총 비용 :','$',i+j)\n",
    "print('positive를 negative로 분류 :', '$',false_neg*500)\n",
    "print('negative를 positive로 분류 :', '$', false_pos*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    15318\n",
       "pos      682\n",
       "dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred6=Linear_svm_clf.predict(test1)\n",
    "pd.Series(test_pred6).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.664143803216651\n",
      "accuracy score: 0.9778125\n"
     ]
    }
   ],
   "source": [
    "print('f1 score:', f1_score(test['class'].replace({'neg': 0, 'pos' : 1}), pd.Series(test_pred6).replace({'neg': 0, 'pos' : 1})))\n",
    "print('accuracy score:', accuracy_score(test['class'].replace({'neg': 0, 'pos' : 1}), pd.Series(test_pred6).replace({'neg': 0, 'pos' : 1})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df6 = pd.DataFrame({'predicted':test_pred6, 'true':test['class']})\n",
    "t_df6.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC 총 비용 : $ 15310\n",
      "positive를 negative로 분류 : $ 12000\n",
      "negative를 positive로 분류 : $ 3310\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "j= 0\n",
    "false_neg = 0\n",
    "false_pos = 0\n",
    "\n",
    "for predicted, true in t_df6.values:\n",
    "    if predicted != true: #예측이 틀렸을 때\n",
    "        if true == 'neg': \n",
    "            i = i+10\n",
    "            false_pos = false_pos+1\n",
    "        else :\n",
    "            j = j+500\n",
    "            false_neg = false_neg+1\n",
    "            \n",
    "print('LinearSVC 총 비용 :','$',i+j)\n",
    "print('positive를 negative로 분류 :', '$',false_neg*500)\n",
    "print('negative를 positive로 분류 :', '$', false_pos*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Parameter Tuning on XGB and CB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### insight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weight for class 1 in binary classification. The value is used as a multiplier for the weights of objects from class 1. <br>\n",
    "<https://catboost.ai/docs/concepts/python-reference_parameters-list.html#python-reference_parameters-list>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tip. For imbalanced datasets, the weight multiplier can be set to $\\frac{sum-negative}{sum-positive}$ <br>\n",
    "oversampling 하기 전 y_train(class label)의 pos:neg=1:52 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. XGB Params Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.25, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.8,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xgb_model_2 = xgb.XGBClassifier(learning_rate=0.25, subsample=0.8, objective=\"binary:logistic\", random_state=42)\n",
    "xgb_model_2.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    11171\n",
       "pos      229\n",
       "dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result7 = xgb_model_2.predict(X_val01)\n",
    "pd.Series(result7).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.828054298642534\n",
      "accuracy score: 0.9933333333333333\n"
     ]
    }
   ],
   "source": [
    "print('f1 score:', f1_score(y_val.replace({'neg': 0, 'pos' : 1}), pd.Series(result7).replace({'neg': 0, 'pos' : 1})))\n",
    "print('accuracy score:', accuracy_score(y_val.replace({'neg': 0, 'pos' : 1}), pd.Series(result7).replace({'neg': 0, 'pos' : 1})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = pd.DataFrame({'predicted':result7, 'true':y_val})\n",
    "df7.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost 총 비용 : $ 15460\n",
      "positive를 negative로 분류 : $ 30 개 15000\n",
      "negative를 positive로 분류 : $ 46 개 460\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "j= 0\n",
    "false_neg = 0\n",
    "false_pos = 0\n",
    "\n",
    "for predicted, true in df7.values:\n",
    "    if predicted != true: #예측이 틀렸을 때\n",
    "        if true == 'neg': \n",
    "            i = i+10\n",
    "            false_pos = false_pos+1\n",
    "        else :\n",
    "            j = j+500\n",
    "            false_neg = false_neg+1\n",
    "            \n",
    "print('XGBoost 총 비용 :','$',i+j)\n",
    "print('positive를 negative로 분류 :', '$',false_neg,'개',false_neg*500)\n",
    "print('negative를 positive로 분류 :', '$',false_pos,'개', false_pos*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-1 XGB scale_pos_weight setting to 52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.2, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=52, subsample=0.8,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xgb_model_3 = xgb.XGBClassifier(learning_rate=0.2, subsample=0.8, objective=\"binary:logistic\", scale_pos_weight=52, random_state=42)\n",
    "xgb_model_3.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    11094\n",
       "pos      306\n",
       "dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result9 = xgb_model_3.predict(X_val01)\n",
    "pd.Series(result9).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.7321772639691715\n",
      "accuracy score: 0.9878070175438597\n"
     ]
    }
   ],
   "source": [
    "print('f1 score:', f1_score(y_val.replace({'neg': 0, 'pos' : 1}), pd.Series(result9).replace({'neg': 0, 'pos' : 1})))\n",
    "print('accuracy score:', accuracy_score(y_val.replace({'neg': 0, 'pos' : 1}), pd.Series(result9).replace({'neg': 0, 'pos' : 1})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9 = pd.DataFrame({'predicted':result9, 'true':y_val})\n",
    "df9.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost 총 비용 : $ 12660\n",
      "positive를 negative로 분류 : $ 23 개 11500\n",
      "negative를 positive로 분류 : $ 116 개 1160\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "j= 0\n",
    "false_neg = 0\n",
    "false_pos = 0\n",
    "\n",
    "for predicted, true in df9.values:\n",
    "    if predicted != true: #예측이 틀렸을 때\n",
    "        if true == 'neg': \n",
    "            i = i+10\n",
    "            false_pos = false_pos+1\n",
    "        else :\n",
    "            j = j+500\n",
    "            false_neg = false_neg+1\n",
    "            \n",
    "print('XGBoost 총 비용 :','$',i+j)\n",
    "print('positive를 negative로 분류 :', '$',false_neg,'개',false_neg*500)\n",
    "print('negative를 positive로 분류 :', '$',false_pos,'개', false_pos*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scale_pos_weight 을 52에 가까이 할수록 총 비용은 줄어들지만\n",
    "f1 score은 점점 낮아진다. <br>\n",
    "모델의 목적이 false_negative 분류에 의한 비용 감소니까, trade-off에서 비용을 감소시키는 쪽을 택한다. <br>\n",
    "모델의 하이퍼파라미터 튜닝을 할 때 무엇이 모델의 목적에 우선순위인지 파악해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. CatBoost Params Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기존 learning rate = 0.07<br>\n",
    "Setting learning rate to 0.3 and scale_pos_weight= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.2358208\ttotal: 117ms\tremaining: 1m 57s\n",
      "1:\tlearn: 0.1087975\ttotal: 214ms\tremaining: 1m 46s\n",
      "2:\tlearn: 0.0705597\ttotal: 311ms\tremaining: 1m 43s\n",
      "3:\tlearn: 0.0568091\ttotal: 425ms\tremaining: 1m 45s\n",
      "4:\tlearn: 0.0473283\ttotal: 559ms\tremaining: 1m 51s\n",
      "5:\tlearn: 0.0425090\ttotal: 650ms\tremaining: 1m 47s\n",
      "6:\tlearn: 0.0372743\ttotal: 743ms\tremaining: 1m 45s\n",
      "7:\tlearn: 0.0348986\ttotal: 829ms\tremaining: 1m 42s\n",
      "8:\tlearn: 0.0314994\ttotal: 926ms\tremaining: 1m 41s\n",
      "9:\tlearn: 0.0301612\ttotal: 1.02s\tremaining: 1m 41s\n",
      "10:\tlearn: 0.0281558\ttotal: 1.11s\tremaining: 1m 40s\n",
      "11:\tlearn: 0.0271557\ttotal: 1.2s\tremaining: 1m 38s\n",
      "12:\tlearn: 0.0257247\ttotal: 1.29s\tremaining: 1m 37s\n",
      "13:\tlearn: 0.0247208\ttotal: 1.39s\tremaining: 1m 37s\n",
      "14:\tlearn: 0.0231230\ttotal: 1.48s\tremaining: 1m 37s\n",
      "15:\tlearn: 0.0222602\ttotal: 1.58s\tremaining: 1m 37s\n",
      "16:\tlearn: 0.0211968\ttotal: 1.68s\tremaining: 1m 37s\n",
      "17:\tlearn: 0.0203771\ttotal: 1.79s\tremaining: 1m 37s\n",
      "18:\tlearn: 0.0195659\ttotal: 1.9s\tremaining: 1m 37s\n",
      "19:\tlearn: 0.0189183\ttotal: 2.01s\tremaining: 1m 38s\n",
      "20:\tlearn: 0.0185552\ttotal: 2.09s\tremaining: 1m 37s\n",
      "21:\tlearn: 0.0180579\ttotal: 2.18s\tremaining: 1m 37s\n",
      "22:\tlearn: 0.0172808\ttotal: 2.28s\tremaining: 1m 36s\n",
      "23:\tlearn: 0.0167621\ttotal: 2.38s\tremaining: 1m 36s\n",
      "24:\tlearn: 0.0160506\ttotal: 2.47s\tremaining: 1m 36s\n",
      "25:\tlearn: 0.0157536\ttotal: 2.55s\tremaining: 1m 35s\n",
      "26:\tlearn: 0.0153232\ttotal: 2.65s\tremaining: 1m 35s\n",
      "27:\tlearn: 0.0150937\ttotal: 2.72s\tremaining: 1m 34s\n",
      "28:\tlearn: 0.0147713\ttotal: 2.81s\tremaining: 1m 34s\n",
      "29:\tlearn: 0.0142676\ttotal: 2.91s\tremaining: 1m 34s\n",
      "30:\tlearn: 0.0141026\ttotal: 3s\tremaining: 1m 33s\n",
      "31:\tlearn: 0.0138202\ttotal: 3.08s\tremaining: 1m 33s\n",
      "32:\tlearn: 0.0136222\ttotal: 3.16s\tremaining: 1m 32s\n",
      "33:\tlearn: 0.0134077\ttotal: 3.25s\tremaining: 1m 32s\n",
      "34:\tlearn: 0.0129348\ttotal: 3.34s\tremaining: 1m 32s\n",
      "35:\tlearn: 0.0126780\ttotal: 3.45s\tremaining: 1m 32s\n",
      "36:\tlearn: 0.0125531\ttotal: 3.54s\tremaining: 1m 32s\n",
      "37:\tlearn: 0.0121879\ttotal: 3.63s\tremaining: 1m 31s\n",
      "38:\tlearn: 0.0119678\ttotal: 3.71s\tremaining: 1m 31s\n",
      "39:\tlearn: 0.0118472\ttotal: 3.8s\tremaining: 1m 31s\n",
      "40:\tlearn: 0.0117358\ttotal: 3.88s\tremaining: 1m 30s\n",
      "41:\tlearn: 0.0116430\ttotal: 3.96s\tremaining: 1m 30s\n",
      "42:\tlearn: 0.0114725\ttotal: 4.04s\tremaining: 1m 30s\n",
      "43:\tlearn: 0.0114725\ttotal: 4.11s\tremaining: 1m 29s\n",
      "44:\tlearn: 0.0113480\ttotal: 4.19s\tremaining: 1m 28s\n",
      "45:\tlearn: 0.0113174\ttotal: 4.27s\tremaining: 1m 28s\n",
      "46:\tlearn: 0.0111187\ttotal: 4.35s\tremaining: 1m 28s\n",
      "47:\tlearn: 0.0111186\ttotal: 4.42s\tremaining: 1m 27s\n",
      "48:\tlearn: 0.0111186\ttotal: 4.5s\tremaining: 1m 27s\n",
      "49:\tlearn: 0.0111186\ttotal: 4.57s\tremaining: 1m 26s\n",
      "50:\tlearn: 0.0111185\ttotal: 4.63s\tremaining: 1m 26s\n",
      "51:\tlearn: 0.0111184\ttotal: 4.7s\tremaining: 1m 25s\n",
      "52:\tlearn: 0.0111184\ttotal: 4.77s\tremaining: 1m 25s\n",
      "53:\tlearn: 0.0111183\ttotal: 4.85s\tremaining: 1m 24s\n",
      "54:\tlearn: 0.0111183\ttotal: 4.91s\tremaining: 1m 24s\n",
      "55:\tlearn: 0.0111183\ttotal: 4.97s\tremaining: 1m 23s\n",
      "56:\tlearn: 0.0111183\ttotal: 5.04s\tremaining: 1m 23s\n",
      "57:\tlearn: 0.0111183\ttotal: 5.1s\tremaining: 1m 22s\n",
      "58:\tlearn: 0.0111183\ttotal: 5.17s\tremaining: 1m 22s\n",
      "59:\tlearn: 0.0111183\ttotal: 5.25s\tremaining: 1m 22s\n",
      "60:\tlearn: 0.0111181\ttotal: 5.32s\tremaining: 1m 21s\n",
      "61:\tlearn: 0.0111181\ttotal: 5.38s\tremaining: 1m 21s\n",
      "62:\tlearn: 0.0111180\ttotal: 5.45s\tremaining: 1m 21s\n",
      "63:\tlearn: 0.0111180\ttotal: 5.54s\tremaining: 1m 21s\n",
      "64:\tlearn: 0.0111179\ttotal: 5.64s\tremaining: 1m 21s\n",
      "65:\tlearn: 0.0111179\ttotal: 5.71s\tremaining: 1m 20s\n",
      "66:\tlearn: 0.0111179\ttotal: 5.79s\tremaining: 1m 20s\n",
      "67:\tlearn: 0.0111178\ttotal: 5.86s\tremaining: 1m 20s\n",
      "68:\tlearn: 0.0111176\ttotal: 5.92s\tremaining: 1m 19s\n",
      "69:\tlearn: 0.0111175\ttotal: 5.99s\tremaining: 1m 19s\n",
      "70:\tlearn: 0.0111174\ttotal: 6.06s\tremaining: 1m 19s\n",
      "71:\tlearn: 0.0111174\ttotal: 6.12s\tremaining: 1m 18s\n",
      "72:\tlearn: 0.0111174\ttotal: 6.19s\tremaining: 1m 18s\n",
      "73:\tlearn: 0.0111173\ttotal: 6.27s\tremaining: 1m 18s\n",
      "74:\tlearn: 0.0111172\ttotal: 6.35s\tremaining: 1m 18s\n",
      "75:\tlearn: 0.0111171\ttotal: 6.43s\tremaining: 1m 18s\n",
      "76:\tlearn: 0.0111171\ttotal: 6.5s\tremaining: 1m 17s\n",
      "77:\tlearn: 0.0111170\ttotal: 6.57s\tremaining: 1m 17s\n",
      "78:\tlearn: 0.0111170\ttotal: 6.64s\tremaining: 1m 17s\n",
      "79:\tlearn: 0.0111168\ttotal: 6.71s\tremaining: 1m 17s\n",
      "80:\tlearn: 0.0111168\ttotal: 6.79s\tremaining: 1m 17s\n",
      "81:\tlearn: 0.0111167\ttotal: 6.88s\tremaining: 1m 17s\n",
      "82:\tlearn: 0.0111167\ttotal: 6.96s\tremaining: 1m 16s\n",
      "83:\tlearn: 0.0111166\ttotal: 7.03s\tremaining: 1m 16s\n",
      "84:\tlearn: 0.0111166\ttotal: 7.1s\tremaining: 1m 16s\n",
      "85:\tlearn: 0.0111166\ttotal: 7.17s\tremaining: 1m 16s\n",
      "86:\tlearn: 0.0111165\ttotal: 7.25s\tremaining: 1m 16s\n",
      "87:\tlearn: 0.0111165\ttotal: 7.33s\tremaining: 1m 16s\n",
      "88:\tlearn: 0.0111164\ttotal: 7.43s\tremaining: 1m 16s\n",
      "89:\tlearn: 0.0111164\ttotal: 7.52s\tremaining: 1m 16s\n",
      "90:\tlearn: 0.0107922\ttotal: 7.62s\tremaining: 1m 16s\n",
      "91:\tlearn: 0.0107922\ttotal: 7.7s\tremaining: 1m 15s\n",
      "92:\tlearn: 0.0107920\ttotal: 7.79s\tremaining: 1m 15s\n",
      "93:\tlearn: 0.0107920\ttotal: 7.86s\tremaining: 1m 15s\n",
      "94:\tlearn: 0.0107920\ttotal: 7.94s\tremaining: 1m 15s\n",
      "95:\tlearn: 0.0107919\ttotal: 8.02s\tremaining: 1m 15s\n",
      "96:\tlearn: 0.0107918\ttotal: 8.12s\tremaining: 1m 15s\n",
      "97:\tlearn: 0.0107918\ttotal: 8.2s\tremaining: 1m 15s\n",
      "98:\tlearn: 0.0107917\ttotal: 8.27s\tremaining: 1m 15s\n",
      "99:\tlearn: 0.0107915\ttotal: 8.34s\tremaining: 1m 15s\n",
      "100:\tlearn: 0.0107915\ttotal: 8.41s\tremaining: 1m 14s\n",
      "101:\tlearn: 0.0107915\ttotal: 8.48s\tremaining: 1m 14s\n",
      "102:\tlearn: 0.0107914\ttotal: 8.54s\tremaining: 1m 14s\n",
      "103:\tlearn: 0.0107914\ttotal: 8.62s\tremaining: 1m 14s\n",
      "104:\tlearn: 0.0107913\ttotal: 8.72s\tremaining: 1m 14s\n",
      "105:\tlearn: 0.0107913\ttotal: 8.8s\tremaining: 1m 14s\n",
      "106:\tlearn: 0.0107912\ttotal: 8.89s\tremaining: 1m 14s\n",
      "107:\tlearn: 0.0107911\ttotal: 8.96s\tremaining: 1m 13s\n",
      "108:\tlearn: 0.0107909\ttotal: 9.03s\tremaining: 1m 13s\n",
      "109:\tlearn: 0.0107908\ttotal: 9.1s\tremaining: 1m 13s\n",
      "110:\tlearn: 0.0107908\ttotal: 9.21s\tremaining: 1m 13s\n",
      "111:\tlearn: 0.0107908\ttotal: 9.3s\tremaining: 1m 13s\n",
      "112:\tlearn: 0.0107908\ttotal: 9.39s\tremaining: 1m 13s\n",
      "113:\tlearn: 0.0107902\ttotal: 9.47s\tremaining: 1m 13s\n",
      "114:\tlearn: 0.0107901\ttotal: 9.55s\tremaining: 1m 13s\n",
      "115:\tlearn: 0.0107900\ttotal: 9.62s\tremaining: 1m 13s\n",
      "116:\tlearn: 0.0107900\ttotal: 9.69s\tremaining: 1m 13s\n",
      "117:\tlearn: 0.0107899\ttotal: 9.79s\tremaining: 1m 13s\n",
      "118:\tlearn: 0.0107899\ttotal: 9.89s\tremaining: 1m 13s\n",
      "119:\tlearn: 0.0107898\ttotal: 9.98s\tremaining: 1m 13s\n",
      "120:\tlearn: 0.0107898\ttotal: 10.1s\tremaining: 1m 13s\n",
      "121:\tlearn: 0.0107897\ttotal: 10.1s\tremaining: 1m 12s\n",
      "122:\tlearn: 0.0107897\ttotal: 10.2s\tremaining: 1m 12s\n",
      "123:\tlearn: 0.0107897\ttotal: 10.3s\tremaining: 1m 12s\n",
      "124:\tlearn: 0.0107896\ttotal: 10.4s\tremaining: 1m 12s\n",
      "125:\tlearn: 0.0107895\ttotal: 10.5s\tremaining: 1m 12s\n",
      "126:\tlearn: 0.0107895\ttotal: 10.6s\tremaining: 1m 12s\n",
      "127:\tlearn: 0.0107895\ttotal: 10.7s\tremaining: 1m 12s\n",
      "128:\tlearn: 0.0107894\ttotal: 10.7s\tremaining: 1m 12s\n",
      "129:\tlearn: 0.0107894\ttotal: 10.8s\tremaining: 1m 12s\n",
      "130:\tlearn: 0.0107894\ttotal: 10.9s\tremaining: 1m 12s\n",
      "131:\tlearn: 0.0107892\ttotal: 10.9s\tremaining: 1m 12s\n",
      "132:\tlearn: 0.0107892\ttotal: 11s\tremaining: 1m 11s\n",
      "133:\tlearn: 0.0107891\ttotal: 11.1s\tremaining: 1m 11s\n",
      "134:\tlearn: 0.0107890\ttotal: 11.2s\tremaining: 1m 11s\n",
      "135:\tlearn: 0.0107890\ttotal: 11.3s\tremaining: 1m 11s\n",
      "136:\tlearn: 0.0107890\ttotal: 11.3s\tremaining: 1m 11s\n",
      "137:\tlearn: 0.0107890\ttotal: 11.4s\tremaining: 1m 11s\n",
      "138:\tlearn: 0.0107889\ttotal: 11.5s\tremaining: 1m 11s\n",
      "139:\tlearn: 0.0107889\ttotal: 11.6s\tremaining: 1m 11s\n",
      "140:\tlearn: 0.0107888\ttotal: 11.6s\tremaining: 1m 10s\n",
      "141:\tlearn: 0.0107888\ttotal: 11.7s\tremaining: 1m 10s\n",
      "142:\tlearn: 0.0107887\ttotal: 11.8s\tremaining: 1m 10s\n",
      "143:\tlearn: 0.0107886\ttotal: 11.9s\tremaining: 1m 10s\n",
      "144:\tlearn: 0.0107885\ttotal: 11.9s\tremaining: 1m 10s\n",
      "145:\tlearn: 0.0107885\ttotal: 12s\tremaining: 1m 10s\n",
      "146:\tlearn: 0.0107884\ttotal: 12.1s\tremaining: 1m 10s\n",
      "147:\tlearn: 0.0107883\ttotal: 12.1s\tremaining: 1m 9s\n",
      "148:\tlearn: 0.0107883\ttotal: 12.2s\tremaining: 1m 9s\n",
      "149:\tlearn: 0.0107882\ttotal: 12.3s\tremaining: 1m 9s\n",
      "150:\tlearn: 0.0107882\ttotal: 12.3s\tremaining: 1m 9s\n",
      "151:\tlearn: 0.0107881\ttotal: 12.4s\tremaining: 1m 9s\n",
      "152:\tlearn: 0.0107881\ttotal: 12.5s\tremaining: 1m 9s\n",
      "153:\tlearn: 0.0107881\ttotal: 12.6s\tremaining: 1m 9s\n",
      "154:\tlearn: 0.0107880\ttotal: 12.7s\tremaining: 1m 9s\n",
      "155:\tlearn: 0.0107879\ttotal: 12.8s\tremaining: 1m 9s\n",
      "156:\tlearn: 0.0107879\ttotal: 12.9s\tremaining: 1m 9s\n",
      "157:\tlearn: 0.0107878\ttotal: 12.9s\tremaining: 1m 8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158:\tlearn: 0.0107876\ttotal: 13s\tremaining: 1m 8s\n",
      "159:\tlearn: 0.0107875\ttotal: 13.1s\tremaining: 1m 8s\n",
      "160:\tlearn: 0.0107875\ttotal: 13.2s\tremaining: 1m 8s\n",
      "161:\tlearn: 0.0107873\ttotal: 13.3s\tremaining: 1m 8s\n",
      "162:\tlearn: 0.0107873\ttotal: 13.3s\tremaining: 1m 8s\n",
      "163:\tlearn: 0.0107873\ttotal: 13.4s\tremaining: 1m 8s\n",
      "164:\tlearn: 0.0107873\ttotal: 13.5s\tremaining: 1m 8s\n",
      "165:\tlearn: 0.0107873\ttotal: 13.6s\tremaining: 1m 8s\n",
      "166:\tlearn: 0.0107873\ttotal: 13.6s\tremaining: 1m 7s\n",
      "167:\tlearn: 0.0107873\ttotal: 13.7s\tremaining: 1m 7s\n",
      "168:\tlearn: 0.0107873\ttotal: 13.8s\tremaining: 1m 7s\n",
      "169:\tlearn: 0.0107873\ttotal: 13.8s\tremaining: 1m 7s\n",
      "170:\tlearn: 0.0107873\ttotal: 13.9s\tremaining: 1m 7s\n",
      "171:\tlearn: 0.0107873\ttotal: 14s\tremaining: 1m 7s\n",
      "172:\tlearn: 0.0107873\ttotal: 14.1s\tremaining: 1m 7s\n",
      "173:\tlearn: 0.0107873\ttotal: 14.1s\tremaining: 1m 7s\n",
      "174:\tlearn: 0.0107873\ttotal: 14.2s\tremaining: 1m 6s\n",
      "175:\tlearn: 0.0107873\ttotal: 14.3s\tremaining: 1m 6s\n",
      "176:\tlearn: 0.0107873\ttotal: 14.3s\tremaining: 1m 6s\n",
      "177:\tlearn: 0.0107873\ttotal: 14.4s\tremaining: 1m 6s\n",
      "178:\tlearn: 0.0107873\ttotal: 14.5s\tremaining: 1m 6s\n",
      "179:\tlearn: 0.0107873\ttotal: 14.6s\tremaining: 1m 6s\n",
      "180:\tlearn: 0.0107873\ttotal: 14.6s\tremaining: 1m 6s\n",
      "181:\tlearn: 0.0107873\ttotal: 14.7s\tremaining: 1m 6s\n",
      "182:\tlearn: 0.0107873\ttotal: 14.8s\tremaining: 1m 5s\n",
      "183:\tlearn: 0.0107871\ttotal: 14.8s\tremaining: 1m 5s\n",
      "184:\tlearn: 0.0107871\ttotal: 14.9s\tremaining: 1m 5s\n",
      "185:\tlearn: 0.0107871\ttotal: 15s\tremaining: 1m 5s\n",
      "186:\tlearn: 0.0107871\ttotal: 15.1s\tremaining: 1m 5s\n",
      "187:\tlearn: 0.0107871\ttotal: 15.1s\tremaining: 1m 5s\n",
      "188:\tlearn: 0.0107871\ttotal: 15.2s\tremaining: 1m 5s\n",
      "189:\tlearn: 0.0107871\ttotal: 15.3s\tremaining: 1m 5s\n",
      "190:\tlearn: 0.0107871\ttotal: 15.4s\tremaining: 1m 5s\n",
      "191:\tlearn: 0.0107871\ttotal: 15.4s\tremaining: 1m 4s\n",
      "192:\tlearn: 0.0107871\ttotal: 15.5s\tremaining: 1m 4s\n",
      "193:\tlearn: 0.0107871\ttotal: 15.6s\tremaining: 1m 4s\n",
      "194:\tlearn: 0.0107871\ttotal: 15.6s\tremaining: 1m 4s\n",
      "195:\tlearn: 0.0107870\ttotal: 15.7s\tremaining: 1m 4s\n",
      "196:\tlearn: 0.0107868\ttotal: 15.8s\tremaining: 1m 4s\n",
      "197:\tlearn: 0.0107867\ttotal: 15.8s\tremaining: 1m 4s\n",
      "198:\tlearn: 0.0107867\ttotal: 15.9s\tremaining: 1m 4s\n",
      "199:\tlearn: 0.0107866\ttotal: 16s\tremaining: 1m 4s\n",
      "200:\tlearn: 0.0107866\ttotal: 16.1s\tremaining: 1m 3s\n",
      "201:\tlearn: 0.0107863\ttotal: 16.2s\tremaining: 1m 3s\n",
      "202:\tlearn: 0.0107862\ttotal: 16.2s\tremaining: 1m 3s\n",
      "203:\tlearn: 0.0107862\ttotal: 16.3s\tremaining: 1m 3s\n",
      "204:\tlearn: 0.0107862\ttotal: 16.4s\tremaining: 1m 3s\n",
      "205:\tlearn: 0.0107862\ttotal: 16.5s\tremaining: 1m 3s\n",
      "206:\tlearn: 0.0107861\ttotal: 16.5s\tremaining: 1m 3s\n",
      "207:\tlearn: 0.0107861\ttotal: 16.6s\tremaining: 1m 3s\n",
      "208:\tlearn: 0.0107860\ttotal: 16.7s\tremaining: 1m 3s\n",
      "209:\tlearn: 0.0107858\ttotal: 16.8s\tremaining: 1m 3s\n",
      "210:\tlearn: 0.0107857\ttotal: 16.9s\tremaining: 1m 3s\n",
      "211:\tlearn: 0.0107855\ttotal: 17s\tremaining: 1m 3s\n",
      "212:\tlearn: 0.0107855\ttotal: 17s\tremaining: 1m 2s\n",
      "213:\tlearn: 0.0107855\ttotal: 17.1s\tremaining: 1m 2s\n",
      "214:\tlearn: 0.0107855\ttotal: 17.2s\tremaining: 1m 2s\n",
      "215:\tlearn: 0.0107855\ttotal: 17.2s\tremaining: 1m 2s\n",
      "216:\tlearn: 0.0107855\ttotal: 17.3s\tremaining: 1m 2s\n",
      "217:\tlearn: 0.0107855\ttotal: 17.4s\tremaining: 1m 2s\n",
      "218:\tlearn: 0.0107855\ttotal: 17.4s\tremaining: 1m 2s\n",
      "219:\tlearn: 0.0107855\ttotal: 17.5s\tremaining: 1m 2s\n",
      "220:\tlearn: 0.0107855\ttotal: 17.6s\tremaining: 1m 2s\n",
      "221:\tlearn: 0.0107855\ttotal: 17.7s\tremaining: 1m 1s\n",
      "222:\tlearn: 0.0107855\ttotal: 17.8s\tremaining: 1m 2s\n",
      "223:\tlearn: 0.0107855\ttotal: 17.9s\tremaining: 1m 1s\n",
      "224:\tlearn: 0.0107855\ttotal: 18s\tremaining: 1m 1s\n",
      "225:\tlearn: 0.0107855\ttotal: 18s\tremaining: 1m 1s\n",
      "226:\tlearn: 0.0107855\ttotal: 18.1s\tremaining: 1m 1s\n",
      "227:\tlearn: 0.0107855\ttotal: 18.2s\tremaining: 1m 1s\n",
      "228:\tlearn: 0.0107855\ttotal: 18.2s\tremaining: 1m 1s\n",
      "229:\tlearn: 0.0107855\ttotal: 18.3s\tremaining: 1m 1s\n",
      "230:\tlearn: 0.0107854\ttotal: 18.4s\tremaining: 1m 1s\n",
      "231:\tlearn: 0.0107854\ttotal: 18.4s\tremaining: 1m 1s\n",
      "232:\tlearn: 0.0107854\ttotal: 18.5s\tremaining: 1m\n",
      "233:\tlearn: 0.0107854\ttotal: 18.6s\tremaining: 1m\n",
      "234:\tlearn: 0.0107854\ttotal: 18.6s\tremaining: 1m\n",
      "235:\tlearn: 0.0107854\ttotal: 18.7s\tremaining: 1m\n",
      "236:\tlearn: 0.0107854\ttotal: 18.8s\tremaining: 1m\n",
      "237:\tlearn: 0.0107854\ttotal: 18.9s\tremaining: 1m\n",
      "238:\tlearn: 0.0107854\ttotal: 18.9s\tremaining: 1m\n",
      "239:\tlearn: 0.0107854\ttotal: 19s\tremaining: 1m\n",
      "240:\tlearn: 0.0107854\ttotal: 19.1s\tremaining: 1m\n",
      "241:\tlearn: 0.0107854\ttotal: 19.1s\tremaining: 59.9s\n",
      "242:\tlearn: 0.0107854\ttotal: 19.2s\tremaining: 59.8s\n",
      "243:\tlearn: 0.0107854\ttotal: 19.3s\tremaining: 59.7s\n",
      "244:\tlearn: 0.0107854\ttotal: 19.3s\tremaining: 59.6s\n",
      "245:\tlearn: 0.0107854\ttotal: 19.4s\tremaining: 59.5s\n",
      "246:\tlearn: 0.0107854\ttotal: 19.5s\tremaining: 59.4s\n",
      "247:\tlearn: 0.0107854\ttotal: 19.5s\tremaining: 59.3s\n",
      "248:\tlearn: 0.0107854\ttotal: 19.6s\tremaining: 59.2s\n",
      "249:\tlearn: 0.0107854\ttotal: 19.7s\tremaining: 59.1s\n",
      "250:\tlearn: 0.0107854\ttotal: 19.8s\tremaining: 58.9s\n",
      "251:\tlearn: 0.0107854\ttotal: 19.8s\tremaining: 58.8s\n",
      "252:\tlearn: 0.0107854\ttotal: 19.9s\tremaining: 58.8s\n",
      "253:\tlearn: 0.0107854\ttotal: 20s\tremaining: 58.7s\n",
      "254:\tlearn: 0.0107854\ttotal: 20.1s\tremaining: 58.6s\n",
      "255:\tlearn: 0.0107854\ttotal: 20.1s\tremaining: 58.5s\n",
      "256:\tlearn: 0.0107854\ttotal: 20.2s\tremaining: 58.4s\n",
      "257:\tlearn: 0.0107854\ttotal: 20.3s\tremaining: 58.3s\n",
      "258:\tlearn: 0.0107854\ttotal: 20.3s\tremaining: 58.2s\n",
      "259:\tlearn: 0.0107854\ttotal: 20.4s\tremaining: 58.1s\n",
      "260:\tlearn: 0.0107854\ttotal: 20.5s\tremaining: 58s\n",
      "261:\tlearn: 0.0107854\ttotal: 20.5s\tremaining: 57.9s\n",
      "262:\tlearn: 0.0107854\ttotal: 20.6s\tremaining: 57.8s\n",
      "263:\tlearn: 0.0107854\ttotal: 20.7s\tremaining: 57.7s\n",
      "264:\tlearn: 0.0107854\ttotal: 20.8s\tremaining: 57.6s\n",
      "265:\tlearn: 0.0107854\ttotal: 20.8s\tremaining: 57.5s\n",
      "266:\tlearn: 0.0107854\ttotal: 20.9s\tremaining: 57.4s\n",
      "267:\tlearn: 0.0107854\ttotal: 21s\tremaining: 57.3s\n",
      "268:\tlearn: 0.0107854\ttotal: 21s\tremaining: 57.2s\n",
      "269:\tlearn: 0.0107854\ttotal: 21.1s\tremaining: 57.1s\n",
      "270:\tlearn: 0.0107854\ttotal: 21.2s\tremaining: 57s\n",
      "271:\tlearn: 0.0107854\ttotal: 21.3s\tremaining: 56.9s\n",
      "272:\tlearn: 0.0107854\ttotal: 21.3s\tremaining: 56.8s\n",
      "273:\tlearn: 0.0107854\ttotal: 21.4s\tremaining: 56.7s\n",
      "274:\tlearn: 0.0107854\ttotal: 21.5s\tremaining: 56.6s\n",
      "275:\tlearn: 0.0107854\ttotal: 21.5s\tremaining: 56.5s\n",
      "276:\tlearn: 0.0107854\ttotal: 21.6s\tremaining: 56.4s\n",
      "277:\tlearn: 0.0107854\ttotal: 21.7s\tremaining: 56.3s\n",
      "278:\tlearn: 0.0104617\ttotal: 21.8s\tremaining: 56.3s\n",
      "279:\tlearn: 0.0104617\ttotal: 21.9s\tremaining: 56.2s\n",
      "280:\tlearn: 0.0102054\ttotal: 22s\tremaining: 56.2s\n",
      "281:\tlearn: 0.0101236\ttotal: 22s\tremaining: 56.1s\n",
      "282:\tlearn: 0.0100260\ttotal: 22.1s\tremaining: 56.1s\n",
      "283:\tlearn: 0.0098869\ttotal: 22.2s\tremaining: 56s\n",
      "284:\tlearn: 0.0097988\ttotal: 22.3s\tremaining: 56s\n",
      "285:\tlearn: 0.0097988\ttotal: 22.4s\tremaining: 55.8s\n",
      "286:\tlearn: 0.0096730\ttotal: 22.5s\tremaining: 55.8s\n",
      "287:\tlearn: 0.0095984\ttotal: 22.6s\tremaining: 55.8s\n",
      "288:\tlearn: 0.0095086\ttotal: 22.7s\tremaining: 55.7s\n",
      "289:\tlearn: 0.0094061\ttotal: 22.7s\tremaining: 55.7s\n",
      "290:\tlearn: 0.0094059\ttotal: 22.8s\tremaining: 55.6s\n",
      "291:\tlearn: 0.0094058\ttotal: 22.9s\tremaining: 55.5s\n",
      "292:\tlearn: 0.0094057\ttotal: 23s\tremaining: 55.4s\n",
      "293:\tlearn: 0.0094057\ttotal: 23s\tremaining: 55.3s\n",
      "294:\tlearn: 0.0094057\ttotal: 23.1s\tremaining: 55.2s\n",
      "295:\tlearn: 0.0094056\ttotal: 23.2s\tremaining: 55.1s\n",
      "296:\tlearn: 0.0094055\ttotal: 23.2s\tremaining: 55s\n",
      "297:\tlearn: 0.0094053\ttotal: 23.3s\tremaining: 54.9s\n",
      "298:\tlearn: 0.0094050\ttotal: 23.4s\tremaining: 54.8s\n",
      "299:\tlearn: 0.0094050\ttotal: 23.4s\tremaining: 54.7s\n",
      "300:\tlearn: 0.0093564\ttotal: 23.5s\tremaining: 54.6s\n",
      "301:\tlearn: 0.0092720\ttotal: 23.6s\tremaining: 54.6s\n",
      "302:\tlearn: 0.0092193\ttotal: 23.7s\tremaining: 54.5s\n",
      "303:\tlearn: 0.0090486\ttotal: 23.8s\tremaining: 54.4s\n",
      "304:\tlearn: 0.0089607\ttotal: 23.9s\tremaining: 54.4s\n",
      "305:\tlearn: 0.0088862\ttotal: 23.9s\tremaining: 54.3s\n",
      "306:\tlearn: 0.0088861\ttotal: 24s\tremaining: 54.2s\n",
      "307:\tlearn: 0.0088861\ttotal: 24.1s\tremaining: 54.1s\n",
      "308:\tlearn: 0.0088860\ttotal: 24.2s\tremaining: 54s\n",
      "309:\tlearn: 0.0088859\ttotal: 24.2s\tremaining: 53.9s\n",
      "310:\tlearn: 0.0088306\ttotal: 24.3s\tremaining: 53.9s\n",
      "311:\tlearn: 0.0087057\ttotal: 24.4s\tremaining: 53.8s\n",
      "312:\tlearn: 0.0086084\ttotal: 24.5s\tremaining: 53.8s\n",
      "313:\tlearn: 0.0086084\ttotal: 24.6s\tremaining: 53.7s\n",
      "314:\tlearn: 0.0086083\ttotal: 24.6s\tremaining: 53.6s\n",
      "315:\tlearn: 0.0086083\ttotal: 24.7s\tremaining: 53.5s\n",
      "316:\tlearn: 0.0086081\ttotal: 24.8s\tremaining: 53.4s\n",
      "317:\tlearn: 0.0086080\ttotal: 24.8s\tremaining: 53.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318:\tlearn: 0.0086080\ttotal: 24.9s\tremaining: 53.2s\n",
      "319:\tlearn: 0.0086079\ttotal: 25s\tremaining: 53.1s\n",
      "320:\tlearn: 0.0086079\ttotal: 25s\tremaining: 53s\n",
      "321:\tlearn: 0.0086079\ttotal: 25.1s\tremaining: 52.9s\n",
      "322:\tlearn: 0.0086077\ttotal: 25.2s\tremaining: 52.8s\n",
      "323:\tlearn: 0.0086076\ttotal: 25.2s\tremaining: 52.7s\n",
      "324:\tlearn: 0.0086076\ttotal: 25.3s\tremaining: 52.6s\n",
      "325:\tlearn: 0.0086076\ttotal: 25.4s\tremaining: 52.5s\n",
      "326:\tlearn: 0.0086074\ttotal: 25.4s\tremaining: 52.4s\n",
      "327:\tlearn: 0.0086073\ttotal: 25.5s\tremaining: 52.3s\n",
      "328:\tlearn: 0.0086073\ttotal: 25.6s\tremaining: 52.2s\n",
      "329:\tlearn: 0.0086069\ttotal: 25.7s\tremaining: 52.1s\n",
      "330:\tlearn: 0.0086068\ttotal: 25.7s\tremaining: 52s\n",
      "331:\tlearn: 0.0086068\ttotal: 25.8s\tremaining: 51.9s\n",
      "332:\tlearn: 0.0086066\ttotal: 25.9s\tremaining: 51.8s\n",
      "333:\tlearn: 0.0086065\ttotal: 25.9s\tremaining: 51.7s\n",
      "334:\tlearn: 0.0086064\ttotal: 26s\tremaining: 51.6s\n",
      "335:\tlearn: 0.0086063\ttotal: 26.1s\tremaining: 51.5s\n",
      "336:\tlearn: 0.0086062\ttotal: 26.2s\tremaining: 51.5s\n",
      "337:\tlearn: 0.0085800\ttotal: 26.2s\tremaining: 51.4s\n",
      "338:\tlearn: 0.0085796\ttotal: 26.3s\tremaining: 51.3s\n",
      "339:\tlearn: 0.0085796\ttotal: 26.4s\tremaining: 51.2s\n",
      "340:\tlearn: 0.0085795\ttotal: 26.4s\tremaining: 51.1s\n",
      "341:\tlearn: 0.0085791\ttotal: 26.5s\tremaining: 51s\n",
      "342:\tlearn: 0.0085791\ttotal: 26.6s\tremaining: 50.9s\n",
      "343:\tlearn: 0.0085789\ttotal: 26.6s\tremaining: 50.8s\n",
      "344:\tlearn: 0.0085785\ttotal: 26.7s\tremaining: 50.7s\n",
      "345:\tlearn: 0.0085785\ttotal: 26.8s\tremaining: 50.6s\n",
      "346:\tlearn: 0.0085785\ttotal: 26.8s\tremaining: 50.5s\n",
      "347:\tlearn: 0.0085784\ttotal: 26.9s\tremaining: 50.4s\n",
      "348:\tlearn: 0.0085780\ttotal: 27s\tremaining: 50.3s\n",
      "349:\tlearn: 0.0085779\ttotal: 27s\tremaining: 50.2s\n",
      "350:\tlearn: 0.0085779\ttotal: 27.1s\tremaining: 50.1s\n",
      "351:\tlearn: 0.0085779\ttotal: 27.2s\tremaining: 50s\n",
      "352:\tlearn: 0.0085778\ttotal: 27.3s\tremaining: 49.9s\n",
      "353:\tlearn: 0.0085778\ttotal: 27.3s\tremaining: 49.8s\n",
      "354:\tlearn: 0.0085778\ttotal: 27.4s\tremaining: 49.7s\n",
      "355:\tlearn: 0.0085774\ttotal: 27.4s\tremaining: 49.7s\n",
      "356:\tlearn: 0.0085773\ttotal: 27.5s\tremaining: 49.6s\n",
      "357:\tlearn: 0.0085772\ttotal: 27.6s\tremaining: 49.5s\n",
      "358:\tlearn: 0.0085771\ttotal: 27.6s\tremaining: 49.4s\n",
      "359:\tlearn: 0.0085770\ttotal: 27.7s\tremaining: 49.3s\n",
      "360:\tlearn: 0.0085769\ttotal: 27.8s\tremaining: 49.2s\n",
      "361:\tlearn: 0.0085769\ttotal: 27.9s\tremaining: 49.1s\n",
      "362:\tlearn: 0.0085765\ttotal: 27.9s\tremaining: 49s\n",
      "363:\tlearn: 0.0085764\ttotal: 28s\tremaining: 48.9s\n",
      "364:\tlearn: 0.0085764\ttotal: 28.1s\tremaining: 48.8s\n",
      "365:\tlearn: 0.0085764\ttotal: 28.1s\tremaining: 48.7s\n",
      "366:\tlearn: 0.0085764\ttotal: 28.2s\tremaining: 48.6s\n",
      "367:\tlearn: 0.0085764\ttotal: 28.3s\tremaining: 48.6s\n",
      "368:\tlearn: 0.0085763\ttotal: 28.3s\tremaining: 48.5s\n",
      "369:\tlearn: 0.0085763\ttotal: 28.4s\tremaining: 48.4s\n",
      "370:\tlearn: 0.0085763\ttotal: 28.5s\tremaining: 48.3s\n",
      "371:\tlearn: 0.0085763\ttotal: 28.5s\tremaining: 48.2s\n",
      "372:\tlearn: 0.0085763\ttotal: 28.6s\tremaining: 48.1s\n",
      "373:\tlearn: 0.0085763\ttotal: 28.7s\tremaining: 48s\n",
      "374:\tlearn: 0.0085763\ttotal: 28.8s\tremaining: 47.9s\n",
      "375:\tlearn: 0.0085763\ttotal: 28.8s\tremaining: 47.8s\n",
      "376:\tlearn: 0.0085763\ttotal: 28.9s\tremaining: 47.8s\n",
      "377:\tlearn: 0.0085762\ttotal: 29s\tremaining: 47.7s\n",
      "378:\tlearn: 0.0085762\ttotal: 29s\tremaining: 47.6s\n",
      "379:\tlearn: 0.0085762\ttotal: 29.1s\tremaining: 47.5s\n",
      "380:\tlearn: 0.0085762\ttotal: 29.2s\tremaining: 47.4s\n",
      "381:\tlearn: 0.0085762\ttotal: 29.2s\tremaining: 47.3s\n",
      "382:\tlearn: 0.0085760\ttotal: 29.3s\tremaining: 47.2s\n",
      "383:\tlearn: 0.0085760\ttotal: 29.4s\tremaining: 47.2s\n",
      "384:\tlearn: 0.0085759\ttotal: 29.5s\tremaining: 47.1s\n",
      "385:\tlearn: 0.0085758\ttotal: 29.5s\tremaining: 47s\n",
      "386:\tlearn: 0.0085757\ttotal: 29.6s\tremaining: 46.9s\n",
      "387:\tlearn: 0.0085757\ttotal: 29.7s\tremaining: 46.8s\n",
      "388:\tlearn: 0.0085757\ttotal: 29.7s\tremaining: 46.7s\n",
      "389:\tlearn: 0.0085756\ttotal: 29.8s\tremaining: 46.6s\n",
      "390:\tlearn: 0.0085755\ttotal: 29.9s\tremaining: 46.5s\n",
      "391:\tlearn: 0.0085755\ttotal: 29.9s\tremaining: 46.4s\n",
      "392:\tlearn: 0.0085754\ttotal: 30s\tremaining: 46.3s\n",
      "393:\tlearn: 0.0085753\ttotal: 30.1s\tremaining: 46.2s\n",
      "394:\tlearn: 0.0085752\ttotal: 30.1s\tremaining: 46.2s\n",
      "395:\tlearn: 0.0085752\ttotal: 30.2s\tremaining: 46.1s\n",
      "396:\tlearn: 0.0085751\ttotal: 30.3s\tremaining: 46s\n",
      "397:\tlearn: 0.0085750\ttotal: 30.3s\tremaining: 45.9s\n",
      "398:\tlearn: 0.0085749\ttotal: 30.4s\tremaining: 45.8s\n",
      "399:\tlearn: 0.0085748\ttotal: 30.5s\tremaining: 45.7s\n",
      "400:\tlearn: 0.0085747\ttotal: 30.5s\tremaining: 45.6s\n",
      "401:\tlearn: 0.0085747\ttotal: 30.6s\tremaining: 45.5s\n",
      "402:\tlearn: 0.0085747\ttotal: 30.7s\tremaining: 45.5s\n",
      "403:\tlearn: 0.0085746\ttotal: 30.8s\tremaining: 45.4s\n",
      "404:\tlearn: 0.0085745\ttotal: 30.8s\tremaining: 45.3s\n",
      "405:\tlearn: 0.0085744\ttotal: 30.9s\tremaining: 45.2s\n",
      "406:\tlearn: 0.0085743\ttotal: 31s\tremaining: 45.1s\n",
      "407:\tlearn: 0.0085743\ttotal: 31s\tremaining: 45s\n",
      "408:\tlearn: 0.0085743\ttotal: 31.1s\tremaining: 44.9s\n",
      "409:\tlearn: 0.0085743\ttotal: 31.2s\tremaining: 44.9s\n",
      "410:\tlearn: 0.0085743\ttotal: 31.2s\tremaining: 44.8s\n",
      "411:\tlearn: 0.0085743\ttotal: 31.3s\tremaining: 44.7s\n",
      "412:\tlearn: 0.0085743\ttotal: 31.4s\tremaining: 44.6s\n",
      "413:\tlearn: 0.0085743\ttotal: 31.4s\tremaining: 44.5s\n",
      "414:\tlearn: 0.0085743\ttotal: 31.5s\tremaining: 44.4s\n",
      "415:\tlearn: 0.0085743\ttotal: 31.6s\tremaining: 44.3s\n",
      "416:\tlearn: 0.0085743\ttotal: 31.7s\tremaining: 44.3s\n",
      "417:\tlearn: 0.0085743\ttotal: 31.7s\tremaining: 44.2s\n",
      "418:\tlearn: 0.0085743\ttotal: 31.8s\tremaining: 44.1s\n",
      "419:\tlearn: 0.0085743\ttotal: 31.9s\tremaining: 44s\n",
      "420:\tlearn: 0.0085743\ttotal: 31.9s\tremaining: 43.9s\n",
      "421:\tlearn: 0.0085743\ttotal: 32s\tremaining: 43.8s\n",
      "422:\tlearn: 0.0085743\ttotal: 32.1s\tremaining: 43.8s\n",
      "423:\tlearn: 0.0085742\ttotal: 32.1s\tremaining: 43.7s\n",
      "424:\tlearn: 0.0085742\ttotal: 32.2s\tremaining: 43.6s\n",
      "425:\tlearn: 0.0085742\ttotal: 32.3s\tremaining: 43.5s\n",
      "426:\tlearn: 0.0085742\ttotal: 32.4s\tremaining: 43.4s\n",
      "427:\tlearn: 0.0085741\ttotal: 32.4s\tremaining: 43.3s\n",
      "428:\tlearn: 0.0085741\ttotal: 32.5s\tremaining: 43.3s\n",
      "429:\tlearn: 0.0085741\ttotal: 32.6s\tremaining: 43.2s\n",
      "430:\tlearn: 0.0085741\ttotal: 32.6s\tremaining: 43.1s\n",
      "431:\tlearn: 0.0085741\ttotal: 32.7s\tremaining: 43s\n",
      "432:\tlearn: 0.0085741\ttotal: 32.8s\tremaining: 42.9s\n",
      "433:\tlearn: 0.0085741\ttotal: 32.8s\tremaining: 42.8s\n",
      "434:\tlearn: 0.0085741\ttotal: 32.9s\tremaining: 42.7s\n",
      "435:\tlearn: 0.0085740\ttotal: 33s\tremaining: 42.7s\n",
      "436:\tlearn: 0.0085740\ttotal: 33s\tremaining: 42.6s\n",
      "437:\tlearn: 0.0085740\ttotal: 33.1s\tremaining: 42.5s\n",
      "438:\tlearn: 0.0085740\ttotal: 33.2s\tremaining: 42.4s\n",
      "439:\tlearn: 0.0085740\ttotal: 33.3s\tremaining: 42.3s\n",
      "440:\tlearn: 0.0085739\ttotal: 33.3s\tremaining: 42.2s\n",
      "441:\tlearn: 0.0085739\ttotal: 33.4s\tremaining: 42.2s\n",
      "442:\tlearn: 0.0085739\ttotal: 33.5s\tremaining: 42.1s\n",
      "443:\tlearn: 0.0085738\ttotal: 33.5s\tremaining: 42s\n",
      "444:\tlearn: 0.0085738\ttotal: 33.6s\tremaining: 41.9s\n",
      "445:\tlearn: 0.0085738\ttotal: 33.7s\tremaining: 41.8s\n",
      "446:\tlearn: 0.0085737\ttotal: 33.7s\tremaining: 41.7s\n",
      "447:\tlearn: 0.0085737\ttotal: 33.8s\tremaining: 41.6s\n",
      "448:\tlearn: 0.0085737\ttotal: 33.9s\tremaining: 41.6s\n",
      "449:\tlearn: 0.0085736\ttotal: 33.9s\tremaining: 41.5s\n",
      "450:\tlearn: 0.0085736\ttotal: 34s\tremaining: 41.4s\n",
      "451:\tlearn: 0.0085736\ttotal: 34.1s\tremaining: 41.3s\n",
      "452:\tlearn: 0.0085736\ttotal: 34.2s\tremaining: 41.2s\n",
      "453:\tlearn: 0.0085736\ttotal: 34.2s\tremaining: 41.2s\n",
      "454:\tlearn: 0.0085735\ttotal: 34.3s\tremaining: 41.1s\n",
      "455:\tlearn: 0.0084061\ttotal: 34.4s\tremaining: 41s\n",
      "456:\tlearn: 0.0083319\ttotal: 34.5s\tremaining: 40.9s\n",
      "457:\tlearn: 0.0083319\ttotal: 34.5s\tremaining: 40.9s\n",
      "458:\tlearn: 0.0083318\ttotal: 34.6s\tremaining: 40.8s\n",
      "459:\tlearn: 0.0083318\ttotal: 34.7s\tremaining: 40.7s\n",
      "460:\tlearn: 0.0083318\ttotal: 34.7s\tremaining: 40.6s\n",
      "461:\tlearn: 0.0083318\ttotal: 34.8s\tremaining: 40.5s\n",
      "462:\tlearn: 0.0083317\ttotal: 34.9s\tremaining: 40.4s\n",
      "463:\tlearn: 0.0083316\ttotal: 34.9s\tremaining: 40.4s\n",
      "464:\tlearn: 0.0083315\ttotal: 35s\tremaining: 40.3s\n",
      "465:\tlearn: 0.0083315\ttotal: 35.1s\tremaining: 40.2s\n",
      "466:\tlearn: 0.0083314\ttotal: 35.2s\tremaining: 40.1s\n",
      "467:\tlearn: 0.0083314\ttotal: 35.2s\tremaining: 40.1s\n",
      "468:\tlearn: 0.0083314\ttotal: 35.3s\tremaining: 40s\n",
      "469:\tlearn: 0.0083314\ttotal: 35.4s\tremaining: 39.9s\n",
      "470:\tlearn: 0.0083314\ttotal: 35.5s\tremaining: 39.8s\n",
      "471:\tlearn: 0.0083314\ttotal: 35.5s\tremaining: 39.8s\n",
      "472:\tlearn: 0.0083314\ttotal: 35.6s\tremaining: 39.7s\n",
      "473:\tlearn: 0.0083314\ttotal: 35.7s\tremaining: 39.6s\n",
      "474:\tlearn: 0.0083314\ttotal: 35.7s\tremaining: 39.5s\n",
      "475:\tlearn: 0.0083314\ttotal: 35.8s\tremaining: 39.4s\n",
      "476:\tlearn: 0.0083314\ttotal: 35.9s\tremaining: 39.3s\n",
      "477:\tlearn: 0.0083314\ttotal: 35.9s\tremaining: 39.3s\n",
      "478:\tlearn: 0.0083314\ttotal: 36s\tremaining: 39.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479:\tlearn: 0.0083314\ttotal: 36.1s\tremaining: 39.1s\n",
      "480:\tlearn: 0.0083314\ttotal: 36.2s\tremaining: 39s\n",
      "481:\tlearn: 0.0083314\ttotal: 36.2s\tremaining: 38.9s\n",
      "482:\tlearn: 0.0083314\ttotal: 36.3s\tremaining: 38.9s\n",
      "483:\tlearn: 0.0083314\ttotal: 36.4s\tremaining: 38.8s\n",
      "484:\tlearn: 0.0083314\ttotal: 36.5s\tremaining: 38.7s\n",
      "485:\tlearn: 0.0083314\ttotal: 36.5s\tremaining: 38.6s\n",
      "486:\tlearn: 0.0082337\ttotal: 36.6s\tremaining: 38.6s\n",
      "487:\tlearn: 0.0082336\ttotal: 36.7s\tremaining: 38.5s\n",
      "488:\tlearn: 0.0082335\ttotal: 36.8s\tremaining: 38.4s\n",
      "489:\tlearn: 0.0082335\ttotal: 36.8s\tremaining: 38.3s\n",
      "490:\tlearn: 0.0082335\ttotal: 36.9s\tremaining: 38.2s\n",
      "491:\tlearn: 0.0082335\ttotal: 37s\tremaining: 38.2s\n",
      "492:\tlearn: 0.0082335\ttotal: 37s\tremaining: 38.1s\n",
      "493:\tlearn: 0.0082335\ttotal: 37.1s\tremaining: 38s\n",
      "494:\tlearn: 0.0082335\ttotal: 37.2s\tremaining: 37.9s\n",
      "495:\tlearn: 0.0082335\ttotal: 37.2s\tremaining: 37.8s\n",
      "496:\tlearn: 0.0082335\ttotal: 37.3s\tremaining: 37.8s\n",
      "497:\tlearn: 0.0082335\ttotal: 37.4s\tremaining: 37.7s\n",
      "498:\tlearn: 0.0082335\ttotal: 37.4s\tremaining: 37.6s\n",
      "499:\tlearn: 0.0081788\ttotal: 37.5s\tremaining: 37.5s\n",
      "500:\tlearn: 0.0078967\ttotal: 37.6s\tremaining: 37.5s\n",
      "501:\tlearn: 0.0078967\ttotal: 37.7s\tremaining: 37.4s\n",
      "502:\tlearn: 0.0078966\ttotal: 37.8s\tremaining: 37.3s\n",
      "503:\tlearn: 0.0077817\ttotal: 37.9s\tremaining: 37.3s\n",
      "504:\tlearn: 0.0077816\ttotal: 37.9s\tremaining: 37.2s\n",
      "505:\tlearn: 0.0076533\ttotal: 38s\tremaining: 37.1s\n",
      "506:\tlearn: 0.0076014\ttotal: 38.1s\tremaining: 37.1s\n",
      "507:\tlearn: 0.0074585\ttotal: 38.2s\tremaining: 37s\n",
      "508:\tlearn: 0.0074585\ttotal: 38.3s\tremaining: 36.9s\n",
      "509:\tlearn: 0.0074583\ttotal: 38.4s\tremaining: 36.9s\n",
      "510:\tlearn: 0.0074583\ttotal: 38.4s\tremaining: 36.8s\n",
      "511:\tlearn: 0.0074583\ttotal: 38.5s\tremaining: 36.7s\n",
      "512:\tlearn: 0.0074583\ttotal: 38.6s\tremaining: 36.6s\n",
      "513:\tlearn: 0.0074583\ttotal: 38.7s\tremaining: 36.6s\n",
      "514:\tlearn: 0.0074057\ttotal: 38.7s\tremaining: 36.5s\n",
      "515:\tlearn: 0.0074056\ttotal: 38.8s\tremaining: 36.4s\n",
      "516:\tlearn: 0.0074056\ttotal: 38.9s\tremaining: 36.3s\n",
      "517:\tlearn: 0.0074056\ttotal: 39s\tremaining: 36.2s\n",
      "518:\tlearn: 0.0074055\ttotal: 39s\tremaining: 36.2s\n",
      "519:\tlearn: 0.0074055\ttotal: 39.1s\tremaining: 36.1s\n",
      "520:\tlearn: 0.0074055\ttotal: 39.2s\tremaining: 36s\n",
      "521:\tlearn: 0.0074054\ttotal: 39.2s\tremaining: 35.9s\n",
      "522:\tlearn: 0.0074054\ttotal: 39.3s\tremaining: 35.9s\n",
      "523:\tlearn: 0.0074054\ttotal: 39.4s\tremaining: 35.8s\n",
      "524:\tlearn: 0.0074053\ttotal: 39.5s\tremaining: 35.7s\n",
      "525:\tlearn: 0.0074053\ttotal: 39.5s\tremaining: 35.6s\n",
      "526:\tlearn: 0.0074053\ttotal: 39.6s\tremaining: 35.5s\n",
      "527:\tlearn: 0.0074053\ttotal: 39.7s\tremaining: 35.5s\n",
      "528:\tlearn: 0.0074053\ttotal: 39.7s\tremaining: 35.4s\n",
      "529:\tlearn: 0.0074053\ttotal: 39.8s\tremaining: 35.3s\n",
      "530:\tlearn: 0.0074053\ttotal: 39.9s\tremaining: 35.2s\n",
      "531:\tlearn: 0.0074053\ttotal: 39.9s\tremaining: 35.1s\n",
      "532:\tlearn: 0.0074053\ttotal: 40s\tremaining: 35.1s\n",
      "533:\tlearn: 0.0074053\ttotal: 40.1s\tremaining: 35s\n",
      "534:\tlearn: 0.0074053\ttotal: 40.2s\tremaining: 34.9s\n",
      "535:\tlearn: 0.0074052\ttotal: 40.2s\tremaining: 34.8s\n",
      "536:\tlearn: 0.0074052\ttotal: 40.3s\tremaining: 34.7s\n",
      "537:\tlearn: 0.0074052\ttotal: 40.4s\tremaining: 34.7s\n",
      "538:\tlearn: 0.0074052\ttotal: 40.4s\tremaining: 34.6s\n",
      "539:\tlearn: 0.0074052\ttotal: 40.5s\tremaining: 34.5s\n",
      "540:\tlearn: 0.0074051\ttotal: 40.6s\tremaining: 34.4s\n",
      "541:\tlearn: 0.0074051\ttotal: 40.6s\tremaining: 34.3s\n",
      "542:\tlearn: 0.0074049\ttotal: 40.7s\tremaining: 34.3s\n",
      "543:\tlearn: 0.0074049\ttotal: 40.8s\tremaining: 34.2s\n",
      "544:\tlearn: 0.0074048\ttotal: 40.9s\tremaining: 34.1s\n",
      "545:\tlearn: 0.0074048\ttotal: 40.9s\tremaining: 34s\n",
      "546:\tlearn: 0.0074047\ttotal: 41s\tremaining: 34s\n",
      "547:\tlearn: 0.0074047\ttotal: 41.1s\tremaining: 33.9s\n",
      "548:\tlearn: 0.0074046\ttotal: 41.2s\tremaining: 33.8s\n",
      "549:\tlearn: 0.0074046\ttotal: 41.2s\tremaining: 33.7s\n",
      "550:\tlearn: 0.0074046\ttotal: 41.3s\tremaining: 33.7s\n",
      "551:\tlearn: 0.0074046\ttotal: 41.4s\tremaining: 33.6s\n",
      "552:\tlearn: 0.0074046\ttotal: 41.4s\tremaining: 33.5s\n",
      "553:\tlearn: 0.0074046\ttotal: 41.5s\tremaining: 33.4s\n",
      "554:\tlearn: 0.0074046\ttotal: 41.6s\tremaining: 33.3s\n",
      "555:\tlearn: 0.0074046\ttotal: 41.7s\tremaining: 33.3s\n",
      "556:\tlearn: 0.0074046\ttotal: 41.7s\tremaining: 33.2s\n",
      "557:\tlearn: 0.0074046\ttotal: 41.8s\tremaining: 33.1s\n",
      "558:\tlearn: 0.0074046\ttotal: 41.9s\tremaining: 33s\n",
      "559:\tlearn: 0.0074046\ttotal: 41.9s\tremaining: 33s\n",
      "560:\tlearn: 0.0074046\ttotal: 42s\tremaining: 32.9s\n",
      "561:\tlearn: 0.0074046\ttotal: 42.1s\tremaining: 32.8s\n",
      "562:\tlearn: 0.0074046\ttotal: 42.2s\tremaining: 32.7s\n",
      "563:\tlearn: 0.0074046\ttotal: 42.3s\tremaining: 32.7s\n",
      "564:\tlearn: 0.0074046\ttotal: 42.3s\tremaining: 32.6s\n",
      "565:\tlearn: 0.0074046\ttotal: 42.4s\tremaining: 32.5s\n",
      "566:\tlearn: 0.0074046\ttotal: 42.5s\tremaining: 32.4s\n",
      "567:\tlearn: 0.0074046\ttotal: 42.6s\tremaining: 32.4s\n",
      "568:\tlearn: 0.0074045\ttotal: 42.6s\tremaining: 32.3s\n",
      "569:\tlearn: 0.0074044\ttotal: 42.7s\tremaining: 32.2s\n",
      "570:\tlearn: 0.0074043\ttotal: 42.8s\tremaining: 32.1s\n",
      "571:\tlearn: 0.0074042\ttotal: 42.8s\tremaining: 32.1s\n",
      "572:\tlearn: 0.0074042\ttotal: 42.9s\tremaining: 32s\n",
      "573:\tlearn: 0.0074042\ttotal: 43s\tremaining: 31.9s\n",
      "574:\tlearn: 0.0074042\ttotal: 43.1s\tremaining: 31.8s\n",
      "575:\tlearn: 0.0074042\ttotal: 43.2s\tremaining: 31.8s\n",
      "576:\tlearn: 0.0074042\ttotal: 43.3s\tremaining: 31.7s\n",
      "577:\tlearn: 0.0074041\ttotal: 43.4s\tremaining: 31.7s\n",
      "578:\tlearn: 0.0074041\ttotal: 43.4s\tremaining: 31.6s\n",
      "579:\tlearn: 0.0074041\ttotal: 43.5s\tremaining: 31.5s\n",
      "580:\tlearn: 0.0074040\ttotal: 43.6s\tremaining: 31.4s\n",
      "581:\tlearn: 0.0074040\ttotal: 43.6s\tremaining: 31.3s\n",
      "582:\tlearn: 0.0074040\ttotal: 43.7s\tremaining: 31.3s\n",
      "583:\tlearn: 0.0074040\ttotal: 43.8s\tremaining: 31.2s\n",
      "584:\tlearn: 0.0074040\ttotal: 43.9s\tremaining: 31.1s\n",
      "585:\tlearn: 0.0074040\ttotal: 43.9s\tremaining: 31s\n",
      "586:\tlearn: 0.0074040\ttotal: 44s\tremaining: 31s\n",
      "587:\tlearn: 0.0074040\ttotal: 44.1s\tremaining: 30.9s\n",
      "588:\tlearn: 0.0074040\ttotal: 44.1s\tremaining: 30.8s\n",
      "589:\tlearn: 0.0074040\ttotal: 44.2s\tremaining: 30.7s\n",
      "590:\tlearn: 0.0074039\ttotal: 44.3s\tremaining: 30.6s\n",
      "591:\tlearn: 0.0074038\ttotal: 44.4s\tremaining: 30.6s\n",
      "592:\tlearn: 0.0073333\ttotal: 44.4s\tremaining: 30.5s\n",
      "593:\tlearn: 0.0073333\ttotal: 44.5s\tremaining: 30.4s\n",
      "594:\tlearn: 0.0073333\ttotal: 44.6s\tremaining: 30.3s\n",
      "595:\tlearn: 0.0073333\ttotal: 44.7s\tremaining: 30.3s\n",
      "596:\tlearn: 0.0073333\ttotal: 44.7s\tremaining: 30.2s\n",
      "597:\tlearn: 0.0073333\ttotal: 44.8s\tremaining: 30.1s\n",
      "598:\tlearn: 0.0073333\ttotal: 44.9s\tremaining: 30s\n",
      "599:\tlearn: 0.0073333\ttotal: 44.9s\tremaining: 30s\n",
      "600:\tlearn: 0.0073333\ttotal: 45s\tremaining: 29.9s\n",
      "601:\tlearn: 0.0073333\ttotal: 45.1s\tremaining: 29.8s\n",
      "602:\tlearn: 0.0073333\ttotal: 45.1s\tremaining: 29.7s\n",
      "603:\tlearn: 0.0073333\ttotal: 45.2s\tremaining: 29.6s\n",
      "604:\tlearn: 0.0073333\ttotal: 45.3s\tremaining: 29.6s\n",
      "605:\tlearn: 0.0073333\ttotal: 45.4s\tremaining: 29.5s\n",
      "606:\tlearn: 0.0073333\ttotal: 45.4s\tremaining: 29.4s\n",
      "607:\tlearn: 0.0073333\ttotal: 45.5s\tremaining: 29.3s\n",
      "608:\tlearn: 0.0073333\ttotal: 45.6s\tremaining: 29.3s\n",
      "609:\tlearn: 0.0073333\ttotal: 45.6s\tremaining: 29.2s\n",
      "610:\tlearn: 0.0073333\ttotal: 45.7s\tremaining: 29.1s\n",
      "611:\tlearn: 0.0073333\ttotal: 45.8s\tremaining: 29s\n",
      "612:\tlearn: 0.0073333\ttotal: 45.9s\tremaining: 29s\n",
      "613:\tlearn: 0.0073333\ttotal: 45.9s\tremaining: 28.9s\n",
      "614:\tlearn: 0.0073333\ttotal: 46s\tremaining: 28.8s\n",
      "615:\tlearn: 0.0073333\ttotal: 46.1s\tremaining: 28.7s\n",
      "616:\tlearn: 0.0073333\ttotal: 46.2s\tremaining: 28.7s\n",
      "617:\tlearn: 0.0073333\ttotal: 46.2s\tremaining: 28.6s\n",
      "618:\tlearn: 0.0073333\ttotal: 46.3s\tremaining: 28.5s\n",
      "619:\tlearn: 0.0073333\ttotal: 46.4s\tremaining: 28.4s\n",
      "620:\tlearn: 0.0073333\ttotal: 46.5s\tremaining: 28.4s\n",
      "621:\tlearn: 0.0073333\ttotal: 46.5s\tremaining: 28.3s\n",
      "622:\tlearn: 0.0073333\ttotal: 46.6s\tremaining: 28.2s\n",
      "623:\tlearn: 0.0073333\ttotal: 46.7s\tremaining: 28.1s\n",
      "624:\tlearn: 0.0073333\ttotal: 46.8s\tremaining: 28.1s\n",
      "625:\tlearn: 0.0073333\ttotal: 46.8s\tremaining: 28s\n",
      "626:\tlearn: 0.0073333\ttotal: 46.9s\tremaining: 27.9s\n",
      "627:\tlearn: 0.0073333\ttotal: 47s\tremaining: 27.8s\n",
      "628:\tlearn: 0.0073333\ttotal: 47s\tremaining: 27.7s\n",
      "629:\tlearn: 0.0073333\ttotal: 47.1s\tremaining: 27.7s\n",
      "630:\tlearn: 0.0073333\ttotal: 47.2s\tremaining: 27.6s\n",
      "631:\tlearn: 0.0073333\ttotal: 47.3s\tremaining: 27.5s\n",
      "632:\tlearn: 0.0073333\ttotal: 47.3s\tremaining: 27.4s\n",
      "633:\tlearn: 0.0073333\ttotal: 47.4s\tremaining: 27.4s\n",
      "634:\tlearn: 0.0073333\ttotal: 47.5s\tremaining: 27.3s\n",
      "635:\tlearn: 0.0073333\ttotal: 47.5s\tremaining: 27.2s\n",
      "636:\tlearn: 0.0073333\ttotal: 47.6s\tremaining: 27.1s\n",
      "637:\tlearn: 0.0073333\ttotal: 47.7s\tremaining: 27s\n",
      "638:\tlearn: 0.0073333\ttotal: 47.7s\tremaining: 27s\n",
      "639:\tlearn: 0.0073333\ttotal: 47.8s\tremaining: 26.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640:\tlearn: 0.0073333\ttotal: 47.9s\tremaining: 26.8s\n",
      "641:\tlearn: 0.0073333\ttotal: 48s\tremaining: 26.8s\n",
      "642:\tlearn: 0.0073333\ttotal: 48s\tremaining: 26.7s\n",
      "643:\tlearn: 0.0073333\ttotal: 48.1s\tremaining: 26.6s\n",
      "644:\tlearn: 0.0073333\ttotal: 48.2s\tremaining: 26.5s\n",
      "645:\tlearn: 0.0073333\ttotal: 48.3s\tremaining: 26.4s\n",
      "646:\tlearn: 0.0073333\ttotal: 48.3s\tremaining: 26.4s\n",
      "647:\tlearn: 0.0073333\ttotal: 48.4s\tremaining: 26.3s\n",
      "648:\tlearn: 0.0073333\ttotal: 48.5s\tremaining: 26.2s\n",
      "649:\tlearn: 0.0073333\ttotal: 48.5s\tremaining: 26.1s\n",
      "650:\tlearn: 0.0073333\ttotal: 48.6s\tremaining: 26.1s\n",
      "651:\tlearn: 0.0073333\ttotal: 48.7s\tremaining: 26s\n",
      "652:\tlearn: 0.0073333\ttotal: 48.7s\tremaining: 25.9s\n",
      "653:\tlearn: 0.0073333\ttotal: 48.8s\tremaining: 25.8s\n",
      "654:\tlearn: 0.0073333\ttotal: 48.9s\tremaining: 25.8s\n",
      "655:\tlearn: 0.0073333\ttotal: 49s\tremaining: 25.7s\n",
      "656:\tlearn: 0.0073333\ttotal: 49s\tremaining: 25.6s\n",
      "657:\tlearn: 0.0073333\ttotal: 49.1s\tremaining: 25.5s\n",
      "658:\tlearn: 0.0073333\ttotal: 49.2s\tremaining: 25.4s\n",
      "659:\tlearn: 0.0073333\ttotal: 49.3s\tremaining: 25.4s\n",
      "660:\tlearn: 0.0073333\ttotal: 49.3s\tremaining: 25.3s\n",
      "661:\tlearn: 0.0073333\ttotal: 49.4s\tremaining: 25.2s\n",
      "662:\tlearn: 0.0073333\ttotal: 49.5s\tremaining: 25.1s\n",
      "663:\tlearn: 0.0073333\ttotal: 49.5s\tremaining: 25.1s\n",
      "664:\tlearn: 0.0073333\ttotal: 49.6s\tremaining: 25s\n",
      "665:\tlearn: 0.0073333\ttotal: 49.7s\tremaining: 24.9s\n",
      "666:\tlearn: 0.0073333\ttotal: 49.7s\tremaining: 24.8s\n",
      "667:\tlearn: 0.0073333\ttotal: 49.8s\tremaining: 24.8s\n",
      "668:\tlearn: 0.0073333\ttotal: 49.9s\tremaining: 24.7s\n",
      "669:\tlearn: 0.0073333\ttotal: 50s\tremaining: 24.6s\n",
      "670:\tlearn: 0.0073333\ttotal: 50s\tremaining: 24.5s\n",
      "671:\tlearn: 0.0073333\ttotal: 50.1s\tremaining: 24.5s\n",
      "672:\tlearn: 0.0073333\ttotal: 50.2s\tremaining: 24.4s\n",
      "673:\tlearn: 0.0073333\ttotal: 50.2s\tremaining: 24.3s\n",
      "674:\tlearn: 0.0073333\ttotal: 50.3s\tremaining: 24.2s\n",
      "675:\tlearn: 0.0073333\ttotal: 50.4s\tremaining: 24.1s\n",
      "676:\tlearn: 0.0073333\ttotal: 50.5s\tremaining: 24.1s\n",
      "677:\tlearn: 0.0073333\ttotal: 50.5s\tremaining: 24s\n",
      "678:\tlearn: 0.0073333\ttotal: 50.6s\tremaining: 23.9s\n",
      "679:\tlearn: 0.0073333\ttotal: 50.7s\tremaining: 23.8s\n",
      "680:\tlearn: 0.0073333\ttotal: 50.7s\tremaining: 23.8s\n",
      "681:\tlearn: 0.0073333\ttotal: 50.8s\tremaining: 23.7s\n",
      "682:\tlearn: 0.0073333\ttotal: 50.9s\tremaining: 23.6s\n",
      "683:\tlearn: 0.0073333\ttotal: 50.9s\tremaining: 23.5s\n",
      "684:\tlearn: 0.0073333\ttotal: 51s\tremaining: 23.5s\n",
      "685:\tlearn: 0.0073333\ttotal: 51.1s\tremaining: 23.4s\n",
      "686:\tlearn: 0.0073333\ttotal: 51.2s\tremaining: 23.3s\n",
      "687:\tlearn: 0.0073333\ttotal: 51.2s\tremaining: 23.2s\n",
      "688:\tlearn: 0.0073333\ttotal: 51.3s\tremaining: 23.2s\n",
      "689:\tlearn: 0.0073333\ttotal: 51.4s\tremaining: 23.1s\n",
      "690:\tlearn: 0.0073333\ttotal: 51.5s\tremaining: 23s\n",
      "691:\tlearn: 0.0073333\ttotal: 51.5s\tremaining: 22.9s\n",
      "692:\tlearn: 0.0073333\ttotal: 51.6s\tremaining: 22.9s\n",
      "693:\tlearn: 0.0073333\ttotal: 51.7s\tremaining: 22.8s\n",
      "694:\tlearn: 0.0073333\ttotal: 51.7s\tremaining: 22.7s\n",
      "695:\tlearn: 0.0073333\ttotal: 51.8s\tremaining: 22.6s\n",
      "696:\tlearn: 0.0073333\ttotal: 51.9s\tremaining: 22.6s\n",
      "697:\tlearn: 0.0073333\ttotal: 52s\tremaining: 22.5s\n",
      "698:\tlearn: 0.0073333\ttotal: 52s\tremaining: 22.4s\n",
      "699:\tlearn: 0.0073333\ttotal: 52.1s\tremaining: 22.3s\n",
      "700:\tlearn: 0.0073333\ttotal: 52.2s\tremaining: 22.2s\n",
      "701:\tlearn: 0.0073333\ttotal: 52.2s\tremaining: 22.2s\n",
      "702:\tlearn: 0.0073333\ttotal: 52.3s\tremaining: 22.1s\n",
      "703:\tlearn: 0.0073333\ttotal: 52.4s\tremaining: 22s\n",
      "704:\tlearn: 0.0073333\ttotal: 52.4s\tremaining: 21.9s\n",
      "705:\tlearn: 0.0073333\ttotal: 52.5s\tremaining: 21.9s\n",
      "706:\tlearn: 0.0073333\ttotal: 52.6s\tremaining: 21.8s\n",
      "707:\tlearn: 0.0073333\ttotal: 52.6s\tremaining: 21.7s\n",
      "708:\tlearn: 0.0073333\ttotal: 52.7s\tremaining: 21.6s\n",
      "709:\tlearn: 0.0073333\ttotal: 52.8s\tremaining: 21.6s\n",
      "710:\tlearn: 0.0073333\ttotal: 52.9s\tremaining: 21.5s\n",
      "711:\tlearn: 0.0073333\ttotal: 52.9s\tremaining: 21.4s\n",
      "712:\tlearn: 0.0073333\ttotal: 53s\tremaining: 21.3s\n",
      "713:\tlearn: 0.0073333\ttotal: 53.1s\tremaining: 21.3s\n",
      "714:\tlearn: 0.0073333\ttotal: 53.1s\tremaining: 21.2s\n",
      "715:\tlearn: 0.0073333\ttotal: 53.2s\tremaining: 21.1s\n",
      "716:\tlearn: 0.0073333\ttotal: 53.3s\tremaining: 21s\n",
      "717:\tlearn: 0.0073333\ttotal: 53.4s\tremaining: 21s\n",
      "718:\tlearn: 0.0073333\ttotal: 53.4s\tremaining: 20.9s\n",
      "719:\tlearn: 0.0073333\ttotal: 53.5s\tremaining: 20.8s\n",
      "720:\tlearn: 0.0073333\ttotal: 53.6s\tremaining: 20.7s\n",
      "721:\tlearn: 0.0073333\ttotal: 53.6s\tremaining: 20.7s\n",
      "722:\tlearn: 0.0073333\ttotal: 53.7s\tremaining: 20.6s\n",
      "723:\tlearn: 0.0073333\ttotal: 53.8s\tremaining: 20.5s\n",
      "724:\tlearn: 0.0073333\ttotal: 53.9s\tremaining: 20.4s\n",
      "725:\tlearn: 0.0073333\ttotal: 53.9s\tremaining: 20.4s\n",
      "726:\tlearn: 0.0073333\ttotal: 54s\tremaining: 20.3s\n",
      "727:\tlearn: 0.0073333\ttotal: 54.1s\tremaining: 20.2s\n",
      "728:\tlearn: 0.0073333\ttotal: 54.1s\tremaining: 20.1s\n",
      "729:\tlearn: 0.0073333\ttotal: 54.2s\tremaining: 20.1s\n",
      "730:\tlearn: 0.0073333\ttotal: 54.3s\tremaining: 20s\n",
      "731:\tlearn: 0.0073333\ttotal: 54.4s\tremaining: 19.9s\n",
      "732:\tlearn: 0.0073333\ttotal: 54.4s\tremaining: 19.8s\n",
      "733:\tlearn: 0.0073333\ttotal: 54.5s\tremaining: 19.8s\n",
      "734:\tlearn: 0.0073333\ttotal: 54.6s\tremaining: 19.7s\n",
      "735:\tlearn: 0.0073333\ttotal: 54.6s\tremaining: 19.6s\n",
      "736:\tlearn: 0.0073333\ttotal: 54.7s\tremaining: 19.5s\n",
      "737:\tlearn: 0.0073333\ttotal: 54.8s\tremaining: 19.4s\n",
      "738:\tlearn: 0.0073333\ttotal: 54.8s\tremaining: 19.4s\n",
      "739:\tlearn: 0.0073333\ttotal: 54.9s\tremaining: 19.3s\n",
      "740:\tlearn: 0.0073333\ttotal: 55s\tremaining: 19.2s\n",
      "741:\tlearn: 0.0073333\ttotal: 55.1s\tremaining: 19.1s\n",
      "742:\tlearn: 0.0073333\ttotal: 55.1s\tremaining: 19.1s\n",
      "743:\tlearn: 0.0073333\ttotal: 55.2s\tremaining: 19s\n",
      "744:\tlearn: 0.0073333\ttotal: 55.3s\tremaining: 18.9s\n",
      "745:\tlearn: 0.0073333\ttotal: 55.3s\tremaining: 18.8s\n",
      "746:\tlearn: 0.0073333\ttotal: 55.4s\tremaining: 18.8s\n",
      "747:\tlearn: 0.0073333\ttotal: 55.5s\tremaining: 18.7s\n",
      "748:\tlearn: 0.0073333\ttotal: 55.6s\tremaining: 18.6s\n",
      "749:\tlearn: 0.0073333\ttotal: 55.6s\tremaining: 18.5s\n",
      "750:\tlearn: 0.0073333\ttotal: 55.7s\tremaining: 18.5s\n",
      "751:\tlearn: 0.0073333\ttotal: 55.8s\tremaining: 18.4s\n",
      "752:\tlearn: 0.0073333\ttotal: 55.8s\tremaining: 18.3s\n",
      "753:\tlearn: 0.0073333\ttotal: 55.9s\tremaining: 18.2s\n",
      "754:\tlearn: 0.0073333\ttotal: 56s\tremaining: 18.2s\n",
      "755:\tlearn: 0.0073333\ttotal: 56.1s\tremaining: 18.1s\n",
      "756:\tlearn: 0.0073333\ttotal: 56.1s\tremaining: 18s\n",
      "757:\tlearn: 0.0073333\ttotal: 56.2s\tremaining: 17.9s\n",
      "758:\tlearn: 0.0073333\ttotal: 56.3s\tremaining: 17.9s\n",
      "759:\tlearn: 0.0073333\ttotal: 56.3s\tremaining: 17.8s\n",
      "760:\tlearn: 0.0073333\ttotal: 56.4s\tremaining: 17.7s\n",
      "761:\tlearn: 0.0073333\ttotal: 56.5s\tremaining: 17.6s\n",
      "762:\tlearn: 0.0073333\ttotal: 56.6s\tremaining: 17.6s\n",
      "763:\tlearn: 0.0073333\ttotal: 56.6s\tremaining: 17.5s\n",
      "764:\tlearn: 0.0073333\ttotal: 56.7s\tremaining: 17.4s\n",
      "765:\tlearn: 0.0073333\ttotal: 56.8s\tremaining: 17.3s\n",
      "766:\tlearn: 0.0073333\ttotal: 56.8s\tremaining: 17.3s\n",
      "767:\tlearn: 0.0073333\ttotal: 56.9s\tremaining: 17.2s\n",
      "768:\tlearn: 0.0073333\ttotal: 57s\tremaining: 17.1s\n",
      "769:\tlearn: 0.0073333\ttotal: 57.1s\tremaining: 17s\n",
      "770:\tlearn: 0.0073333\ttotal: 57.1s\tremaining: 17s\n",
      "771:\tlearn: 0.0073333\ttotal: 57.2s\tremaining: 16.9s\n",
      "772:\tlearn: 0.0073333\ttotal: 57.3s\tremaining: 16.8s\n",
      "773:\tlearn: 0.0073333\ttotal: 57.4s\tremaining: 16.8s\n",
      "774:\tlearn: 0.0073333\ttotal: 57.4s\tremaining: 16.7s\n",
      "775:\tlearn: 0.0073333\ttotal: 57.5s\tremaining: 16.6s\n",
      "776:\tlearn: 0.0073333\ttotal: 57.6s\tremaining: 16.5s\n",
      "777:\tlearn: 0.0073333\ttotal: 57.6s\tremaining: 16.4s\n",
      "778:\tlearn: 0.0073333\ttotal: 57.7s\tremaining: 16.4s\n",
      "779:\tlearn: 0.0073333\ttotal: 57.8s\tremaining: 16.3s\n",
      "780:\tlearn: 0.0073333\ttotal: 57.9s\tremaining: 16.2s\n",
      "781:\tlearn: 0.0073333\ttotal: 57.9s\tremaining: 16.1s\n",
      "782:\tlearn: 0.0073333\ttotal: 58s\tremaining: 16.1s\n",
      "783:\tlearn: 0.0073333\ttotal: 58.1s\tremaining: 16s\n",
      "784:\tlearn: 0.0073333\ttotal: 58.1s\tremaining: 15.9s\n",
      "785:\tlearn: 0.0073333\ttotal: 58.2s\tremaining: 15.8s\n",
      "786:\tlearn: 0.0073333\ttotal: 58.3s\tremaining: 15.8s\n",
      "787:\tlearn: 0.0073333\ttotal: 58.4s\tremaining: 15.7s\n",
      "788:\tlearn: 0.0073333\ttotal: 58.4s\tremaining: 15.6s\n",
      "789:\tlearn: 0.0073333\ttotal: 58.5s\tremaining: 15.5s\n",
      "790:\tlearn: 0.0073333\ttotal: 58.6s\tremaining: 15.5s\n",
      "791:\tlearn: 0.0073333\ttotal: 58.6s\tremaining: 15.4s\n",
      "792:\tlearn: 0.0073333\ttotal: 58.7s\tremaining: 15.3s\n",
      "793:\tlearn: 0.0073333\ttotal: 58.8s\tremaining: 15.2s\n",
      "794:\tlearn: 0.0073333\ttotal: 58.8s\tremaining: 15.2s\n",
      "795:\tlearn: 0.0073333\ttotal: 58.9s\tremaining: 15.1s\n",
      "796:\tlearn: 0.0073333\ttotal: 59s\tremaining: 15s\n",
      "797:\tlearn: 0.0073333\ttotal: 59.1s\tremaining: 14.9s\n",
      "798:\tlearn: 0.0073333\ttotal: 59.1s\tremaining: 14.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "799:\tlearn: 0.0073333\ttotal: 59.2s\tremaining: 14.8s\n",
      "800:\tlearn: 0.0073333\ttotal: 59.3s\tremaining: 14.7s\n",
      "801:\tlearn: 0.0073333\ttotal: 59.3s\tremaining: 14.7s\n",
      "802:\tlearn: 0.0073333\ttotal: 59.4s\tremaining: 14.6s\n",
      "803:\tlearn: 0.0073333\ttotal: 59.5s\tremaining: 14.5s\n",
      "804:\tlearn: 0.0073333\ttotal: 59.6s\tremaining: 14.4s\n",
      "805:\tlearn: 0.0073333\ttotal: 59.6s\tremaining: 14.4s\n",
      "806:\tlearn: 0.0073333\ttotal: 59.7s\tremaining: 14.3s\n",
      "807:\tlearn: 0.0073333\ttotal: 59.8s\tremaining: 14.2s\n",
      "808:\tlearn: 0.0073333\ttotal: 59.8s\tremaining: 14.1s\n",
      "809:\tlearn: 0.0073333\ttotal: 59.9s\tremaining: 14.1s\n",
      "810:\tlearn: 0.0073333\ttotal: 60s\tremaining: 14s\n",
      "811:\tlearn: 0.0073333\ttotal: 1m\tremaining: 13.9s\n",
      "812:\tlearn: 0.0073333\ttotal: 1m\tremaining: 13.8s\n",
      "813:\tlearn: 0.0073333\ttotal: 1m\tremaining: 13.8s\n",
      "814:\tlearn: 0.0073333\ttotal: 1m\tremaining: 13.7s\n",
      "815:\tlearn: 0.0073333\ttotal: 1m\tremaining: 13.6s\n",
      "816:\tlearn: 0.0073333\ttotal: 1m\tremaining: 13.5s\n",
      "817:\tlearn: 0.0073333\ttotal: 1m\tremaining: 13.5s\n",
      "818:\tlearn: 0.0073333\ttotal: 1m\tremaining: 13.4s\n",
      "819:\tlearn: 0.0073333\ttotal: 1m\tremaining: 13.3s\n",
      "820:\tlearn: 0.0073333\ttotal: 1m\tremaining: 13.2s\n",
      "821:\tlearn: 0.0073333\ttotal: 1m\tremaining: 13.2s\n",
      "822:\tlearn: 0.0073333\ttotal: 1m\tremaining: 13.1s\n",
      "823:\tlearn: 0.0073333\ttotal: 1m\tremaining: 13s\n",
      "824:\tlearn: 0.0073333\ttotal: 1m\tremaining: 12.9s\n",
      "825:\tlearn: 0.0073333\ttotal: 1m 1s\tremaining: 12.9s\n",
      "826:\tlearn: 0.0073333\ttotal: 1m 1s\tremaining: 12.8s\n",
      "827:\tlearn: 0.0073333\ttotal: 1m 1s\tremaining: 12.7s\n",
      "828:\tlearn: 0.0073333\ttotal: 1m 1s\tremaining: 12.6s\n",
      "829:\tlearn: 0.0073333\ttotal: 1m 1s\tremaining: 12.6s\n",
      "830:\tlearn: 0.0073333\ttotal: 1m 1s\tremaining: 12.5s\n",
      "831:\tlearn: 0.0073333\ttotal: 1m 1s\tremaining: 12.4s\n",
      "832:\tlearn: 0.0073333\ttotal: 1m 1s\tremaining: 12.3s\n",
      "833:\tlearn: 0.0073333\ttotal: 1m 1s\tremaining: 12.3s\n",
      "834:\tlearn: 0.0073333\ttotal: 1m 1s\tremaining: 12.2s\n",
      "835:\tlearn: 0.0073333\ttotal: 1m 1s\tremaining: 12.1s\n",
      "836:\tlearn: 0.0073333\ttotal: 1m 1s\tremaining: 12s\n",
      "837:\tlearn: 0.0073333\ttotal: 1m 1s\tremaining: 12s\n",
      "838:\tlearn: 0.0073333\ttotal: 1m 1s\tremaining: 11.9s\n",
      "839:\tlearn: 0.0073333\ttotal: 1m 2s\tremaining: 11.8s\n",
      "840:\tlearn: 0.0073333\ttotal: 1m 2s\tremaining: 11.7s\n",
      "841:\tlearn: 0.0073333\ttotal: 1m 2s\tremaining: 11.7s\n",
      "842:\tlearn: 0.0073333\ttotal: 1m 2s\tremaining: 11.6s\n",
      "843:\tlearn: 0.0073333\ttotal: 1m 2s\tremaining: 11.5s\n",
      "844:\tlearn: 0.0073333\ttotal: 1m 2s\tremaining: 11.4s\n",
      "845:\tlearn: 0.0073333\ttotal: 1m 2s\tremaining: 11.4s\n",
      "846:\tlearn: 0.0073333\ttotal: 1m 2s\tremaining: 11.3s\n",
      "847:\tlearn: 0.0073333\ttotal: 1m 2s\tremaining: 11.2s\n",
      "848:\tlearn: 0.0073333\ttotal: 1m 2s\tremaining: 11.2s\n",
      "849:\tlearn: 0.0073333\ttotal: 1m 2s\tremaining: 11.1s\n",
      "850:\tlearn: 0.0073333\ttotal: 1m 2s\tremaining: 11s\n",
      "851:\tlearn: 0.0073333\ttotal: 1m 2s\tremaining: 10.9s\n",
      "852:\tlearn: 0.0073333\ttotal: 1m 2s\tremaining: 10.9s\n",
      "853:\tlearn: 0.0073333\ttotal: 1m 3s\tremaining: 10.8s\n",
      "854:\tlearn: 0.0073333\ttotal: 1m 3s\tremaining: 10.7s\n",
      "855:\tlearn: 0.0073333\ttotal: 1m 3s\tremaining: 10.6s\n",
      "856:\tlearn: 0.0073333\ttotal: 1m 3s\tremaining: 10.6s\n",
      "857:\tlearn: 0.0073333\ttotal: 1m 3s\tremaining: 10.5s\n",
      "858:\tlearn: 0.0073333\ttotal: 1m 3s\tremaining: 10.4s\n",
      "859:\tlearn: 0.0073333\ttotal: 1m 3s\tremaining: 10.3s\n",
      "860:\tlearn: 0.0073333\ttotal: 1m 3s\tremaining: 10.3s\n",
      "861:\tlearn: 0.0073333\ttotal: 1m 3s\tremaining: 10.2s\n",
      "862:\tlearn: 0.0073333\ttotal: 1m 3s\tremaining: 10.1s\n",
      "863:\tlearn: 0.0073333\ttotal: 1m 3s\tremaining: 10s\n",
      "864:\tlearn: 0.0073333\ttotal: 1m 3s\tremaining: 9.97s\n",
      "865:\tlearn: 0.0073333\ttotal: 1m 3s\tremaining: 9.89s\n",
      "866:\tlearn: 0.0073333\ttotal: 1m 4s\tremaining: 9.82s\n",
      "867:\tlearn: 0.0073333\ttotal: 1m 4s\tremaining: 9.75s\n",
      "868:\tlearn: 0.0073333\ttotal: 1m 4s\tremaining: 9.68s\n",
      "869:\tlearn: 0.0073333\ttotal: 1m 4s\tremaining: 9.6s\n",
      "870:\tlearn: 0.0073333\ttotal: 1m 4s\tremaining: 9.53s\n",
      "871:\tlearn: 0.0073333\ttotal: 1m 4s\tremaining: 9.45s\n",
      "872:\tlearn: 0.0073333\ttotal: 1m 4s\tremaining: 9.38s\n",
      "873:\tlearn: 0.0073333\ttotal: 1m 4s\tremaining: 9.3s\n",
      "874:\tlearn: 0.0073333\ttotal: 1m 4s\tremaining: 9.23s\n",
      "875:\tlearn: 0.0073333\ttotal: 1m 4s\tremaining: 9.16s\n",
      "876:\tlearn: 0.0073333\ttotal: 1m 4s\tremaining: 9.08s\n",
      "877:\tlearn: 0.0073333\ttotal: 1m 4s\tremaining: 9.01s\n",
      "878:\tlearn: 0.0073333\ttotal: 1m 4s\tremaining: 8.93s\n",
      "879:\tlearn: 0.0073333\ttotal: 1m 4s\tremaining: 8.86s\n",
      "880:\tlearn: 0.0073333\ttotal: 1m 5s\tremaining: 8.79s\n",
      "881:\tlearn: 0.0073333\ttotal: 1m 5s\tremaining: 8.71s\n",
      "882:\tlearn: 0.0073333\ttotal: 1m 5s\tremaining: 8.64s\n",
      "883:\tlearn: 0.0073333\ttotal: 1m 5s\tremaining: 8.56s\n",
      "884:\tlearn: 0.0073333\ttotal: 1m 5s\tremaining: 8.49s\n",
      "885:\tlearn: 0.0073333\ttotal: 1m 5s\tremaining: 8.41s\n",
      "886:\tlearn: 0.0073333\ttotal: 1m 5s\tremaining: 8.34s\n",
      "887:\tlearn: 0.0073333\ttotal: 1m 5s\tremaining: 8.27s\n",
      "888:\tlearn: 0.0073333\ttotal: 1m 5s\tremaining: 8.2s\n",
      "889:\tlearn: 0.0073333\ttotal: 1m 5s\tremaining: 8.13s\n",
      "890:\tlearn: 0.0073333\ttotal: 1m 5s\tremaining: 8.05s\n",
      "891:\tlearn: 0.0073333\ttotal: 1m 5s\tremaining: 7.98s\n",
      "892:\tlearn: 0.0073333\ttotal: 1m 5s\tremaining: 7.9s\n",
      "893:\tlearn: 0.0073333\ttotal: 1m 6s\tremaining: 7.83s\n",
      "894:\tlearn: 0.0073333\ttotal: 1m 6s\tremaining: 7.75s\n",
      "895:\tlearn: 0.0073333\ttotal: 1m 6s\tremaining: 7.68s\n",
      "896:\tlearn: 0.0073333\ttotal: 1m 6s\tremaining: 7.61s\n",
      "897:\tlearn: 0.0073333\ttotal: 1m 6s\tremaining: 7.53s\n",
      "898:\tlearn: 0.0073333\ttotal: 1m 6s\tremaining: 7.46s\n",
      "899:\tlearn: 0.0073333\ttotal: 1m 6s\tremaining: 7.38s\n",
      "900:\tlearn: 0.0073333\ttotal: 1m 6s\tremaining: 7.31s\n",
      "901:\tlearn: 0.0073333\ttotal: 1m 6s\tremaining: 7.24s\n",
      "902:\tlearn: 0.0073333\ttotal: 1m 6s\tremaining: 7.16s\n",
      "903:\tlearn: 0.0073333\ttotal: 1m 6s\tremaining: 7.09s\n",
      "904:\tlearn: 0.0073333\ttotal: 1m 6s\tremaining: 7.01s\n",
      "905:\tlearn: 0.0073333\ttotal: 1m 6s\tremaining: 6.94s\n",
      "906:\tlearn: 0.0073333\ttotal: 1m 6s\tremaining: 6.87s\n",
      "907:\tlearn: 0.0073333\ttotal: 1m 7s\tremaining: 6.79s\n",
      "908:\tlearn: 0.0073333\ttotal: 1m 7s\tremaining: 6.72s\n",
      "909:\tlearn: 0.0073333\ttotal: 1m 7s\tremaining: 6.65s\n",
      "910:\tlearn: 0.0073333\ttotal: 1m 7s\tremaining: 6.57s\n",
      "911:\tlearn: 0.0073333\ttotal: 1m 7s\tremaining: 6.5s\n",
      "912:\tlearn: 0.0073333\ttotal: 1m 7s\tremaining: 6.42s\n",
      "913:\tlearn: 0.0073333\ttotal: 1m 7s\tremaining: 6.35s\n",
      "914:\tlearn: 0.0073333\ttotal: 1m 7s\tremaining: 6.28s\n",
      "915:\tlearn: 0.0073333\ttotal: 1m 7s\tremaining: 6.2s\n",
      "916:\tlearn: 0.0073333\ttotal: 1m 7s\tremaining: 6.13s\n",
      "917:\tlearn: 0.0073333\ttotal: 1m 7s\tremaining: 6.05s\n",
      "918:\tlearn: 0.0073333\ttotal: 1m 7s\tremaining: 5.98s\n",
      "919:\tlearn: 0.0073333\ttotal: 1m 7s\tremaining: 5.91s\n",
      "920:\tlearn: 0.0073333\ttotal: 1m 7s\tremaining: 5.83s\n",
      "921:\tlearn: 0.0073333\ttotal: 1m 8s\tremaining: 5.76s\n",
      "922:\tlearn: 0.0073333\ttotal: 1m 8s\tremaining: 5.68s\n",
      "923:\tlearn: 0.0073333\ttotal: 1m 8s\tremaining: 5.61s\n",
      "924:\tlearn: 0.0073333\ttotal: 1m 8s\tremaining: 5.54s\n",
      "925:\tlearn: 0.0073333\ttotal: 1m 8s\tremaining: 5.46s\n",
      "926:\tlearn: 0.0073333\ttotal: 1m 8s\tremaining: 5.39s\n",
      "927:\tlearn: 0.0073333\ttotal: 1m 8s\tremaining: 5.31s\n",
      "928:\tlearn: 0.0073333\ttotal: 1m 8s\tremaining: 5.24s\n",
      "929:\tlearn: 0.0073333\ttotal: 1m 8s\tremaining: 5.17s\n",
      "930:\tlearn: 0.0073333\ttotal: 1m 8s\tremaining: 5.09s\n",
      "931:\tlearn: 0.0073333\ttotal: 1m 8s\tremaining: 5.02s\n",
      "932:\tlearn: 0.0073333\ttotal: 1m 8s\tremaining: 4.95s\n",
      "933:\tlearn: 0.0073333\ttotal: 1m 8s\tremaining: 4.87s\n",
      "934:\tlearn: 0.0073333\ttotal: 1m 9s\tremaining: 4.8s\n",
      "935:\tlearn: 0.0073333\ttotal: 1m 9s\tremaining: 4.72s\n",
      "936:\tlearn: 0.0073333\ttotal: 1m 9s\tremaining: 4.65s\n",
      "937:\tlearn: 0.0073333\ttotal: 1m 9s\tremaining: 4.57s\n",
      "938:\tlearn: 0.0073333\ttotal: 1m 9s\tremaining: 4.5s\n",
      "939:\tlearn: 0.0073333\ttotal: 1m 9s\tremaining: 4.43s\n",
      "940:\tlearn: 0.0073333\ttotal: 1m 9s\tremaining: 4.35s\n",
      "941:\tlearn: 0.0073333\ttotal: 1m 9s\tremaining: 4.28s\n",
      "942:\tlearn: 0.0073333\ttotal: 1m 9s\tremaining: 4.21s\n",
      "943:\tlearn: 0.0073333\ttotal: 1m 9s\tremaining: 4.13s\n",
      "944:\tlearn: 0.0073333\ttotal: 1m 9s\tremaining: 4.06s\n",
      "945:\tlearn: 0.0073333\ttotal: 1m 9s\tremaining: 3.98s\n",
      "946:\tlearn: 0.0073333\ttotal: 1m 9s\tremaining: 3.91s\n",
      "947:\tlearn: 0.0073333\ttotal: 1m 9s\tremaining: 3.84s\n",
      "948:\tlearn: 0.0073333\ttotal: 1m 10s\tremaining: 3.76s\n",
      "949:\tlearn: 0.0073333\ttotal: 1m 10s\tremaining: 3.69s\n",
      "950:\tlearn: 0.0073333\ttotal: 1m 10s\tremaining: 3.62s\n",
      "951:\tlearn: 0.0073333\ttotal: 1m 10s\tremaining: 3.54s\n",
      "952:\tlearn: 0.0073333\ttotal: 1m 10s\tremaining: 3.47s\n",
      "953:\tlearn: 0.0073333\ttotal: 1m 10s\tremaining: 3.39s\n",
      "954:\tlearn: 0.0073333\ttotal: 1m 10s\tremaining: 3.32s\n",
      "955:\tlearn: 0.0073333\ttotal: 1m 10s\tremaining: 3.25s\n",
      "956:\tlearn: 0.0073333\ttotal: 1m 10s\tremaining: 3.17s\n",
      "957:\tlearn: 0.0073333\ttotal: 1m 10s\tremaining: 3.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "958:\tlearn: 0.0073333\ttotal: 1m 10s\tremaining: 3.02s\n",
      "959:\tlearn: 0.0073333\ttotal: 1m 10s\tremaining: 2.95s\n",
      "960:\tlearn: 0.0073333\ttotal: 1m 10s\tremaining: 2.88s\n",
      "961:\tlearn: 0.0073333\ttotal: 1m 10s\tremaining: 2.8s\n",
      "962:\tlearn: 0.0073333\ttotal: 1m 11s\tremaining: 2.73s\n",
      "963:\tlearn: 0.0073333\ttotal: 1m 11s\tremaining: 2.65s\n",
      "964:\tlearn: 0.0073333\ttotal: 1m 11s\tremaining: 2.58s\n",
      "965:\tlearn: 0.0073333\ttotal: 1m 11s\tremaining: 2.51s\n",
      "966:\tlearn: 0.0073333\ttotal: 1m 11s\tremaining: 2.43s\n",
      "967:\tlearn: 0.0073333\ttotal: 1m 11s\tremaining: 2.36s\n",
      "968:\tlearn: 0.0073333\ttotal: 1m 11s\tremaining: 2.29s\n",
      "969:\tlearn: 0.0073333\ttotal: 1m 11s\tremaining: 2.21s\n",
      "970:\tlearn: 0.0073333\ttotal: 1m 11s\tremaining: 2.14s\n",
      "971:\tlearn: 0.0073333\ttotal: 1m 11s\tremaining: 2.06s\n",
      "972:\tlearn: 0.0073333\ttotal: 1m 11s\tremaining: 1.99s\n",
      "973:\tlearn: 0.0073333\ttotal: 1m 11s\tremaining: 1.92s\n",
      "974:\tlearn: 0.0073333\ttotal: 1m 11s\tremaining: 1.84s\n",
      "975:\tlearn: 0.0073333\ttotal: 1m 11s\tremaining: 1.77s\n",
      "976:\tlearn: 0.0073333\ttotal: 1m 12s\tremaining: 1.7s\n",
      "977:\tlearn: 0.0073333\ttotal: 1m 12s\tremaining: 1.62s\n",
      "978:\tlearn: 0.0073333\ttotal: 1m 12s\tremaining: 1.55s\n",
      "979:\tlearn: 0.0073333\ttotal: 1m 12s\tremaining: 1.47s\n",
      "980:\tlearn: 0.0073333\ttotal: 1m 12s\tremaining: 1.4s\n",
      "981:\tlearn: 0.0073333\ttotal: 1m 12s\tremaining: 1.33s\n",
      "982:\tlearn: 0.0073333\ttotal: 1m 12s\tremaining: 1.25s\n",
      "983:\tlearn: 0.0073333\ttotal: 1m 12s\tremaining: 1.18s\n",
      "984:\tlearn: 0.0073333\ttotal: 1m 12s\tremaining: 1.11s\n",
      "985:\tlearn: 0.0073333\ttotal: 1m 12s\tremaining: 1.03s\n",
      "986:\tlearn: 0.0073333\ttotal: 1m 12s\tremaining: 958ms\n",
      "987:\tlearn: 0.0073333\ttotal: 1m 12s\tremaining: 885ms\n",
      "988:\tlearn: 0.0073333\ttotal: 1m 12s\tremaining: 811ms\n",
      "989:\tlearn: 0.0073333\ttotal: 1m 13s\tremaining: 737ms\n",
      "990:\tlearn: 0.0073333\ttotal: 1m 13s\tremaining: 664ms\n",
      "991:\tlearn: 0.0073333\ttotal: 1m 13s\tremaining: 590ms\n",
      "992:\tlearn: 0.0073333\ttotal: 1m 13s\tremaining: 516ms\n",
      "993:\tlearn: 0.0073333\ttotal: 1m 13s\tremaining: 443ms\n",
      "994:\tlearn: 0.0073333\ttotal: 1m 13s\tremaining: 369ms\n",
      "995:\tlearn: 0.0073333\ttotal: 1m 13s\tremaining: 295ms\n",
      "996:\tlearn: 0.0073333\ttotal: 1m 13s\tremaining: 221ms\n",
      "997:\tlearn: 0.0073333\ttotal: 1m 13s\tremaining: 148ms\n",
      "998:\tlearn: 0.0073333\ttotal: 1m 13s\tremaining: 73.8ms\n",
      "999:\tlearn: 0.0073333\ttotal: 1m 13s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1d181547e88>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "cat2 = CatBoostClassifier(learning_rate=0.3, scale_pos_weight=10, verbose=True)\n",
    "cat2.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    10944\n",
       "pos      456\n",
       "dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result8 = cat2.predict(X_val01)\n",
    "pd.Series(result8).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.5949177877428998\n",
      "accuracy score: 0.9762280701754386\n"
     ]
    }
   ],
   "source": [
    "print('f1 score:', f1_score(y_val.replace({'neg': 0, 'pos' : 1}), pd.Series(result8).replace({'neg': 0, 'pos' : 1})))\n",
    "print('accuracy score:', accuracy_score(y_val.replace({'neg': 0, 'pos' : 1}), pd.Series(result8).replace({'neg': 0, 'pos' : 1})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'predicted':result8, 'true':y_val})\n",
    "df2.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost 총 비용 : $ 9570\n",
      "positive를 negative로 분류 : 14 개 $ 7000\n",
      "negative를 positive로 분류 : 257 개 $ 2570\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "j= 0\n",
    "false_neg = 0\n",
    "false_pos = 0\n",
    "\n",
    "for predicted, true in df2.values:\n",
    "    if predicted != true: #예측이 틀렸을 때\n",
    "        if true == 'neg': \n",
    "            i = i+10\n",
    "            false_pos = false_pos+1\n",
    "        else :\n",
    "            j = j+500\n",
    "            false_neg = false_neg+1\n",
    "            \n",
    "print('CatBoost 총 비용 :','$',i+j)\n",
    "print('positive를 negative로 분류 :',false_neg,'개', '$',false_neg*500)\n",
    "print('negative를 positive로 분류 :',false_pos,'개', '$', false_pos*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTing the Tuned Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) XGB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    15629\n",
       "pos      371\n",
       "dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred7 = xgb_model_2.predict(test1)\n",
    "pd.Series(test_pred7).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.9463806970509383\n",
      "accuracy score: 0.9975\n"
     ]
    }
   ],
   "source": [
    "print('f1 score:', f1_score(test['class'].replace({'neg': 0, 'pos' : 1}), pd.Series(test_pred7).replace({'neg': 0, 'pos' : 1})))\n",
    "print('accuracy score:', accuracy_score(test['class'].replace({'neg': 0, 'pos' : 1}), pd.Series(test_pred7).replace({'neg': 0, 'pos' : 1})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df7 = pd.DataFrame({'predicted':test_pred7, 'true':test['class']})\n",
    "t_df7.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XG Boost 총 비용 : $ 11180\n",
      "positive를 negative로 분류 : $ 22 개 11000\n",
      "negative를 positive로 분류 : $ 18 개 180\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "j= 0\n",
    "false_neg = 0\n",
    "false_pos = 0\n",
    "\n",
    "for predicted, true in t_df7.values:\n",
    "    if predicted != true: #예측이 틀렸을 때\n",
    "        if true == 'neg': \n",
    "            i = i+10\n",
    "            false_pos = false_pos+1\n",
    "        else :\n",
    "            j = j+500\n",
    "            false_neg = false_neg+1\n",
    "            \n",
    "print('XG Boost 총 비용 :','$',i+j)\n",
    "print('positive를 negative로 분류 :', '$',false_neg,'개',false_neg*500)\n",
    "print('negative를 positive로 분류 :', '$',false_pos,'개', false_pos*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-1) XGBoost with scale_pos_weight = 52**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    15583\n",
       "pos      417\n",
       "dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred10 = xgb_model_3.predict(test1)\n",
    "pd.Series(test_pred10).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.9141414141414141\n",
      "accuracy score: 0.99575\n"
     ]
    }
   ],
   "source": [
    "print('f1 score:', f1_score(test['class'].replace({'neg': 0, 'pos' : 1}), pd.Series(test_pred10).replace({'neg': 0, 'pos' : 1})))\n",
    "print('accuracy score:', accuracy_score(test['class'].replace({'neg': 0, 'pos' : 1}), pd.Series(test_pred10).replace({'neg': 0, 'pos' : 1})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df10 = pd.DataFrame({'predicted':test_pred10, 'true':test['class']})\n",
    "t_df10.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XG Boost 총 비용 : $ 7050\n",
      "positive를 negative로 분류 : $ 13 개 6500\n",
      "negative를 positive로 분류 : $ 55 개 550\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "j= 0\n",
    "false_neg = 0\n",
    "false_pos = 0\n",
    "\n",
    "for predicted, true in t_df10.values:\n",
    "    if predicted != true: #예측이 틀렸을 때\n",
    "        if true == 'neg': \n",
    "            i = i+10\n",
    "            false_pos = false_pos+1\n",
    "        else :\n",
    "            j = j+500\n",
    "            false_neg = false_neg+1\n",
    "            \n",
    "print('XG Boost 총 비용 :','$',i+j)\n",
    "print('positive를 negative로 분류 :', '$',false_neg,'개',false_neg*500)\n",
    "print('negative를 positive로 분류 :', '$',false_pos,'개', false_pos*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) CatBoost with learning rate = 0.3, scale_pos_weight=10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    15337\n",
       "pos      663\n",
       "dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred8 = cat2.predict(test1)\n",
    "pd.Series(test_pred8).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.7090558766859344\n",
      "accuracy score: 0.981125\n"
     ]
    }
   ],
   "source": [
    "print('f1 score:', f1_score(test['class'].replace({'neg': 0, 'pos' : 1}), pd.Series(test_pred8).replace({'neg': 0, 'pos' : 1})))\n",
    "print('accuracy score:', accuracy_score(test['class'].replace({'neg': 0, 'pos' : 1}), pd.Series(test_pred8).replace({'neg': 0, 'pos' : 1})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df8 = pd.DataFrame({'predicted':test_pred8, 'true':test['class']})\n",
    "t_df8.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost 총 비용 : $ 6450\n",
      "positive를 negative로 분류 : 7 개 $ 3500\n",
      "negative를 positive로 분류 : 295 개 $ 2950\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "j= 0\n",
    "false_neg = 0\n",
    "false_pos = 0\n",
    "\n",
    "for predicted, true in t_df8.values:\n",
    "    if predicted != true: #예측이 틀렸을 때\n",
    "        if true == 'neg': \n",
    "            i = i+10\n",
    "            false_pos = false_pos+1\n",
    "        else :\n",
    "            j = j+500\n",
    "            false_neg = false_neg+1\n",
    "            \n",
    "print('CatBoost 총 비용 :','$',i+j)\n",
    "print('positive를 negative로 분류 :',false_neg, '개', '$',false_neg*500)\n",
    "print('negative를 positive로 분류 :',false_pos,'개', '$', false_pos*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 분석과정에 대한 간단한 설명"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 전처리:\n",
    "column을 삭제할 경우, 정보 손실이 우려되어 na를 -1로 바꿔주는 방식으로 결측치를 처리하였다.\n",
    "\n",
    "#### 데이터:\n",
    "주어진 데이터를 training-validation set으로 나누어 학습시켰고, test set은 따로 Kaggle에서 가져온 것이다.  \n",
    "training data 와 test set은 둘 다 imbalanced data로, training dataset은 약 pos:neg = 1:50의 비율이고 test dataset은 약 pos:neg= 1:40의 비율로 구성된다.  \n",
    "주어진 원시 데이터는 stratify를 통해 각각의 클래스가 1:50=pos:neg에 맞게, 80:20 비율로 training과 validation data 로 나뉘었다.  \n",
    "후에 training data를 SMOTE을 이용하여 oversampling하였다.  \n",
    "즉, minority class였던 pos가 neg와 같은 수로 맞춰진 상태에서 모델이 정답 레이블을 학습한 것이다.  \n",
    "\n",
    "#### 진행과정:\n",
    "Random Forest, Catboost, XGBoost, Logistic Regression, Softmax Regression, SVC 모델을 각각 비교해보았다. 추가적으로 Catboost와 XGBoost의 경우에는, 파라미터를 조정해보며 더 우수한 결과를 도출할 수 있도록 하였다.\n",
    "\n",
    "#### 결과:\n",
    "파라미터를 조정한 Catboost가 가장 성능이 좋았다. 다음은 각 모델의 결과를 정리한 표이다.  \n",
    "\n",
    "![title](cost_table.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning 하며 알게된 것들 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 모델의 성능을 측정하는 기준인 f1 score은 높게, 우리 모델의 목적인 비용은 낮게 만드는 것은 쉽지 않은 일이다.<br>\n",
    "대회의 목적은 총 비용을 줄이는 것이기 때문에, f1 score은 낮게 나오더라도 비용이 적게 나오는 hyperparameter을 썼다. <br>\n",
    "false_negative의 페널티가 500이고, false_positive의 페널티가 10이다. 50배나 차이가 난다. false_positive가 100개 더 많아지는 것과 false_negative가 2개 많아지는 것이 똑같기 때문에, false_negative를 하나라도 더 줄이는 것에 집중했다. <br>\n",
    "다만, validation set의 f1 score이 최대한 0.5 밑으로 떨어지는 것은 방지하려고 했다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. validation set에서의 f1 score와 비용을 보고 파라미터를 조정했다. (주로 learning_rate 과 scale_pos_weight을 튜닝하였다)\n",
    "<br>\n",
    "그 후 Kaggle에서 가져온 test set을 모델에 넣어 결과를 도출했다. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. xgbClassifier의 최종 파라미터는 (learning_rate=0.2, subsample=0.8, objective=\"binary:logistic\", scale_pos_weight=52, random_state=42)이다. <br>\n",
    "다양하게 learning_rate과 scale_pos_weight 을 튜닝하며 결과를 지켜보았다.<br>\n",
    "scale_pos_weight을 더 집중된 tuning이다. 52는 $\\frac{sum-negative}{sum-positive}$ 이 공식에서 도출했다.\n",
    "<br>\n",
    "\n",
    "|  scale_pos_weight | 1 | 10 | 20 | 50  | 52  | 52  | 70  |\n",
    "|---|---|---|---|---| --- | --- | --- |\n",
    "|learning rate| 0.25 | 0.2 |  0.2 | 0.2 | 0.2 | 0.07 | 0.2 |\n",
    "| **test 총 비용** | 11180 | 7890 | 7370 | 7550 | **7050**  | 7430  | 7610 |\n",
    "|  false neg | 22 | 15 | 14 |14  |  13 | 14  |  14 |\n",
    "| false pos | 18 | 39|  37| 55 | 55 | 43 | 61 |\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사실 위의 공식에 따른 52를 scale_pos_weight에 넣는 것은 오버샘플링을 통해 클래스 수가 1:1로 맞춰진 학습 데이터를 생각한다면 적절치 않으나,<br>\n",
    "learning rate을 0.2로 동일하게 놓고 scale_pos_weight을 각각 1과 52로 설정한 후 모델을 돌렸을 때, 총 비용 측면에서 52를 넣는 것이 결과가 더 좋았다. <br>\n",
    "아마도 test dataset가 학습 데이터만큼 imbalanced data이기 때문에 모델과 fit이 좋지 않았나 생각한다.<br>\n",
    "52가 모델에 무슨 의미를 지니는지 정확히 모르지만, scale_pos_weight에 (동일한 learning rate에서) 40, 50, 60 등을 추가로 넣어 돌렸을 때 52가 성능이 가장 우수하여 이 수치를 선택하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. CatBoostClassifier의 최종 파라미터는 cat2 = CatBoostClassifier(learning_rate=0.3, scale_pos_weight=10, verbose=True) 이다. <br>\n",
    "다양한 learning rate과 scale_pos_weight을 튜닝하며 결과를 내보았다.\n",
    "\n",
    "| learning rate |  0.1 | 0.1  | 0.15  | 0.2  |  0.2  | 0.3  |\n",
    "|---|---|---|---|---|---|---|\n",
    "|scale_pos_weight| 5 | 20 | 10 | 1 | 10 | 10 |\n",
    "| **총 비용**  | 8410  |  8090 |  6910 | 11810  | 7120  | **5920**  |\n",
    "| false neg  |  12 | 5  |  7 |  23 |  7 |  6 |\n",
    "| false pos |  241 |  559 | 341  | 31  | 362   | 292  |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
