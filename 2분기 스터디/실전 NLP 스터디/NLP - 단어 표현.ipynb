{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'정부': 0, '가': 1, '발표': 2, '하는': 3, '물가상승률': 4, '과': 5, '소비자': 6, '느끼는': 7, '은': 8, '다르다': 9}\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "import re  \n",
    "okt=Okt()  \n",
    "\n",
    "token=re.sub(\"(\\.)\",\"\",\"정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.\")  \n",
    "# 정규 표현식을 통해 온점을 제거하는 정제 작업입니다.  \n",
    "token=okt.morphs(token)  \n",
    "# OKT 형태소 분석기를 통해 토큰화 작업을 수행한 뒤에, token에다가 넣습니다.  \n",
    "\n",
    "word2index={}  \n",
    "bow=[]  \n",
    "for voca in token:  \n",
    "    if voca not in word2index.keys():  \n",
    "        word2index[voca]=len(word2index)  \n",
    "# token을 읽으면서, word2index에 없는 (not in) 단어는 새로 추가하고, 이미 있는 단어는 넘깁니다.   \n",
    "        bow.insert(len(word2index)-1,1)\n",
    "# BoW 전체에 전부 기본값 1을 넣어줍니다. 단어의 개수는 최소 1개 이상이기 때문입니다.  \n",
    "    else:\n",
    "        index=word2index.get(voca)\n",
    "# 재등장하는 단어의 인덱스를 받아옵니다.\n",
    "        bow[index]=bow[index]+1\n",
    "# 재등장한 단어는 해당하는 인덱스의 위치에 1을 더해줍니다. (단어의 개수를 세는 것입니다.)  \n",
    "print(word2index) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 1, 1, 2, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 2 1 2 1]]\n",
      "{'you': 4, 'know': 1, 'want': 3, 'your': 5, 'love': 2, 'because': 0}\n"
     ]
    }
   ],
   "source": [
    "# CountVectorizer를 이용하여 Bow를 쉽게 형성\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = ['you know I want your love. because I love you.']\n",
    "vector = CountVectorizer()\n",
    "print(vector.fit_transform(corpus).toarray()) # 코퍼스로부터 각 단어의 빈도 수를 기록한다.\n",
    "print(vector.vocabulary_) # 각 단어의 인덱스가 어떻게 부여되었는지를 보여준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 1 1 0 1 0 1 0 0 1 0]\n",
      " [1 0 1 0 0 0 1 0 1 0 1 1 0 1]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n",
      "{'정부가': 12, '발표하는': 7, '물가상승률과': 4, '소비자가': 9, '느끼는': 1, '물가상승률은': 5, '다르다': 3, '소비자는': 10, '주로': 13, '소비하는': 11, '상품을': 8, '기준으로': 0, '물가상승률을': 6, '느낀다': 2}\n"
     ]
    }
   ],
   "source": [
    "# 띄워쓰기를 기준으로 하는 낮은 토큰화 방식\n",
    "# 한국어에는 특히 어울리지 않는 방법\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = ['정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다',\n",
    "          '소비자는 주로 소비하는 상품을 기준으로 물가상승률을 느낀다',\n",
    "        '정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다. 소비자는 주로 소비하는 상품을 기준으로 물가상승률을 느낀다.']\n",
    "vector = CountVectorizer()\n",
    "print(vector.fit_transform(corpus).toarray()) # 코퍼스로부터 각 단어의 빈도 수를 기록한다.\n",
    "print(vector.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 1]]\n",
      "{'family': 1, 'important': 2, 'thing': 4, 'it': 3, 'everything': 0}\n"
     ]
    }
   ],
   "source": [
    "# 불용어 지정 시 제외하고 카운팅 \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "text=[\"Family is not an important thing. It's everything.\"]\n",
    "vect = CountVectorizer(stop_words=[\"the\", \"a\", \"an\", \"is\", \"not\"])\n",
    "print(vect.fit_transform(text).toarray()) \n",
    "print(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1]]\n",
      "{'family': 0, 'important': 1, 'thing': 2}\n"
     ]
    }
   ],
   "source": [
    "text=[\"Family is not an important thing. It's everything.\"]\n",
    "vect = CountVectorizer(stop_words=\"english\")\n",
    "print(vect.fit_transform(text).toarray())\n",
    "print(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1]]\n",
      "{'family': 1, 'important': 2, 'thing': 3, 'everything': 0}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "text=[\"Family is not an important thing. It's everything.\"]\n",
    "sw = stopwords.words(\"english\")\n",
    "vect = CountVectorizer(stop_words =sw)\n",
    "print(vect.fit_transform(text).toarray()) \n",
    "print(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # 데이터프레임 사용을 위해\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "  '먹고 싶은 사과',\n",
    "  '먹고 싶은 바나나',\n",
    "  '길고 노란 바나나 바나나',\n",
    "  '저는 과일이 좋아요'\n",
    "] \n",
    "vocab = list(set(w for doc in docs for w in doc.split()))\n",
    "vocab.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(docs) # 총 문서의 수\n",
    "\n",
    "def tf(t, d):\n",
    "    return d.count(t)\n",
    "\n",
    "def idf(t):\n",
    "    df = 0\n",
    "    for doc in docs:\n",
    "        df += t in doc\n",
    "    return log(N/(df + 1))\n",
    "\n",
    "def tfidf(t, d):\n",
    "    return tf(t,d)* idf(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>과일이</th>\n",
       "      <th>길고</th>\n",
       "      <th>노란</th>\n",
       "      <th>먹고</th>\n",
       "      <th>바나나</th>\n",
       "      <th>사과</th>\n",
       "      <th>싶은</th>\n",
       "      <th>저는</th>\n",
       "      <th>좋아요</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   과일이  길고  노란  먹고  바나나  사과  싶은  저는  좋아요\n",
       "0    0   0   0   1    0   1   1   0    0\n",
       "1    0   0   0   1    1   0   1   0    0\n",
       "2    0   1   1   0    2   0   0   0    0\n",
       "3    1   0   0   0    0   0   0   1    1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for i in range(N): # 각 문서에 대해서 아래 명령을 수행\n",
    "    result.append([])\n",
    "    d = docs[i]\n",
    "    for j in range(len(vocab)):\n",
    "        t = vocab[j]        \n",
    "        result[-1].append(tf(t, d))\n",
    "\n",
    "tf_ = pd.DataFrame(result, columns = vocab)\n",
    "tf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>과일이</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>길고</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>노란</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>먹고</th>\n",
       "      <td>0.287682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>바나나</th>\n",
       "      <td>0.287682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>사과</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>싶은</th>\n",
       "      <td>0.287682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>저는</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>좋아요</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          IDF\n",
       "과일이  0.693147\n",
       "길고   0.693147\n",
       "노란   0.693147\n",
       "먹고   0.287682\n",
       "바나나  0.287682\n",
       "사과   0.693147\n",
       "싶은   0.287682\n",
       "저는   0.693147\n",
       "좋아요  0.693147"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for j in range(len(vocab)):\n",
    "    t = vocab[j]\n",
    "    result.append(idf(t))\n",
    "\n",
    "idf_ = pd.DataFrame(result, index = vocab, columns = [\"IDF\"])\n",
    "idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>과일이</th>\n",
       "      <th>길고</th>\n",
       "      <th>노란</th>\n",
       "      <th>먹고</th>\n",
       "      <th>바나나</th>\n",
       "      <th>사과</th>\n",
       "      <th>싶은</th>\n",
       "      <th>저는</th>\n",
       "      <th>좋아요</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.575364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        과일이        길고        노란        먹고       바나나        사과        싶은  \\\n",
       "0  0.000000  0.000000  0.000000  0.287682  0.000000  0.693147  0.287682   \n",
       "1  0.000000  0.000000  0.000000  0.287682  0.287682  0.000000  0.287682   \n",
       "2  0.000000  0.693147  0.693147  0.000000  0.575364  0.000000  0.000000   \n",
       "3  0.693147  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "         저는       좋아요  \n",
       "0  0.000000  0.000000  \n",
       "1  0.000000  0.000000  \n",
       "2  0.000000  0.000000  \n",
       "3  0.693147  0.693147  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for i in range(N):\n",
    "    result.append([])\n",
    "    d = docs[i]\n",
    "    for j in range(len(vocab)):\n",
    "        t = vocab[j]\n",
    "\n",
    "        result[-1].append(tfidf(t,d))\n",
    "\n",
    "tfidf_ = pd.DataFrame(result, columns = vocab)\n",
    "tfidf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 0 1 0 1 1]\n",
      " [0 0 1 0 0 0 0 1 0]\n",
      " [1 0 0 0 1 0 1 0 0]]\n",
      "{'you': 7, 'know': 1, 'want': 5, 'your': 8, 'love': 3, 'like': 2, 'what': 6, 'should': 4, 'do': 0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [\n",
    "    'you know I want your love',\n",
    "    'I like you',\n",
    "    'what should I do ',    \n",
    "]\n",
    "vector = CountVectorizer()\n",
    "print(vector.fit_transform(corpus).toarray()) # 코퍼스로부터 각 단어의 빈도 수를 기록한다.\n",
    "print(vector.vocabulary_) # 각 단어의 인덱스가 어떻게 부여되었는지를 보여준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.46735098 0.         0.46735098 0.         0.46735098\n",
      "  0.         0.35543247 0.46735098]\n",
      " [0.         0.         0.79596054 0.         0.         0.\n",
      "  0.         0.60534851 0.        ]\n",
      " [0.57735027 0.         0.         0.         0.57735027 0.\n",
      "  0.57735027 0.         0.        ]]\n",
      "{'you': 7, 'know': 1, 'want': 5, 'your': 8, 'love': 3, 'like': 2, 'what': 6, 'should': 4, 'do': 0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = [\n",
    "    'you know I want your love',\n",
    "    'I like you',\n",
    "    'what should I do ',    \n",
    "]\n",
    "tfidfv = TfidfVectorizer().fit(corpus)\n",
    "print(tfidfv.transform(corpus).toarray())\n",
    "print(tfidfv.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 9)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "A=np.array([[0,0,0,1,0,1,1,0,0],[0,0,0,1,1,0,1,0,0],[0,1,1,0,2,0,0,0,0],[1,0,0,0,0,0,0,1,1]])\n",
    "np.shape(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.24  0.75  0.   -0.62]\n",
      " [-0.51  0.44 -0.    0.74]\n",
      " [-0.83 -0.49 -0.   -0.27]\n",
      " [-0.   -0.    1.    0.  ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVD 분해\n",
    "U, s, VT = np.linalg.svd(A, full_matrices = True)\n",
    "print(U.round(2))\n",
    "np.shape(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.69 2.05 1.73 0.77]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 대각행렬확인\n",
    "print(s.round(2))\n",
    "np.shape(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.69 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   2.05 0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   1.73 0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.77 0.   0.   0.   0.   0.  ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4, 9)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = np.zeros((4, 9)) # 대각 행렬의 크기인 4 x 9의 임의의 행렬 생성\n",
    "S[:4, :4] = np.diag(s) # 특이값을 대각행렬에 삽입\n",
    "print(S.round(2))\n",
    "np.shape(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.   -0.31 -0.31 -0.28 -0.8  -0.09 -0.28 -0.   -0.  ]\n",
      " [ 0.   -0.24 -0.24  0.58 -0.26  0.37  0.58 -0.   -0.  ]\n",
      " [ 0.58 -0.    0.    0.   -0.    0.   -0.    0.58  0.58]\n",
      " [ 0.   -0.35 -0.35  0.16  0.25 -0.8   0.16 -0.   -0.  ]\n",
      " [-0.   -0.78 -0.01 -0.2   0.4   0.4  -0.2   0.    0.  ]\n",
      " [-0.29  0.31 -0.78 -0.24  0.23  0.23  0.01  0.14  0.14]\n",
      " [-0.29 -0.1   0.26 -0.59 -0.08 -0.08  0.66  0.14  0.14]\n",
      " [-0.5  -0.06  0.15  0.24 -0.05 -0.05 -0.19  0.75 -0.25]\n",
      " [-0.5  -0.06  0.15  0.24 -0.05 -0.05 -0.19 -0.25  0.75]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9, 9)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(VT.round(2))\n",
    "np.shape(VT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 다시 곱했을 때 같은지 여부\n",
    "np.allclose(A, np.dot(np.dot(U,S), VT).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.69 0.  ]\n",
      " [0.   2.05]]\n"
     ]
    }
   ],
   "source": [
    "# 상위 2 특이값만 추출\n",
    "S=S[:2,:2]\n",
    "print(S.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.24  0.75]\n",
      " [-0.51  0.44]\n",
      " [-0.83 -0.49]\n",
      " [-0.   -0.  ]]\n"
     ]
    }
   ],
   "source": [
    "U=U[:,:2]\n",
    "print(U.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.   -0.31 -0.31 -0.28 -0.8  -0.09 -0.28 -0.   -0.  ]\n",
      " [ 0.   -0.24 -0.24  0.58 -0.26  0.37  0.58 -0.   -0.  ]]\n"
     ]
    }
   ],
   "source": [
    "VT=VT[:2,:]\n",
    "print(VT.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 0 1 1 0 0]\n",
      " [0 0 0 1 1 0 1 0 0]\n",
      " [0 1 1 0 2 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 1 1]]\n",
      "[[ 0.   -0.17 -0.17  1.08  0.12  0.62  1.08 -0.   -0.  ]\n",
      " [ 0.    0.2   0.2   0.91  0.86  0.45  0.91  0.    0.  ]\n",
      " [ 0.    0.93  0.93  0.03  2.05 -0.17  0.03  0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.  ]]\n"
     ]
    }
   ],
   "source": [
    "# 기존의 DTM과 비교했을 때 비슷한 결과를 보임\n",
    "A_prime=np.dot(np.dot(U,S), VT)\n",
    "print(A)\n",
    "print(A_prime.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실제 예시를 통한 사례, 뉴스 데이터 분석\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
    "documents = dataset.data\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to read the FAQ, etc. and actually accept hard\\natheism?  No, you need a little leap of faith, Jimmy.  Your logic runs out\\nof steam!\\n\\n\\n\\n\\n\\n\\n\\nJim,\\n\\nSorry I can't pity you, Jim.  And I'm sorry that you have these feelings of\\ndenial about the faith you need to get by.  Oh well, just pretend that it will\\nall end happily ever after anyway.  Maybe if you start a new newsgroup,\\nalt.atheist.hard, you won't be bummin' so much?\\n\\n\\n\\n\\n\\n\\nBye-Bye, Big Jim.  Don't forget your Flintstone's Chewables!  :) \\n--\\nBake Timmons, III\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "# 뉴스들이 갖고 있는 20가지 주제들\n",
    "print(dataset.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.DataFrame({'document':documents})\n",
    "# 특수 문자 제거\n",
    "news_df['clean_doc'] = news_df['document'].str.replace(\"[^a-zA-Z]\", \" \")\n",
    "# 길이가 3이하인 단어는 제거 (길이가 짧은 단어 제거)\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
    "# 전체 단어에 대한 소문자 변환\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yeah expect people read actually accept hard atheism need little leap faith jimmy your logic runs steam sorry pity sorry that have these feelings denial about faith need well just pretend that will happily ever after anyway maybe start newsgroup atheist hard bummin much forget your flintstone chewables bake timmons'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정제 작업 확인 \n",
    "news_df['clean_doc'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english') # NLTK로부터 불용어를 받아옵니다.\n",
    "tokenized_doc = news_df['clean_doc'].apply(lambda x: x.split()) # 토큰화\n",
    "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])\n",
    "# 불용어를 제거합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yeah', 'expect', 'people', 'read', 'actually', 'accept', 'hard', 'atheism', 'need', 'little', 'leap', 'faith', 'jimmy', 'logic', 'runs', 'steam', 'sorry', 'pity', 'sorry', 'feelings', 'denial', 'faith', 'need', 'well', 'pretend', 'happily', 'ever', 'anyway', 'maybe', 'start', 'newsgroup', 'atheist', 'hard', 'bummin', 'much', 'forget', 'flintstone', 'chewables', 'bake', 'timmons']\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_doc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf-idf를 만들기 위해 역토큰화 (토큰화 작업을 역으로 되돌림)\n",
    "detokenized_doc = []\n",
    "for i in range(len(news_df)):\n",
    "    t = ' '.join(tokenized_doc[i])\n",
    "    detokenized_doc.append(t)\n",
    "\n",
    "news_df['clean_doc'] = detokenized_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yeah expect people read actually accept hard atheism need little leap faith jimmy logic runs steam sorry pity sorry feelings denial faith need well pretend happily ever anyway maybe start newsgroup atheist hard bummin much forget flintstone chewables bake timmons'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df['clean_doc'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 1000)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english', \n",
    "max_features= 1000, # 상위 1,000개의 단어를 보존 \n",
    "max_df = 0.5, \n",
    "smooth_idf=True)\n",
    "\n",
    "X = vectorizer.fit_transform(news_df['clean_doc'])\n",
    "X.shape # TF-IDF 행렬의 크기 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_components는 특이값 개수\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd_model = TruncatedSVD(n_components=20, algorithm='randomized', n_iter=100, random_state=122)\n",
    "svd_model.fit(X)\n",
    "len(svd_model.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: [('like', 0.21378), ('know', 0.20032), ('people', 0.19317), ('think', 0.17807), ('good', 0.15105)]\n",
      "Topic 2: [('thanks', 0.3292), ('windows', 0.29094), ('card', 0.18016), ('drive', 0.1739), ('mail', 0.15126)]\n",
      "Topic 3: [('game', 0.37161), ('team', 0.32553), ('year', 0.28204), ('games', 0.25416), ('season', 0.18464)]\n",
      "Topic 4: [('drive', 0.52804), ('scsi', 0.20035), ('disk', 0.15514), ('hard', 0.15506), ('card', 0.14041)]\n",
      "Topic 5: [('windows', 0.4052), ('file', 0.25609), ('window', 0.18057), ('files', 0.1619), ('program', 0.1401)]\n",
      "Topic 6: [('chip', 0.16138), ('government', 0.16026), ('mail', 0.15625), ('space', 0.1505), ('information', 0.13575)]\n",
      "Topic 7: [('like', 0.67109), ('bike', 0.14268), ('know', 0.11428), ('chip', 0.11058), ('sounds', 0.10398)]\n",
      "Topic 8: [('card', 0.45115), ('sale', 0.21607), ('video', 0.21391), ('monitor', 0.14913), ('offer', 0.14872)]\n",
      "Topic 9: [('know', 0.44979), ('card', 0.35491), ('chip', 0.17206), ('video', 0.15184), ('government', 0.15053)]\n",
      "Topic 10: [('good', 0.41591), ('know', 0.23083), ('time', 0.18988), ('bike', 0.11332), ('jesus', 0.09419)]\n",
      "Topic 11: [('think', 0.78338), ('chip', 0.10778), ('good', 0.10654), ('thanks', 0.08962), ('clipper', 0.07873)]\n",
      "Topic 12: [('thanks', 0.37328), ('problem', 0.21778), ('right', 0.21728), ('good', 0.21301), ('bike', 0.21102)]\n",
      "Topic 13: [('good', 0.3669), ('people', 0.33724), ('windows', 0.28297), ('know', 0.25208), ('file', 0.18138)]\n",
      "Topic 14: [('space', 0.39916), ('think', 0.23326), ('know', 0.17933), ('nasa', 0.15226), ('problem', 0.12932)]\n",
      "Topic 15: [('space', 0.30963), ('good', 0.30091), ('card', 0.2162), ('people', 0.20295), ('time', 0.15889)]\n",
      "Topic 16: [('people', 0.46931), ('problem', 0.20916), ('window', 0.16015), ('time', 0.13971), ('game', 0.13578)]\n",
      "Topic 17: [('time', 0.34532), ('bike', 0.26907), ('right', 0.26148), ('windows', 0.19697), ('file', 0.19177)]\n",
      "Topic 18: [('time', 0.60055), ('problem', 0.15235), ('file', 0.13682), ('think', 0.13024), ('israel', 0.1093)]\n",
      "Topic 19: [('file', 0.45058), ('need', 0.25892), ('card', 0.18726), ('files', 0.1769), ('problem', 0.15143)]\n",
      "Topic 20: [('problem', 0.32669), ('file', 0.2618), ('thanks', 0.23506), ('used', 0.19363), ('space', 0.13747)]\n"
     ]
    }
   ],
   "source": [
    "# 각 20개의 주제의 각 1,000개의 열 중 가장 값이 큰 5개의 값을 찾아서 단어로 출력\n",
    "# 새로운 문서가 유입되면 분해를 처음부터 해야하기 때문에 업데이트가 느리다는 단점\n",
    "# 14번 주제는 sci.space, 3번 주제는 rec.sport, 18번 주제는 religion 등 주제를 어느 정도 반영 \n",
    "\n",
    "terms = vectorizer.get_feature_names() # 단어 집합. 1,000개의 단어가 저장됨.\n",
    "\n",
    "def get_topics(components, feature_names, n=5):\n",
    "    for idx, topic in enumerate(components):\n",
    "        print(\"Topic %d:\" % (idx+1), [(feature_names[i], topic[i].round(5)) for i in topic.argsort()[:-n - 1:-1]])\n",
    "get_topics(svd_model.components_,terms)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAABDcAAACBCAYAAADUkVGsAAAgAElEQVR4Ae2dTZLjuA6Efb+K6Ot01EmqL1J9jVn0KXoxm1m8rV/wB2QCBEXKlmSpKidiwrIkkkDiA0nBdvXtzv+oABWgAlSAClABKkAFqAAVoAJUgApQASpwYQVuF7adplMBKkAFqAAVoAJUgApQASpABagAFaACVODO4gYhoAJUgApQASpABagAFaACVIAKUAEqQAUurQCLG5cOH42nAlSAClABKkAFqAAVoAJUgApQASpABVjcIANUgApQASpABagAFaACVIAKUAEqQAWowKUVYHHj0uGj8VSAClABKkAFqAAVoAJUgApQASpABagAixtkgApQASpABagAFaACVIAKUAEqQAWoABW4tAIsblw6fDSeClABKkAFqAAVoAJUgApQASpABagAFWBxgwxQASpABagAFaACVIAKUAEqQAWoABWgApdWgMWNS4ePxlMBKkAFqAAVoAJUgApQASpABagAFaACLG6QASpABagAFaACVIAKUAEqQAWoABWgAlTg0gqwuHHp8NF4KkAFqAAVoAJUgApQASpABagAFaACVIDFDTJABagAFaACVIAKUAEqQAWoABWgAlSAClxaARY3Lh0+Gk8FqAAVoAJUgApQASpABagAFaACVIAKrCpu/O9//7v/+++/979///J/akAGyAAZIANkgAyQATJABsgAGSADZIAMbMZAqDeEusMj/00XN/7777/NDGZxhMUhMkAGyAAZIANkgAyQATJABsgAGSADZMBjINQf1v43VdwIlRNvQJ4jiGSADJABMkAGyAAZIANkgAyQATJABsjA1gys/QbHVHGDP0UhqFuDyv7IFBkgA2SADJABMkAGyAAZIANkgAz0GAh1iDX/TRU3eoPxPEEkA2SADJABMkAGyAAZIANkgAyQATJABvZggMUN/kEX/oyIDJABMkAGyAAZIANkgAyQATJABsjApRlgcYMAXxrgPSp+7JOVZDJABsgAGSADZIAMkAEyQAbIwLUYYHGDxQ0WN8gAGSADZIAMkAEyQAbIABkgA2SADFyaARY3CPClAWY19VrVVMaL8SIDZIAMkAEyQAbIABkgA2RgDwZY3GBxg8UNMkAGyAAZIANkgAyQATJABsgAGSADl2aAxQ0CfGmA96j4sU9WkskAGSADZIAMkAEyQAbIABkgA9digMUNFjdY3CADZIAMkAEyQAbIABkgA2SADJABMnBpBljcIMCXBpjV1GtVUxkvxosMkAEyQAbIABkgA2SADJCBPRhgcYPFDRY3yAAZIANkgAyQATJABsgAGSADZIAMXJqBlxQ3/vx6u99ut/z/2/3jH1au9qhcsU9yRQbIABkgA2SADJABMkAGyAAZIAPfgYHXFTd+fNz/LFXGfr/H4sf777Ugft7fS+Hkdn/79ed81afo2/v9c8n/qWt/7h8/bvfbSMupvjo6PxyHTn+NLQf40Iw5a9sV7ku8j/PkAJ3JyvnmmlexvxkLidtTzuMjbf/5uL/d9l2DPn+GDwm2WEs6c90BPnyHjdbfXj7E8zvGb8ToFtdf4cMrxpzUijnZmUsm9fv688Er1rRXjDnJwQFrzO45eQa2e2vMattOzMoKX85b3MjAjx/aegm0HKAI+8/P/R5Gov2db6VstjAnH3ctbjwdh1586vkYiz0LNCsS4noL64mKG2Rlv/nkagxzob3/zfmwZ2EmfQtyz4fjNL/s6cP15ty6dk3b3suHzfYCD9i01ZzyCh9eMeakXszJF7I4GaPpvN2lv+Vnk31se8WYsxzsv8bsn5Ozvu54X2+NWc3wmVmZ1+/kxY1OcWAqWMsB+hrFjflAPzxhLhVppuIwtnH3WGxk58Ma7jr+bHFjHIen/SMrLG5szvryPP40s5vbe0Cegc1x07ZrYfhE8wv4/WXifuKH9GmNX+HDK8ac5I85eewcOM3pZPz27+8Va9orxpzlYP81Zv+cnPX1CvedmZV5/c5b3FiaiPInYuXvdribOz9A8UEafrZS+lj51V7bT/mGibUNxiqffsnCHF/z3x5pfEj2F/vMdTW+uSaTs7pHfT06TCZv949f6ac/4Zsfn/J3UPb8NstSTHvXGj31p5SpIit/vwW/Ap70e/+Vvhoev7oteote4X04lvMxVrp/0bL/auIk8c46RvvCMY5hNcZroT1eH9ooC0N6TbzooqDiQHy3eg90VvYHG3v92H6PfD/w4Xys6DgFxlSsVM6OJvUJ3kMsBhr1Oc+2IZsSW2HU6b/Mi/leyQcVC9tnYyPmddABWcefZSQNyjwr9v39e5dxxb/HdZ6ZO7V9nj1//7bzhtXqmViJn7u/2rlLzQvWR+A9M/MRf1YT4vuZfmJ5u91FB4mZYkX1P8qJcN3aYPpv1v0UO7Eh6Pc4K22+Yb8xNlG/9/un0rGuQUmDD9BG2AItgfM23sn/999ah5ZJfT2sI42tvXE8H5o42f61/RJrtc6YecHGofwcS8Zv7Mu5Kn/Tzc4rxsbQf9AFedM6GR9M+1b7GT53uEexZNdq4Uf2TJW1qP2Pj/vuOWnjADmYtAebYky3zMnMxGjva210Ym151KwsxTVxhHOem282jpgP0b6gE8bT6GZ9KPsJGb/9yX7Jw6i74T08M0gu4ZqKdqKNoQ+8tmZOaXJ5Sc8nrzU6aR1xPghxqnFO+uz5jBEZs5qKrsKksd/O2xJT5Yft0/Sh/Qz6ImdH77kei+8Fixt/7h8/8e91JNErcCJEP4HLhsUGeDahfr+rhT9BoxMibUz1ZFAWP0l4gTODU33IkwrYFyEv94uPedO+4nyyIYMa2gnUYaxol/FjVpM97su22WQVHVvdkQWZmIM/1t8clyYOre4yVu/VxsVORnVCEV2TLdWnz/s7xFkeaMr1oY3ZN1h4rE1ie7TFYaUZ08YyxqHDsr33Ve9Pz4rDVoxt1bUbnylNJ3jPeVDYmurXzDXIam4f7W7OW85TPyUf5H4bN/s+P5zWuTH1W9/nOTBvkAP7eE3Yx/PP6ZzzbWruTDHp2aOKmDYWjQ41DuLTy18Nv9qeAe95XgvaCBOBS5w/5XzVqY29HrPVCPtr720ZtWzY920f7Zj+Pe1Y8b7B/C4aFG3iPN/nqh1b5gUoVjRxc2JleVx63/jQxunPr3f1YBTjAmuR+FkKFmausvervUrMFVlfIR7q/HjfGMfAwn1sL/Nzq1Fj05JGR11rYgt6NPtMPXfKg+i+OdnJg6JPe93moH3fMo8+2+PUf/xwJs+xcX6JuglDk6wAv+tsaHMy8S/jB5sH+0KxHQoGkcfeumrW0XBvb12S88/mbOJJ8qcWeh/df6zT2Ma98z7r2LPJjUspcEgcQ9wsV9nvZm5s55Elv+L4EtOSI+2HNamPNnfC+eQDfGhqfbbvDStS2BAuap+J1zmW3g7/QPSCxY0WUpXUBYAEEQYEIfLbtH1jm+5xhAOSONjgnRPb1ESaxlT2xLY40fX7i+A6k2wC2tgk4+PGAe30xi1tHtTmifZKk6YfP75VD7yOSR+OceIxOofYOHr6sU9jqInRtE9xwDHQLk9Tc91hJS4axUb0LffntZFJrrSrYy/rLOz5i6GvS+37qOvLPhhNM0uHsoJ5VljWdi3n7EhT7AuZAN5lAXYWy6k4AdvR1twPHtd+0IZqe9VczqHd3qKtr6uHmqJjHQttCUzI/I/H8R6ZA0ofYs/otY6l5nh37jS2w1iRV/jEsuqWxl/meWTjEdf7vkVfRrzDHIVMYPzwvOiD1+Xc0us6nVuf4ngPs4JxAG6AA5dnm2d5zkYmwrGwveS/fHNF35v8LOsWxGK5L/QHjp32aKvbp2mTdO6tk0E7s5dR7eE65iEeo+b52NoY36v1EWLm9eUyDro4Y7pabHZfy68aT2kmdoKPcB1zD3MOz0vfeF3O9V/TeLVgKXbUVx2X1qc4nuVhWkPwF+PnxRf6VDZhO7in73P1Ld3T+qTWErdP0ybaAAVLs79rY6Lb4/Xgm8wPeNz4A3yEaykOvZxNhWrpV/pSOrp+Wq32fb9sj9ZMfIh+x3kCrwNXcZ+10TNG0DzPSRgzPBa7pAhR5vWsb7VXtES7r7DnErvXvV6yuBGDJV//l9dmw64DWAFIAi1DPRIxT9Aydnw1i+/SBGgmiWCbsidel68N4qsZQyYYtSBX27VOOAlBIqKd8Rjvq31Z/fZ/vxy/XiLXzSK2B39nJp6Fhw7rd4xb0T+NiQt3O7G0msY+FEt1san+QDvFD/qW71HXazvfFtSp3mv9lG93hK+ruV+hfOlCNfLB0SjYW3TC9nhvOB4sUrOslLG0xirvJZ8LC2tyccKHGKPkn8TRbj5snG/if2hb5ocw1tv97UeyL/jQ9IMFVGCjZRDtNvNgbKevt+2DnnBP0Dnm4+f9PdoYvuWXruOiH/t5SGfgYzh3gl2ggeSWyvsyhxh/nHbS/rWvoINn44h3uI4xjcdYNFO65I2YOTfSoa8zMm2OwafHWcFc7+gFOhQ/4Bxqg3OFn3M4nhx7DOpzOEaxAfwfngN75V60NZ6LuYJ7mXBc57dFGzDPxC41Zs3v0M/bj7f0zdpwD7ASxyg5n22BfWNjs4wVXuN41v7wvt2TiQbHv3YYy374GgMLoCneG483zclk5/IalNkoa47wnF51LCtHY81BI+TKjKP7N6yATuPxtN3pftBcGENb8rnIo+G1rLPO/WhLy7IZs+TGwjoZx7DMV62RERwbfZQYq1fIubadp9de54wmEovyCqyUczIXBB2wPd4bjjfaNxYuw1jfdc/1WPyvV9yIE4teUNpEDmIgeK04fpv2vjb5Ur/4AOtWXZcmH2dyVPYUoMf2LE8wtX3svyz0kIho54pxW13qWFtdU5rg5BKP/fhWPfA6+DsobtT2c/5EG3EBKhqn9qP+4nXY5DXcOqzoPtG3bLPTJsREt6v+Letc7ytxdXKwXGvi5LTf4Z5lH5CFak/VA6+jnuG4v0jV9rXPrg6YZ8V/HLftI/pkeOr2r+a7jg9l3DxWtEl/+tPvP7QJ/b7fP0O7n5+RJ/ktPxYOUh9oQ/Wt1Uxr0MZRX68FqdqnKnQG24Jmv99jweXzZ4gfxNFqIIXlaZ3BL4xpPK4bv6SBsd0ZG+/DNaXVAf09w/HAN9Sm+A1tYI5CJuLxwoPUc7qk8VFnmW8Dv2Hs8vBQbNZar8tJbAvcYN+gg+Reo0dmE30PxyNbkS19r7HFsUFsmXp12qOtkp/KBtMGfW7G9Fgy7cN4aS7S81OJdbx/ed+obcbY9Qtfja0Y28OPIb+8sY1myXZgAa5jPOLxXjkZY2vXoOTHPjkJ/iJX8TjP3yNWsJ2n8/CcEyfTZ9R8aV9o7rcctiybMUP7xXUy6fRwzuZ1VbUf6mJy7oD7W53QBqNZtqfmBl4HrjZ9xgj96jnt++25MCbzx5crbjRJHyci+D1RSQgErxWk6ae0k3sTrG1l3iZ9Gmd8n/SLlb96TidZ7nOiwlkTrfZlJ7rwXt8HiYiTZDy2G/SJfstv0Jbv9exaPJdj2z44pXGaGEb7ZaHE+IO/ixOPjW32J/eLnzQlu8P9esNk/dG6t/rEuMODVfIJNq6w4ahjwvXoj/ic+2/agF4wVrF1oHO5T3IEmZFzE6+NbxNtmrF7bQY+vJ6VNqcbm4xv8boTr8hMk3MTvJv+5aGjl1+t9mGMt/v7z/zJaODgZ/hjh14OYM5V7luf0G47N2bNlK9tjuocCtffo43xj5/FIsdH2iA0/i/nha8z+IV5EI/t3Gl864wfdI5j4Xw/4LmNTdUYr4kP8zH2+8E+5Tjx68U+9JFjBz4p3mGOQibice9BKmps5jpZ20KBGcYSG+1ro3OISbAlfCqmHiZ8HdBW7Ft07m/mgRvkAHRI/Wm+cTy0PRzrsVK7dh/SMhj7VL7mtgP9UjtH58YHw3MTN7G15gv6ibqmY+NDHC98oqzbv/18j0XXxN77/QOKVY3P0gf4jPr2bJhhrG2rWRJWjs9JzVawM9oiawzEEeMRj3fLyWRTo0Ww5amcFMbs/ATjdebvMSt5bhPdMJ/xOHOPnLo8hzZoi40LzHEl5839DXMQyzIXN+vowjqZba9xET11zuE3o3wbrP46F5o2qF8+TvGw8936ftyx8jxQ/dT9NiwoXXBeAq42fcYIY3z3PZeOiRtHh5vLFTcwUeNXneRf+pBFKsOqvgblbnzyBFU+da9Jm8STZHaS04zx/jvcO76vTExq4kmBaxdWax/+1Wuxrf+VMVlAqw7oHyQiTpLxGO+bgConezuBT7R1gGzANVrbcayfdZKanXi0hrU92L/go0y8Ved207W4AOTiRGn/8zNuODQrSzZCLEVPxdeYlaj5ks7NtfYBo4mb2IKvCzpOtce+vOPGTs3yq1mRYkKJNWzOg//WPsu6aCT3FUaiFhO8F/0rT7oPYN7Tt9gousocJe9zEbXMqe04MV/UphDtTuOLf0GnYF94r+y0fjj91ZzL/MM92H+KRbVfNMZ4qLGxmBjtyPN+PM79NBxmHWSNkgd/1AnsKzY0/fh2lvu9mEkfXv/e/SvPNfOfGsfOPWB/tCu9RybiMT5IoUbeGgsb//bBU/isHFYukPVsZ4lPvfYcK+N8aH8GpudW1Cbakm1scqKsI3YfslID0NuuhSXWVieIpbCItoZzpW3s/+3+8Tv8K2aVB/RT+lCvKufzJ5nQXn42IjbLePJ+uG+Uuc36pvJhVsvKj/JB+nplTiodcU+pC8sYj3icdRFd6xpmeUu+l/usnnZ89cCNuj2bkzL3WPvS+chFtMWZv+38bJ8xYhxbFvQ6IQWLMPdUzhMPqa26H22J/Yv9de1QOd/cj9ql45iDOZ/DWKq9+Fjm6zxeeb9BzgY/hPWFecXNEcmV8FqYsTq2Pg/7wn7luLFRj4M6Bu7tnJLiCFw1xQ1Yf1R7sH/BxzS+2CTcyXsbpzqW8IW53OMPfWxZwRjk/oGTMreWcy1L2P/6PRfoJDGbeL1gceMxRx+CfkJA9puTrYB9ofg4m7JV8XQXmKyHXdQfZelZGx8dd5d235iVXfS8UK7R//uquWUzvfJGY6v5aDO7xuy2m7Jxm8c0xo3pXmO8qt8058pG9zF9XmX7Vx2XOTnm8Cvn5Fflei+/uG8c58te2l+3XxY3DtysfUlAc9XzkpunZwsHsb3/ycBmejxr45n4/s6snCkOtOVFhYbjNwryCWr9tOl4Gx5d944qbsRPlS5Y/JnTlcWNOZ2Oywvm5Fjrr52TY//PxuxL7eG+8dvsV7bk7HXFjfI1JftwyMTfMsD79ZWrqb2vWV3hAWqDwoFsVOrXNM1X6J/VYQMb92NgNlfJyutjMBsr3vc1YpU/He78lOMKPu5b3Khzkv9Tla+SByxunId15uRyLL5LTn6VuWVvPyoPVyzOR9a/xP597zjv0/9LihvLE9w+jnJM6koGyAAZIANkgAyQATJABsgAGSADZOBrMsDixrOfrLM9vzJFBsgAGSADZIAMkAEyQAbIABkgA2TgpQywuEEAXwogq6Zfs2rKuDKuZIAMkAEyQAbIABkgA2SADBzJAIsbLG6wuEEGyAAZIANkgAyQATJABsgAGSADZODSDLC4QYAvDfCRlUCOxcozGSADZIAMkAEyQAbIABkgA2TgnAywuMHiBosbZIAMkAEyQAbIABkgA2SADJABMkAGLs0AixsE+NIAs2p6zqop48K4kAEyQAbIABkgA2SADJABMnAkAyxusLjB4gYZIANkgAyQATJABsgAGSADZIAMkIFLM8DiBgG+NMBHVgI5FivPZIAMkAEyQAbIABkgA2SADJCBczLA4gaLGyxukAEyQAbIABkgA2SADJABMkAGyAAZuDQDLG4Q4EsDzKrpOaumjAvjQgbIABkgA2SADJABMkAGyMCRDJy3uPH7/X673e7vv/cC4s/948ftfvvxcf/zYIHj8+ftfru93z8fbL9JoP/5uL/dgh3p/7dff05TrEj6ZNvOrHPW8EzabcLG0VxeIGcvqevRcXxmPDMfnXn+HrKwO897rW1X6Detv6+dcz/v78/uMUa8j65Lrh2wBp1ivyL+frnXA3iOjLzdP/7ZP793Z4W8b7NP332Nev45abjO7sjCn19v5dno5c9qe895X4GFDTU6b3EjA7/f5vjvPU7gZ37oHgY6bc5eu0EcL7RxgnlC5zRB7VlEuoaOw0VigZfI+s/PbRbU3jgXyNlnNDyi7bO5coSNc2Ns8ODY4yyff3b+HvpxAM9DGwYavLr94/PKAQ+DQ+22ZHTU19z1Pdfy/dfR8V7g1byOxj81z3E+Oqa4sT8rKR/25D3G8tUfPg7noIWcmYn3AWvUUevsniz8jQ/+ez1DjOb2hRg/w4dtu3tx4/ln5tH8u+X1kxc39p3IH1/IDoLVwmvfz0x+ts0L3j/7wPZs+3HCnGRy2jE2h7B+AI+H+LFjHEYs7s/6UXPX/jm1OwsH8Dzi4ezXH48Bixs6tvvny9eZW/abw07N84Hz0f6s7M+7zq/9mNltnJl4z9zz5H7m8Zw4kebfobjxZJxnOL4SC8cWN2Ii3u43/AQ5n9u1arcm6CEJfnzcP+JPTm73t1+f6ecr8PXVOPGXn4J0qoG5iiY/F/F+/hJBKf2EsVb+pGRxYstfJyv9m0JRbBtsT4tMstP4MvJB4iljdL6d0V8ojY2d9jNJt9c9IUYhLhhzGycdR6NhYM/qtPbTBNte6eRsEmAi17bVny/pr+iZONwMK8GHEQtrcmyHe2N8wryCduI84/jgfSvM6mVj3eMsjf8Bc4XkFWrZ1xn5KnNGzCts/1dxGO7T9oUxw/04jm4f7O/5mGyw/Dp8WR5dnp12EneMEcyrRdup/l+4cYr2DeZO44OOU7bd6OCtEUUT0Q5ee3EMbSQfFFdq3nByWuXLMkt27Mqs5acXp8Qorq8tzyMbZ+ZWzAX7M1RhNL2KD3ZesL7a6ylG0lfP39H1XrsDzm/Es9XJZR74tWz326cYvv/WsbT9K9ZXzo12bGFBr5NLsfB5tqws2xj61z4GO0ofMU4wn8sco/LatIdraWybn2fk0viAGgg/4rvsPWEN0hpbf5diqK9ZJipvQbP+OjvWOfnX5bnxre7bqg3aVptLR73vayT2LcUysSe59phvpn/gXWkQ11qfBe2Dd48Zo/Co7Rc/4mtZS5dZSTbaftAGn5UyJ4R8MLyoa5IvS/OK08f8vCdxPt/rscUNEDEFIAX1Mah3EjNvOINNMkkGW2MCFGDz2L2EibDBIlQAqzbH/nqJ6NyPiSp2qWSKk7wkRU5GtDfaCjZBQkgyKB+HPvy5f/zEv1fSj2W0t/G1tfEZTVCfLY+jTUFbsd/oYm1uFrass2i83raRzkl31b/DpYqt4quNQyoQWFbgvWpfmV7v23Zta05IDhhdOvyjbjaWa/yR8UN/iZmgV9I2zW8TOstDqbBmdG7YyoXJOn8mn8O8IOdiG+hv2UejmWfPNM9tX1HPYRw67YwWa2Kz+b1Zg6Cz8KPyq9Eo+SQxcXVY6Z+Nq/VReKwfJBgbbBxk81PWjHT/EkthTOX3Kh9yPoCGzbwT+C721E2caP4381/f2/mkzTnNv/hY57Ymx36/lxgHf5vrxefUV9+W0XVr+4HvN+BZ67re9mWex6y0cUl615yTWPfnxq15tjbZ98JvtbHlVeV1jFNmtZljguZtex2XlsFl3dfHUdlbcmNdP8M5xfXdGcPZB83ap3WzfY9YGuk85jnaifF+UMtZfx+5b8xOy6M/Trqv5oHVu/e+7b8btw4L9v42R9sxWh/aeNd75lhB37UNeXxYJ/V11KZnx8iHXjvs+3rHxxc3QpJm0N7DtyNw83KGBIYkwOSNx9ZWuLfCXDdhCGx7vW6o1LU1GvQmP/d8ArzY5CwQ6K9UA8v9E3b1FiXVr/QTx5cH0Zw4rt2vTSo7+cmGJG1iw6Rg46gnip4mD8e8eaDQ48V+HS67dria+6ysYeEZ/x5pGxmDT29koyc2B//lWPpXmrg6zLOHjGO/ZVy3f6OzPDxBMUJstf7IeRxX2FR+IguuDdpHtN0bU1/XbcWm9OpwmdlV9nV4Pt26IPNWeI061sJG8BfjEI/NWoHXPV21dku6pmuxv2buqe30eNAm2+XGEVlpCmd13cY/oO32g1p1j1v2RZd+gcC2SYx1WYlxWlpjPEbDOTunV11T7L3rXl/QbliIwXsPPn6W54l5ZcT3Ms827kGfdC6x4l3XOTmcGzOnm/KsdJmwUeWfw4D096vzx/bj9SXebTHSt2kUq72vxxiotVxrMR2jkZ69uUl07v7h1pTrah0zY2kbrc72veU5+zu0Q+uyd1xs/8s5668Xto/03tNjwrcJ3st4Jj7pvDfXm3ncbWdtM20UVwNW3P6xP0ebLhfYDmx0x4DreW3qrqPKH2x37uPXFDdkQ7swgRUojxYWQMANYjw2G1Yp0uBmr9gdAaxfJ1MbNhij3P+Inz3IO/2rCbfXFu1Y8kE29OVrgdlXq5HcZx/Yoo1Vn/otFG/j+LokUpqhNuHY6FN9kAcfZ2KyfUy8T4uI0aro7ExoTvy7fjj3Biab+42viucJH57ifKJ/zNV2rBQHjE85Fh07OrR9+Szi+KhdOI6boE7/eG8YC/vRYztxDrqofjv3iH7qXt+PxHTeIMeY42Z5Dc+eLRNxiLamthIjtYkUX175GnXpz1MxpnZexG9/bfSgq+cFjJPPUWWrE0fllxe/lhnLr2a2vb9e92xoz3laah4WWIm8m3kzxkVi5/loz+n+E5PSHv2z7fBaOB5dt/cf+F7FvR3Xi0HUQdb0mXllIl/7PLdcSHEjsdDRVtnVucfYtSnPStfO+GBjzc82BjFvYn+ZZ9Ee7R/yLnuW3vzeGRfHOOhYMad89Vjo2A3a1nmncy/6NWzXiSX2EWPV09nzwTmn+JmwG8c/6Lifs/4a5MfB8X3G/hnepR8vpphPZm9H7JsAACAASURBVL2W/e0wJ2P/SzwsXetphHrgcWagy4U/1hofTrvnkjiueH1JcUPE/gz/TI+auE6QwJAEYmf4p2LjsTwIicBwr5+02Z94H2yIunCu9L/Xj3veJIl7z8L41gf73nsgzjqhjkWnOL7ekJdrou8JXpc3O2Eygbg69i63X9Bb+hrq7ExosY3WtmuHy4FhRWyRV8emV8fOZUzszWzqhyKjvauDuQf6s/7i+Kh1OI7juv23OmM/eoz23nBd3++wgDa7Nlgf0zhhcQ99W83QN22f7ce3peiBdi0dR5ulWGjHeNH7gY4xJnatUD76sVzWc9nXGBdYSzUXqS3GDo/LuGre8ONX7s3+uP0oX3t2exroMaMP6gMQrw30b1mJ7/U8qO3X48VrKrZpPPWJlroOYw+LF85YUzrhGDsdd31K4w15HrTXms/5oHn24o56etdXzo178Kx0mbBR5Z+jE/Sn9cn3xutLvIf7kh29+f2RWO3bJtmLOTg954z07OUf6Oz7huw5cYr9LunsseD0ObSjN/ZrzjdMTuvv6THhwxTvuR/XlqD58v5df3jUs8mJXWFr6Zr9cEr6xzaONl0usJ301RsDrhdb87nY/8n2XNbGiffHFzciZAJUChxOXP5k0gYibXzar5rPtu/eB0mAG0R3gYd7u/2FIDQwZr9hM+q2z5B1/7hL06/o1Oqa9IKFr9tW+jCv5v6mv6iF/zMj1LH62dpYr5mxByDHSRV+k/ZoP1670ULaTOjW1qyLVIK9McI58cE+TI51TjqWdh1mmn6KnW0c+vfmuBgWej7Z86nfHXK2ech3+IlxkHnHuS6/Vx7kpPhg56x4PrdFZsJxis2kzgt2NnHJsa5sdRY3G+uBj3FB//F2f1MPllmzSZ67n1Qv+Gd5Se9HPnmxlDkX/lZO0aBz/5rrI/6buLRjplgu8RjaJN9vow2Ywz/yGHW0NjVxSGOVeWT4sJ58aphsdOz5YOYt8QGYs3NrGkvyqdVU9Kr50OacZqxlS49pNcn9ufFo+xqNpa97/sC5HL9dPgx6muesy2heER8gxj0NNL9jVhoOLe9b8dz1obXR7vtmbbRrS9FIxcnTPJ9bLKzmh53e/N7kLzAI12Ke7LTnKv7m8eJY6NPsGhTvgz0v2B/GEB/qnCe+etrKtfA6yvV8bxjf1bllpWEj2mrnH7Rh7jj1uzRnzvVjY+K9j2OpOSDZ3+W5xKPVA/sXH9p+JnkP43RY0PO9p8WMD0t2jFhpY6xtcrRR8wDa3BtrxoeZfvAe51jmRsWAc1+J+77Xji1u5ElJTSYiCE5eM85Lu4mFEhNleAxJgMkaj6ONGWTzNSa1Ac1+yld8wmvdcElA236ULkGDkY/xem+DnIEudppJfrGtTAb6K73aB2P/j497/CZOiaMdX/pCO0wfwdZHEkP0fqTtgLVmYXXul0Wyxht99LQ012cWWoljo7Pt//3+GWNrx7Ba43UbK7xm+09x1CwI04PXEc+OtsN8zW0wV7tthBPRsslLq1G7KegttDg+MhOOa14PdM6+aJ50futrdl5J/S/HZuyjbN7azUSOb6Nj5aXoAxqHvKgaDHgqjMh8YdpOM1L9XNZjwKw33mjuDG0m/Gi0auYv4UUzEPi2HNgCeNO380Bu71Exmt3AS1GwxLuykPJwhQ9d/zMLPz+j38XOCY3lk+o6N+MaUxkp18v65bP+/jv4U+NhNZR+xMbR9e5c1XBXbT0nz9U+q0HxscTLMjLiue3b2yfYnNA6zcyNIeZ2LGNr14fUTuIefY73VlbCuWUbw/iSL3X+K340/cm9OIa1H3mXuS63s6w3zMn9zqusAU3OOveu6bfR37PfW0MkTo7/cW5CjZKNEgsVs2Jr20+9b5alns5t3x7PkSHROc+v1YZJnbu8TrYverT3i36S73YNSnkvjDo8G99KP4bLMoea86n/JS2daw4LYz8WfBB9is51rUL/Sw7L/fhq26qcSj6ouJt5oOhT1uBkg2oznFdqfEIcdNs29sk3e77qvegv+r7j8bHFjU0dyUIqEKzYfO9D+NV06S0iX83Pq/vDnL1GPqZ8OsMC9YxeadFvN7XP9HmVttF3ro33q8Rrxs7vy7Ozwd90L3n1dXWt/VvM79xzjXO2p/ORPHPPNY7T2vzh/T1Nz7RGXbe4kat+j1WYCGcPziueTwllP8VmjE8XS+bsJR624icZ7qckV8qpvPn+pg/4LG5cidUZW78zz0c+DM7E4tr3bDG/c881ZqCv84E8c891iT3X6fbqDxWPz7VGXbC4kSuRzVfKx5PN1wCIftY45mSCrwnXa9TpPFowZ88Ti15e1Bh1vyL70ILXG2+/87Lx7v6s5iJ+PMMMixv78fVMXB5pS54PfBj8snPDVvM791zLOTyj8xE8Vzuu/g3MZb2/zjx/ZT/PuEZdsLhBmK+cBLSd/JIBMkAGyAAZIANkgAyQATJABsjA1gywuPFlK/VMlq2Thf2RKTJABsgAGSADZIAMkAEyQAbIwDkZYHGDxQ3+Jo0MkAEyQAbIABkgA2SADJABMkAGyMClGWBxgwBfGmBWTc9ZNWVcGBcyQAbIABkgA2SADJABMkAGjmSAxQ0WN1jcIANkgAyQATJABsgAGSADZIAMkAEycGkGWNwgwJcG+MhKIMdi5ZkMkAEyQAbIABkgA2SADJABMnBOBljcYHGDxQ0yQAbIABkgA2SADJABMkAGyAAZIAOXZoDFDQJ8aYBZNT1n1ZRxYVzIABkgA2SADJABMkAGyAAZOJIBFjdY3GBxgwyQATJABsgAGSADZIAMkAEyQAbIwKUZYHGDAF8a4CMrgRyLlWcyQAbIABkgA2SADJABMkAGyMA5GWBxg8UNFjfIABkgA2SADJABMkAGyAAZIANkgAxcmoGXFTc+f97ut9v7/XMvgP75uL/dbve3X39OEKDP+/vtdn//bSpcB9j4vXQ2+m7G1p/7x4/b/fbj4/5nsz6Nrb/f7zePkb3GO7TfxH/wL/zfz8nndd6d94d1S771fTc8LI2zOyvPx2H4acaVfcjztvDsz+tv949/VsR0Kd6PXBvZKH0+vQYdwIrYeuZX8rzrPuvPr7e4dqScW9g3Ph2HC/C8ImejbnvuWx7NyRU+DNeSjg377QVG+5kN1/qOb2NNRjbK2vQ87/vpLDY+/7q7jeR51/l/zHvLyMuKG2mxWlikHk7q7OQBsM0L3ilu/E3nN3ng6ej1vXRuAZ+P0XLbODnuuUnIvDYPSp24buXXsf2MFv2vvNCOfF/mT8XpqQ18by7C8Z+Pg7LXY/gA3pdydptNf0fL6NuLixtF846Ncn1xnRy0jX0cwIrYeuZX8nzM5jbOfQv7xsW58YvwvJizOI//vW8zz+k+h3N73tcu72VSLF62991kju6t6b3za3Xc4v6RLcvzd1xDf34u5vbuhYMN5v39bSTP43lhC57n+3htcWPPh8UNEmK7YPUW1d75+QCObHzN4rad/SP/jro+M8k/Zcsmi+3ZdR8ttGe3/xn7zuL7/nPOVB4cwPtSzm4zL3a0PMC3KY3jGtixcWp9fKbtM7lywbYHxJw8/73/HRU3Frn+fjxvM8+tzccZnWfuWTuuvn/R903ytbem985r++bn8GfaPWfL0pxzjP3P+H5kW/J8Nh5eVtxYFCJX3+Vrv97PAWLS5a+566+6J8ik7erKcBj7x8f9I/5sJnyF/jP9JMH8ZECP73ySYH0w7Rf9X1ygN0xYa2NTbEoTo2gZXms1/kmdo49L/adr77/1PU08rQ9OlVnHyvwsIi5y6ecSmqMNdX42nsbG9udcOhbtddkUVj+9nOoyGccPjOM4hnkTh8oJ6phi2cTw79+7ilHDYegDx65+SF9xI1PmA2Nb1l/fYzgI9odx0Q/XDvTHOcb2wZ7Sh/he5xOdT/lTtsAv9oE8Gw5cjc09lQVfv5jbMMY4DiZWak6oPiitof8uY8/myGR7ZVfhJfBkvmmBMQj3uT4kTZs4xBhAfxKTwoLDjbJ/Zu7T82Jjf+mvY6PJJ8mjFJ/tWPkrvhetdW4q3hZ/stbRzMYpjiPaO77H+8WGcD3ci/5K2zre0zaWWNQ+t8qDWZ6tDw2z0UZHr3D+aZ49nXEvEXSZ5FnFD/Q0nGn/ML517Xhk7lNzc2DN5LTVWecV2NswkTX6lX6eGvr9lJ/ilLlH++H3bXW0Nprrxv7ApfVBa7m0l9D2RX0l74sPSxoccM1wgjYqPe19jk7CrGoX45o0rudF83Zu6c0DMa9/fqZv3oiGxgab+3U81NHaUq+pOJu+1TUZP77K3JnX+nKtntc+ie817xRPVucVf6ogafQBz2fCX9VZa+TbaH1tdRz40ORy1VhrscP5Rr+qs/LDrpNuPvZYsedFj6rzyE/hWc2f1gZjo+LkAY3PV9yIwVoWLcJokrEV1wZkEqwscABDEiOIHMfMwbDjp/sgcWIf6ENKumeD1fo46ZMHxlDnDLAFsOnrQZ1lEe32LwkEmyBPV2yfEx11trFSGjb3pzipSaHx9wnNH+prxE5r85jHlT5kncJGQLTFfEgTFvDe6CrjjVmJtje5bVlc6CcyArmYNW80yQ93JdY57+tmtdVVsePFsuFT/A6vLc/WpvQ+LE5ify/2a8+jHb22eM/C15l/vxcGgh5dHyQvuyzo8Ybaeno/cS7a3XAmNn3e38X+MEbXh46W8f6cD922Mpb32rKic8zmgzxwQA4WbTo2lusLuZRzRHK+F6OulgPfu+2KbZ42cM72j7rHPhzf1fyQrmNhyK4XT9s468uT9y3aOcjZGldHr2AX6mo1n7K71TnaW+a5FTyr+AELxY6OD/H60rXaV1fLxfl9Yc4sttUxquZyLmsU5qSscSyouv72crbVUfvSXre8h3kG813HybDQ9WtO51YD0eKAV2S68ePP/eMn/n215E/ZK5T7l+OQ7m81n/E76Y5FdW1DExe7nxnaWDXWjNTzwU61zyt96nvS2iR7Frw28v05TkSjwGu0MxaqOzFx82gmZ0c+oL8vPF7keXY/09Eu71034bnM+Sb2dm59aJ3R+p+0uGE+VcWkWgwiOtcLFN7jHEMSYNLH47jhDUGxm0gdqJBoeiLU12cmt93vyfBoO0EP0GHZlgd1lomzwA5jx3h7/aZzuPhq20ybASs1pnVsjLnuu95z7PnEjv/JsTzU2IUFeTOaYC7NHjsTDerU8t5bFMe2YL9V5+CPzjkvdvF+l1t/XDWW025qYS8a+mNUH5zrhs9oj8oHp00cD+OLXA5YWWyL/cws+vl+zwdVNOj5oMerOh1zXsW+xLA3ds+HThxEk/wpbH++WjNesiH2Jf2rP1i60sbic69dsK3jX2mb7O9pOcqfxLvO61UchJx1WKt6O/arPB9dl+LdEzYarVb5t6JtLwbueC4/C/GW+x/m2dE5spV1lf5neFbx8/LHG0vuW7om9/TmvqU8SW2f4xlsQz3isV3fO7Y49younOuqcOXxhraE6/G93d9W7RJv4IvX5xnOWb8GNvlzWScO5WHwI/5DAt2928KYKm75vnguPoP443pt5EOV7j5fPqBQ82iNp+93vR7j3cvJ3vnid+LkEX3CuOgv2hmOG387tsQ+zN5SzZmdduqe4o/R5cjzq3j2+emzIvc/yfPC3taLGcb0Eb3PV9wIQOQJVL4yVjcrvYc5DyoJyMp/LQVgxuSJx2FiMbaJjfVTbW/ck072xhfUGX1fBsvz14uHfy4CLF9tUxOs1297TrXP/ZSJDWLp+eC1jfFUdvh2e/3tdy4vAtY/M8HX8VGnDdhbnDjTWJgH5Rg//Y4TPdrl6+pzl8co/SWfSpxxEXFj3tEA78Xj3N+6ybUzRrHN8d3o6vvu6bQ0VromMWg1Wmpbx+rbovtP49SHv7ad43fRpI5X2T3mXGunHtebG6a1xHn1obnE0wzOOawG/XxeR/GGfpu4jNomzXwtl/qtWse2Mv+rzU+9p8tG1rmsW1GXyqJbnFHaOf6p6+DfozY2mk749UAbPwYy1nLOVn0dPYItT/Ps9QvnHM27PHfuHfoQNYUxFzT2tVzR9iFWoH9cF+LxZHHD0Ub5Eq/Xr63LGoHfXJKcqdfC/ZhThgf4NudcDITJF7+ixg4Lel7KmpX9h9jem+PSebs2Vn2kff9VxS3bV88BK2i7E//+A2sdu/Zbz4mt/ppi7nPH1cUH6a99Tb4Ib+0aa8YCf9FutDMcN/10bAz2xH46OYtjtLb3bTv83gHPUZ/iY+K50agU5ewz8z48V42wfzM/NTk3r/k5ixsAsP46rkysZrLF+8txb+IZiANJgGDH4yh0SMal8b1xO5NRsXVg0xH3Rb/BL9ChQujZ6fnr3Tc6lwEvMHv9ah3TpIQLv2kzSPga05FtJ7oefao/D/G/Eog6GU0eYWmgo7uYuOOMbcGcq9yldrIAxtfCiYmNy60/rhrLaYcLZrXFjFf89Meo7ZzrRldlT+nXGw/j613P5ywrsc+5tr4tOQ6o/dAHx+9F3xb82bCd718aO15TD9o9HzpagiaRodUFDm88GAv6X+RrKt7eWBIDGHNB+56W6/InF2fWaJX5xnmhFDp6vqs8d/xT10WH+vpYPGv7Gq9tz/ViIA836tNRl59gj6NH0BHuf8x/p1/oE/uv+nS4HMSn60OPB4drX8uOPU578WGdVqBRow3ucUKcOrY42ihfYr+2L+Qw9TvHSm4Xx4R94wqdRaeXvKLGNoaOT/5c1okDxsfpa8ZfFbdsX7XBH9dr02UFfPbbpfjWMZETc+xwF33snYexlRYxJrC37d2Xz6PdaGc4bh7cJ22J/eAaNNlO+TGwe5d7F3iOOk3tZ3yuFENRD5vvhgfHf4yV578bM6cfr23v3PmLG03Q8gSMALoi9AKVA5ETqf6+PZ8HmDEg8Thv6psEMONjO1lswwZMb7zGQJRPTIa+TvRlbGyAaHROi61a6Nw+HtTZ6SvqWh6c2n6jrpCkNg7pOk5sA1YyA6vj0tietQLbGn2bNo/GDDZBsc/0HidzX5fRhCQ+OPc1bBjbpye8NqZWJ507eZw4/tKmDOyB/MW+LTuSWyX2TjvNYxpDGPPyIl1z9Itxcnw3urq+u9xYBsB/db93X86Jkmd+W98Wy1ruC4q9bTvHb2XjwviP/IHJib4jFwvM+vmD84rY7OmrHwZlY6B/PpHb5/mnWYNwc5z9SWxJDrQx1NfFvvDasbHotBSfdhzMKTluY57HjxrPr3u9fmI8HBbi/YscG98avR1tnHlA/AyvPRvxHu9YfCjzTdEfY/XEcZfncc5Wex09gp1qnspMOHuSqE34dLCJSduvzrGWs9SX8A66DOKzzHs7TvW9jtGLcbKpN7/X9tJnrx9hAddsZTfqHY+tDobrwpLWOdmLf1B05P8aVrK/aGuxYzROq5VoVl5jv2j7RJsy/sy91tfaJukGmud5rOW6Fwd9vs9NsqH5Zow3z2Q9ZP5obDTXi47OWlKvJZ9jX04+h/uacTyNuzmZ/Wvmg6q1tiXdLz7KtWRDO6+g3TGn8jjhWOfW/Df+sc80/loffN/Eh8YuT8+HziU7vf71XCsxdTTqsjLJs+Ss8xzU6mp06q5f5r4V2pyvuCETCXyFxsJeNoxwTwmq0979pLcXCEhUDEg8hiSVBap+agSTYYZErsm/+NH6MQpcXiQeKYyMIHB0au3LiQ06l3uc9qt0NhrFtmqCrb6Lju0DgrHv52f8anZhIWrQ9qOuFw7q16HU9ZGO+brw8EhbmcTd1xn77D1Kx8SYTK5jLZ3NW+zfOY/aODzMs2LiWHirOSX6FvvDPcXPNsbpPm2z7aPYF/yAvJc4xPsh58P5oqM5L23KdfHB2Kj4MLrGtuX+dm5o+s5jlD4tB84DYbTT3ld8Gcch6VRz5f13aFN1bn1IsSk2IjNLx8XGyoBovNWr5qH6IA8ahTUzr8zFwesPz8lDY9DS+ujw3HBhY6X7GNro5Gv0t7CQ+StxyDEv1+34woS2w/KCvmr9PR2SDXJfy5Bvg7pP+fl+/4z+iI2p/dI8IGMXFppYtXnq8il2NHGcbL+UK/mathVYk7HzfOHmrMxX8Fp0jJpBf7lgZh/KCnOFEfHNidPwHolR6MPJh2hntamMDfaHmBUfRL8neW7GgXhq/dfyDCyi3siriWNhErXEe4Jt4T3Y6GqJ17F93HcGu6rObT53ipddnYWJ0WuNucpPieMWr8bXykodO2os/3KN6GzatXFI7Wt/8gcvLY+SF6Bv9qvhDGOQ77G8KZ2GNsrYMm/LK+adl3ty3WhU8s760o5T7LSMePm6sOeKGmV2oxY5PuE4aT+20WqI61Odxxd8mOWw+Cr6jfh/4LqJeeXP2G/2M15OR6aFd6foIbrVMZb2M5MfChj7gw2FlVmd4b7zFTfAuArXA4H+Iv2kSc5OGN9Bj3aBODUPOTGfScZT+/fKfIra2kUhTdhqcn2ljRz7vi2/eWOCG+9vo/HF5r4XxQU3tIW9OFeccb3MG8yyYfwOa7j4mHzn2ih68LXk68Lc8X33vpMPgwvazejLe47Mw++8nzlS5zoWixunniDyhogb/I0fnGoCbDPB54nr0U/1Ts3g1lqt7y9tckxxI1fCuWFer+c2zO88bi4Wfs/iFYsbY0bznGuKBe5ccYL5Ndn13CdRY012zsmHdWRx47qxexVT33nvy+LGl8uXb72fec0cwuLGwwv2vgGTzVD7O799xz3PpHKRDX6etPRXP79LjI7zU74GV74C+uRX1s7D+XEaXsNnKRR+1wfBwMNF5r6Xr535Aah8Jbr/U4DXsS82nvHbJEfNPSxuvI6/o2K83Tjc+7K48XXyhfuZV8WSxY2Xb9C2WxReBRHHZQzJABkgA2SADJABMkAGyAAZIANk4JUMsLjB4sbJf/LBCeKVEwTHJn9kgAyQATJABsgAGSADZIAMXIEBFjdY3GBxgwyQATJABsgAGSADZIAMkAEyQAbIwKUZYHGDAF8a4CtUEGkjK91kgAyQATJABsgAGSADZIAMkIF9GWBxg8UNFjfIABkgA2SADJABMkAGyAAZIANkgAxcmgEWNwjwpQFm9XPf6if1pb5kgAyQATJABsgAGSADZIAMXIEBFjdY3GBxgwyQATJABsgAGSADZIAMkAEyQAbIwKUZYHGDAF8a4CtUEGkjK91kgAyQATJABsgAGSADZIAMkIF9GWBxg8UNFjfIABkgA2SADJABMkAGyAAZIANkgAxcmgEWNwjwpQFm9XPf6if1pb5kgAyQATJABsgAGSADZIAMXIEBFje+cXHjz6+3++12y/+/3T/+YdJeIWlpIzklA2SADJABMkAGyAAZIANkgAxoBg4vbugH6vf7Z6+48Ps9PnS//9YGTwfwn4/72+12f/v157zfTDjAxs+foXixoHPQP9rB4sY0Wz1mef68ucbYMDZkgAyQATJABsgAGSADZOBLM3B4caM8QMbixcJDN4sbm4CXikkLOocEZ3FjE60L25w0qScZIANkgAyQATJABsgAGSADZOBQBs5b3CAIm4AQixs/Pu5/lvRkcWMTrVncePBbVkts8hrZJANkgAyQATJABsgAGSADZGCCgfMVN/JPNeRvQbg/S8nf6pB70qv8rOLz/l7+jkTvZyn6Hv2zjT/3jx+3+/vv9CpjuHa4Aoe+3+4fv9LPam4/Pu6f8rctfn5mKPX4/k9n9PjBjsYGq8OoiOHay29usCjBogQZIANkgAyQATJABsgAGSADZODaDJyvuFEewFMBoHmgz8WPcr77rYNUHGgLB6lfPK9/ulGLCjKGvj4KeC5chEKDFGpCUcP9GU7Pxr/3+LcySjHEGTP2JwUd53rRceJaV8OJtmvG4b2suJIBMkAGyAAZIANkgAyQATJABsjADgxcr7gRHurVNxRSgUAKEbXa1ikcuEUGLKQ47VY9/ENf2C4e27994YyVg7z8h0D77ar/KwoTaOcOkD1kE+3ghEcGyAAZIANkgAyQATJABsgAGSADkwxcr7gRH8ThJxrdbzD4BQD/b1DgvXicCwSrHv63KW6EgkAqcOR/qlUVdGCMyUAvFhhW+beiaLKFbeyDkxkZIANkgAyQATJABsgAGSADZIAMDBi4bHFD/haG+7cootNOkSKcv8g3N3QxIvlyKz9T6fg2CLbuE4oULG5woniUHbYjO2SADJABMkAGyAAZIANkgAycgIHLFTfiNy/KQz48oDdi9goA6VsP+Dc34jckyjcjnHbuw3/q5xb+eOg/aAd8qwLbxeP5n6XYQoT9Gxzp74DYsdGOFcdoZ6Pjin7YlpMaGSADZIAMkAEyQAbIABkgA2SADLyAgYOLG/kbCPCvmaRvYNSH9PTQnn+KAffVYoQUFfQ95Xr8Zoa+FsfAgkh8mId7SmEjPMgfUNwY2ujopGxMBYdGK+ceWyRx37O4wcnnBZOPyyLtIItkgAyQATJABsgAGSADZIAMPMDAwcWN578FYL/BEB+Qun934/nxvsUDGIsbnDwemDy+RW5QF+YGGSADZIAMkAEyQAbIABm4BAMXK27kbzTgtzD+/r2nbzDYn3ywsDH98MnixiWSdTqenHwZTzJABsgAGSADZIAMkAEyQAa+GQMXK26EgoX3sxQWNh558NU/a6k/DXqkL7ZhMY0MkAEyQAbIABkgA2SADJABMkAGXsXABYsbhOVVsHBcskcGyAAZIANkgAyQATJABsgAGSADZ2SAxY1v9lWdM0JImzg5kgEyQAbIABkgA2SADJABMkAGyMAzDLC4weIGf4tGBsgAGSADZIAMkAEyQAbIABkgA2Tg0gywuEGALw3wM5U9tmVlmAyQATJABsgAGSADZIAMkAEy8DUYYHGDxQ0WN8gAGSADZIAMkAEyQAbIABkgA2SADFyaARY3CPClAWaV9WtUWRlHxpEMkAEyQAbIABkgA2SADJCBZxhgcYPF4clDwAAAAVVJREFUDRY3yAAZIANkgAyQATJABsgAGSADZIAMXJqBzYsb//7776UFeaZSxLasNJIBMkAGyAAZIANkgAyQATJABsgAGTiWgVCHWPPfbebm//3vfyxusOJHBsgAGSADZIAMkAEyQAbIABkgA2SADBzCQKhDrPlvqrgROvzvv/8OcYDVsGOrYdSbepMBMkAGyAAZIANkgAyQATJABsjAmRgI9Ye1/00XN0LHoXLCn6gQ+jNBT1vIIxkgA2SADJABMkAGyAAZIANk4GswEOoNa7+xIUWQVcUNacRXKkAFqAAVoAJUgApQASpABagAFaACVIAKnEUBFjfOEgnaQQWoABWgAlSAClABKkAFqAAVoAJUgAo8pACLGw/JxkZUgApQASpABagAFaACVIAKUAEqQAWowFkUYHHjLJGgHVSAClABKkAFqAAVoAJUgApQASpABajAQwr8H7gsbXmE5Ry7AAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [well, sure, story, seem, biased, disagree, st...\n",
       "1    [yeah, expect, people, read, actually, accept,...\n",
       "2    [although, realize, principle, strongest, poin...\n",
       "3    [notwithstanding, legitimate, fuss, proposal, ...\n",
       "4    [well, change, scoring, playoff, pool, unfortu...\n",
       "Name: clean_doc, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_doc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(52, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 2), (67, 1), (68, 1), (69, 1), (70, 1), (71, 2), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 2), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 2), (86, 1), (87, 1), (88, 1), (89, 1)]\n"
     ]
    }
   ],
   "source": [
    "# 단어의 인덱스와 해당 문서에서 단어의 등장 횟수\n",
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(tokenized_doc)\n",
    "corpus = [dictionary.doc2bow(text) for text in tokenized_doc]\n",
    "print(corpus[1]) # 수행된 결과에서 두번째 뉴스 출력. 첫번째 문서의 인덱스는 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faith\n"
     ]
    }
   ],
   "source": [
    "print(dictionary[66])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64281"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.040*\"space\" + 0.012*\"nasa\" + 0.009*\"year\" + 0.009*\"entries\"')\n",
      "(1, '0.017*\"mail\" + 0.015*\"information\" + 0.014*\"please\" + 0.013*\"send\"')\n",
      "(2, '0.023*\"file\" + 0.015*\"program\" + 0.013*\"windows\" + 0.010*\"window\"')\n",
      "(3, '0.012*\"would\" + 0.010*\"like\" + 0.010*\"know\" + 0.008*\"thanks\"')\n",
      "(4, '0.007*\"dodgers\" + 0.007*\"decenso\" + 0.006*\"cubs\" + 0.006*\"idle\"')\n",
      "(5, '0.015*\"health\" + 0.015*\"medical\" + 0.011*\"disease\" + 0.009*\"patients\"')\n",
      "(6, '0.020*\"president\" + 0.016*\"government\" + 0.010*\"states\" + 0.009*\"american\"')\n",
      "(7, '0.018*\"data\" + 0.016*\"image\" + 0.008*\"software\" + 0.008*\"images\"')\n",
      "(8, '0.013*\"bike\" + 0.010*\"cars\" + 0.010*\"engine\" + 0.008*\"price\"')\n",
      "(9, '0.013*\"armenian\" + 0.011*\"israel\" + 0.011*\"armenians\" + 0.010*\"jews\"')\n",
      "(10, '0.054*\"drive\" + 0.034*\"disk\" + 0.033*\"scsi\" + 0.022*\"hard\"')\n",
      "(11, '0.016*\"cover\" + 0.011*\"copies\" + 0.009*\"phillies\" + 0.008*\"radius\"')\n",
      "(12, '0.023*\"church\" + 0.013*\"henrik\" + 0.013*\"militia\" + 0.012*\"right\"')\n",
      "(13, '0.025*\"encryption\" + 0.021*\"chip\" + 0.019*\"keys\" + 0.019*\"clipper\"')\n",
      "(14, '0.024*\"ground\" + 0.023*\"water\" + 0.010*\"wire\" + 0.009*\"plastic\"')\n",
      "(15, '0.022*\"game\" + 0.020*\"team\" + 0.018*\"year\" + 0.015*\"games\"')\n",
      "(16, '0.014*\"jesus\" + 0.009*\"christian\" + 0.008*\"bible\" + 0.007*\"believe\"')\n",
      "(17, '0.020*\"period\" + 0.015*\"power\" + 0.009*\"play\" + 0.008*\"scorer\"')\n",
      "(18, '0.006*\"control\" + 0.006*\"public\" + 0.005*\"guns\" + 0.005*\"number\"')\n",
      "(19, '0.018*\"would\" + 0.013*\"people\" + 0.011*\"think\" + 0.011*\"like\"')\n"
     ]
    }
   ],
   "source": [
    "# 단어의 계수는 해당 토픽에 대한 단어의 기여도를 의미\n",
    "import gensim\n",
    "NUM_TOPICS = 20 #20개의 토픽, k=20\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
    "topics = ldamodel.print_topics(num_words=4)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.040*\"space\" + 0.012*\"nasa\" + 0.009*\"year\" + 0.009*\"entries\" + 0.009*\"launch\" + 0.008*\"char\" + 0.007*\"earth\" + 0.007*\"contest\" + 0.007*\"satellite\" + 0.006*\"shuttle\"'), (1, '0.017*\"mail\" + 0.015*\"information\" + 0.014*\"please\" + 0.013*\"send\" + 0.011*\"email\" + 0.011*\"list\" + 0.008*\"address\" + 0.008*\"available\" + 0.007*\"internet\" + 0.007*\"also\"'), (2, '0.023*\"file\" + 0.015*\"program\" + 0.013*\"windows\" + 0.010*\"window\" + 0.010*\"files\" + 0.010*\"output\" + 0.009*\"entry\" + 0.008*\"version\" + 0.007*\"using\" + 0.007*\"server\"'), (3, '0.012*\"would\" + 0.010*\"like\" + 0.010*\"know\" + 0.008*\"thanks\" + 0.008*\"anyone\" + 0.007*\"need\" + 0.007*\"problem\" + 0.007*\"work\" + 0.007*\"system\" + 0.007*\"also\"'), (4, '0.007*\"dodgers\" + 0.007*\"decenso\" + 0.006*\"cubs\" + 0.006*\"idle\" + 0.005*\"giants\" + 0.005*\"darren\" + 0.005*\"mario\" + 0.005*\"main\" + 0.005*\"gift\" + 0.005*\"crashes\"'), (5, '0.015*\"health\" + 0.015*\"medical\" + 0.011*\"disease\" + 0.009*\"patients\" + 0.006*\"page\" + 0.006*\"cancer\" + 0.006*\"diseases\" + 0.006*\"medicine\" + 0.006*\"research\" + 0.005*\"treatment\"'), (6, '0.020*\"president\" + 0.016*\"government\" + 0.010*\"states\" + 0.009*\"american\" + 0.008*\"bill\" + 0.008*\"congress\" + 0.008*\"clinton\" + 0.008*\"jobs\" + 0.007*\"people\" + 0.007*\"united\"'), (7, '0.018*\"data\" + 0.016*\"image\" + 0.008*\"software\" + 0.008*\"images\" + 0.008*\"graphics\" + 0.008*\"jpeg\" + 0.008*\"available\" + 0.007*\"system\" + 0.006*\"systems\" + 0.005*\"technology\"'), (8, '0.013*\"bike\" + 0.010*\"cars\" + 0.010*\"engine\" + 0.008*\"price\" + 0.008*\"road\" + 0.007*\"miles\" + 0.006*\"front\" + 0.006*\"sell\" + 0.006*\"black\" + 0.005*\"ride\"'), (9, '0.013*\"armenian\" + 0.011*\"israel\" + 0.011*\"armenians\" + 0.010*\"jews\" + 0.009*\"turkish\" + 0.008*\"people\" + 0.007*\"israeli\" + 0.007*\"said\" + 0.006*\"killed\" + 0.006*\"turkey\"'), (10, '0.054*\"drive\" + 0.034*\"disk\" + 0.033*\"scsi\" + 0.022*\"hard\" + 0.017*\"drives\" + 0.016*\"controller\" + 0.013*\"tape\" + 0.013*\"floppy\" + 0.011*\"sale\" + 0.011*\"offer\"'), (11, '0.016*\"cover\" + 0.011*\"copies\" + 0.009*\"phillies\" + 0.008*\"radius\" + 0.007*\"appears\" + 0.007*\"pointer\" + 0.007*\"habs\" + 0.006*\"annual\" + 0.006*\"double\" + 0.006*\"print\"'), (12, '0.023*\"church\" + 0.013*\"henrik\" + 0.013*\"militia\" + 0.012*\"right\" + 0.012*\"catholic\" + 0.010*\"arms\" + 0.009*\"shall\" + 0.008*\"amendment\" + 0.007*\"bear\" + 0.007*\"state\"'), (13, '0.025*\"encryption\" + 0.021*\"chip\" + 0.019*\"keys\" + 0.019*\"clipper\" + 0.018*\"security\" + 0.016*\"privacy\" + 0.015*\"government\" + 0.011*\"algorithm\" + 0.010*\"technology\" + 0.010*\"secure\"'), (14, '0.024*\"ground\" + 0.023*\"water\" + 0.010*\"wire\" + 0.009*\"plastic\" + 0.008*\"detector\" + 0.008*\"circuits\" + 0.008*\"temperature\" + 0.008*\"heat\" + 0.007*\"outlets\" + 0.007*\"receiver\"'), (15, '0.022*\"game\" + 0.020*\"team\" + 0.018*\"year\" + 0.015*\"games\" + 0.011*\"season\" + 0.010*\"play\" + 0.010*\"players\" + 0.009*\"hockey\" + 0.009*\"league\" + 0.009*\"last\"'), (16, '0.014*\"jesus\" + 0.009*\"christian\" + 0.008*\"bible\" + 0.007*\"believe\" + 0.006*\"christians\" + 0.006*\"religion\" + 0.006*\"christ\" + 0.006*\"faith\" + 0.006*\"true\" + 0.005*\"world\"'), (17, '0.020*\"period\" + 0.015*\"power\" + 0.009*\"play\" + 0.008*\"scorer\" + 0.007*\"third\" + 0.007*\"second\" + 0.007*\"first\" + 0.007*\"smith\" + 0.006*\"jose\" + 0.006*\"braves\"'), (18, '0.006*\"control\" + 0.006*\"public\" + 0.005*\"guns\" + 0.005*\"number\" + 0.005*\"would\" + 0.004*\"police\" + 0.004*\"used\" + 0.004*\"years\" + 0.004*\"year\" + 0.004*\"many\"'), (19, '0.018*\"would\" + 0.013*\"people\" + 0.011*\"think\" + 0.011*\"like\" + 0.010*\"know\" + 0.008*\"time\" + 0.007*\"even\" + 0.007*\"well\" + 0.007*\"could\" + 0.007*\"good\"')]\n"
     ]
    }
   ],
   "source": [
    "# 디폴트 값으로 토픽별 10개의 단어들을 추출\n",
    "print(ldamodel.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번째 문서의 topic 비율은 [(4, 0.15122713), (6, 0.023365753), (9, 0.37898627), (17, 0.026436191), (19, 0.4076749)]\n",
      "1 번째 문서의 topic 비율은 [(12, 0.114032485), (14, 0.053886402), (16, 0.116750315), (19, 0.6942644)]\n",
      "2 번째 문서의 topic 비율은 [(0, 0.0728039), (9, 0.3562452), (12, 0.016716944), (19, 0.5413076)]\n",
      "3 번째 문서의 topic 비율은 [(6, 0.09057696), (10, 0.08061455), (13, 0.26794738), (16, 0.05271231), (18, 0.11237008), (19, 0.38481867)]\n",
      "4 번째 문서의 topic 비율은 [(15, 0.403233), (19, 0.5634093)]\n"
     ]
    }
   ],
   "source": [
    "# 문서별 토픽의 비중\n",
    "for i, topic_list in enumerate(ldamodel[corpus]):\n",
    "    if i==5:\n",
    "        break\n",
    "    print(i,'번째 문서의 topic 비율은',topic_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_topictable_per_doc(ldamodel, corpus):\n",
    "    topic_table = pd.DataFrame()\n",
    "\n",
    "    # 몇 번째 문서인지를 의미하는 문서 번호와 해당 문서의 토픽 비중을 한 줄씩 꺼내온다.\n",
    "    for i, topic_list in enumerate(ldamodel[corpus]):\n",
    "        doc = topic_list[0] if ldamodel.per_word_topics else topic_list            \n",
    "        doc = sorted(doc, key=lambda x: (x[1]), reverse=True)\n",
    "        # 각 문서에 대해서 비중이 높은 토픽순으로 토픽을 정렬한다.\n",
    "        # EX) 정렬 전 0번 문서 : (2번 토픽, 48.5%), (8번 토픽, 25%), (10번 토픽, 5%), (12번 토픽, 21.5%), \n",
    "        # Ex) 정렬 후 0번 문서 : (2번 토픽, 48.5%), (8번 토픽, 25%), (12번 토픽, 21.5%), (10번 토픽, 5%)\n",
    "        # 48 > 25 > 21 > 5 순으로 정렬이 된 것.\n",
    "\n",
    "        # 모든 문서에 대해서 각각 아래를 수행\n",
    "        for j, (topic_num, prop_topic) in enumerate(doc): #  몇 번 토픽인지와 비중을 나눠서 저장한다.\n",
    "            if j == 0:  # 정렬을 한 상태이므로 가장 앞에 있는 것이 가장 비중이 높은 토픽\n",
    "                topic_table = topic_table.append(pd.Series([int(topic_num), round(prop_topic,4), topic_list]), ignore_index=True)\n",
    "                # 가장 비중이 높은 토픽과, 가장 비중이 높은 토픽의 비중과, 전체 토픽의 비중을 저장한다.\n",
    "            else:\n",
    "                break\n",
    "    return(topic_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>문서 번호</th>\n",
       "      <th>가장 비중이 높은 토픽</th>\n",
       "      <th>가장 높은 토픽의 비중</th>\n",
       "      <th>각 토픽의 비중</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.4077</td>\n",
       "      <td>[(4, 0.151227), (6, 0.023365209), (9, 0.378997...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.6943</td>\n",
       "      <td>[(12, 0.1140328), (14, 0.053886406), (16, 0.11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.5413</td>\n",
       "      <td>[(0, 0.07280155), (9, 0.35624182), (12, 0.0167...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.3848</td>\n",
       "      <td>[(6, 0.090577595), (10, 0.08061661), (13, 0.26...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.5634</td>\n",
       "      <td>[(15, 0.40321198), (19, 0.56343037)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.4792</td>\n",
       "      <td>[(0, 0.18225594), (11, 0.06624235), (16, 0.237...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5870</td>\n",
       "      <td>[(2, 0.0413213), (3, 0.58702826), (5, 0.017804...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.5833</td>\n",
       "      <td>[(3, 0.17730999), (4, 0.034164593), (9, 0.1435...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>[(2, 0.2224445), (9, 0.26553372), (11, 0.03629...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4273</td>\n",
       "      <td>[(3, 0.42732573), (8, 0.15202497), (16, 0.1309...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   문서 번호  가장 비중이 높은 토픽  가장 높은 토픽의 비중  \\\n",
       "0      0          19.0        0.4077   \n",
       "1      1          19.0        0.6943   \n",
       "2      2          19.0        0.5413   \n",
       "3      3          19.0        0.3848   \n",
       "4      4          19.0        0.5634   \n",
       "5      5          19.0        0.4792   \n",
       "6      6           3.0        0.5870   \n",
       "7      7          19.0        0.5833   \n",
       "8      8          19.0        0.3771   \n",
       "9      9           3.0        0.4273   \n",
       "\n",
       "                                            각 토픽의 비중  \n",
       "0  [(4, 0.151227), (6, 0.023365209), (9, 0.378997...  \n",
       "1  [(12, 0.1140328), (14, 0.053886406), (16, 0.11...  \n",
       "2  [(0, 0.07280155), (9, 0.35624182), (12, 0.0167...  \n",
       "3  [(6, 0.090577595), (10, 0.08061661), (13, 0.26...  \n",
       "4               [(15, 0.40321198), (19, 0.56343037)]  \n",
       "5  [(0, 0.18225594), (11, 0.06624235), (16, 0.237...  \n",
       "6  [(2, 0.0413213), (3, 0.58702826), (5, 0.017804...  \n",
       "7  [(3, 0.17730999), (4, 0.034164593), (9, 0.1435...  \n",
       "8  [(2, 0.2224445), (9, 0.26553372), (11, 0.03629...  \n",
       "9  [(3, 0.42732573), (8, 0.15202497), (16, 0.1309...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topictable = make_topictable_per_doc(ldamodel, corpus)\n",
    "topictable = topictable.reset_index() # 문서 번호을 의미하는 열(column)로 사용하기 위해서 인덱스 열을 하나 더 만든다.\n",
    "topictable.columns = ['문서 번호', '가장 비중이 높은 토픽', '가장 높은 토픽의 비중', '각 토픽의 비중']\n",
    "topictable[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from lxml import etree\n",
    "import urllib.request\n",
    "import zipfile\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\"https://wit3.fbk.eu/get.php?path=XML_releases/xml/ted_en-20160408.zip&filename=ted_en-20160408.zip\", filename=\"ted_en-20160408.zip\")\n",
    "# 데이터 다운로드\n",
    "\n",
    "with zipfile.ZipFile('ted_en-20160408.zip', 'r') as z:\n",
    "  target_text = etree.parse(z.open('ted_en-20160408.xml', 'r'))\n",
    "  parse_text = '\\n'.join(target_text.xpath('//content/text()'))\n",
    "# xml 파일로부터 <content>와 </content> 사이의 내용만 가져온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here are two reasons companies fail: they only do more of the same, or they only do what's new.\\nTo me the real, real solution to quality growth is figuring out the balance between two activities: exploration and exploitation. Both are necessary, but it can be too much of a good thing.\\nConsider Facit\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_text[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_text = re.sub(r'\\([^)]*\\)', '', parse_text)\n",
    "# 정규 표현식의 sub 모듈을 통해 content 중간에 등장하는 (Audio), (Laughter) 등의 배경음 부분을 제거.\n",
    "# 해당 코드는 괄호로 구성된 내용을 제거.\n",
    "\n",
    "sent_text=sent_tokenize(content_text)\n",
    "# 입력 코퍼스에 대해서 NLTK를 이용하여 문장 토큰화를 수행.\n",
    "\n",
    "normalized_text = []\n",
    "for string in sent_text:\n",
    "     tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\n",
    "     normalized_text.append(tokens)\n",
    "# 각 문장에 대해서 구두점을 제거하고, 대문자를 소문자로 변환.\n",
    "\n",
    "result = [word_tokenize(sentence) for sentence in normalized_text]\n",
    "# 각 문장에 대해서 NLTK를 이용하여 단어 토큰화를 수행."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플의 개수 : 273424\n"
     ]
    }
   ],
   "source": [
    "print('총 샘플의 개수 : {}'.format(len(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['here', 'are', 'two', 'reasons', 'companies', 'fail', 'they', 'only', 'do', 'more', 'of', 'the', 'same', 'or', 'they', 'only', 'do', 'what', 's', 'new']\n",
      "['to', 'me', 'the', 'real', 'real', 'solution', 'to', 'quality', 'growth', 'is', 'figuring', 'out', 'the', 'balance', 'between', 'two', 'activities', 'exploration', 'and', 'exploitation']\n",
      "['both', 'are', 'necessary', 'but', 'it', 'can', 'be', 'too', 'much', 'of', 'a', 'good', 'thing']\n"
     ]
    }
   ],
   "source": [
    "for line in result[:3]: # 샘플 3개만 출력\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install gensim\n",
    "# size = 워드 벡터의 특징 값. 즉, 임베딩 된 벡터의 차원.\n",
    "# window = 컨텍스트 윈도우 크기\n",
    "# min_count = 단어 최소 빈도 수 제한 (빈도가 적은 단어들은 학습하지 않는다.)\n",
    "# workers = 학습을 위한 프로세스 수\n",
    "# sg = 0은 CBOW, 1은 Skip-gram.\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(sentences=result, size=100, window=5, min_count=5, workers=4, sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('woman', 0.8691797852516174), ('guy', 0.7960305213928223), ('lady', 0.7846928834915161), ('boy', 0.7706820964813232), ('girl', 0.7662710547447205), ('gentleman', 0.7291470766067505), ('kid', 0.7156811952590942), ('soldier', 0.7098273038864136), ('writer', 0.672561764717102), ('rabbi', 0.6657862067222595)]\n"
     ]
    }
   ],
   "source": [
    "model_result = model.wv.most_similar(\"man\")\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한국어 워드투벡\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8112052</td>\n",
       "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8132799</td>\n",
       "      <td>디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4655635</td>\n",
       "      <td>폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9251303</td>\n",
       "      <td>와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10067386</td>\n",
       "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
       "1   8132799  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n",
       "2   4655635               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n",
       "3   9251303  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n",
       "4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\", filename=\"ratings.txt\")\n",
    "train_data = pd.read_table('ratings.txt')\n",
    "train_data[:5] # 상위 5개 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data)) # 리뷰 개수 출력\n",
    "print(train_data.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "199992\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data.dropna(how = 'any') # Null 값이 존재하는 행 제거\n",
    "print(train_data.isnull().values.any()) # Null 값이 존재하는지 확인\n",
    "print(len(train_data)) # 리뷰 개수 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8112052</td>\n",
       "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8132799</td>\n",
       "      <td>디자인을 배우는 학생으로 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산업...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4655635</td>\n",
       "      <td>폴리스스토리 시리즈는 부터 뉴까지 버릴께 하나도 없음 최고</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9251303</td>\n",
       "      <td>와 연기가 진짜 개쩔구나 지루할거라고 생각했는데 몰입해서 봤다 그래 이런게 진짜 영화지</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10067386</td>\n",
       "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
       "1   8132799  디자인을 배우는 학생으로 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산업...      1\n",
       "2   4655635                   폴리스스토리 시리즈는 부터 뉴까지 버릴께 하나도 없음 최고      1\n",
       "3   9251303   와 연기가 진짜 개쩔구나 지루할거라고 생각했는데 몰입해서 봤다 그래 이런게 진짜 영화지      1\n",
       "4  10067386                         안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화      1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "train_data[:5] # 상위 5개 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소 분석기 OKT를 사용한 토큰화 작업 (다소 시간 소요)\n",
    "okt = Okt()\n",
    "tokenized_data = []\n",
    "for sentence in train_data['document']:\n",
    "    temp_X = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "    tokenized_data.append(temp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰의 최대 길이 : 72\n",
      "리뷰의 평균 길이 : 10.716703668146726\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 리뷰 길이 분포 확인\n",
    "print('리뷰의 최대 길이 :',max(len(l) for l in tokenized_data))\n",
    "print('리뷰의 평균 길이 :',sum(map(len, tokenized_data))/len(tokenized_data))\n",
    "plt.hist([len(s) for s in tokenized_data], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(sentences = tokenized_data, size = 100, window = 5, min_count = 5, workers = 4, sg = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16477, 100)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 완성된 임베딩 매트릭스의 크기 확인\n",
    "model.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('설경구', 0.870771050453186), ('공효진', 0.8618296384811401), ('최민수', 0.8569884300231934), ('한석규', 0.8557893633842468), ('이민호', 0.8502103090286255), ('채민서', 0.8406965732574463), ('류덕환', 0.8406258821487427), ('정재영', 0.8366889953613281), ('송강호', 0.8340768814086914), ('이정재', 0.8333344459533691)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(\"최민식\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('슬래셔', 0.8786855340003967), ('무협', 0.8760503530502319), ('호러', 0.8496416807174683), ('느와르', 0.8447622060775757), ('무비', 0.8412858247756958), ('정통', 0.8362785577774048), ('물의', 0.8227288722991943), ('블랙', 0.8095834851264954), ('멜로', 0.8089835047721863), ('물', 0.8056188821792603)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(\"히어로\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skip-Gram with Negative Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플 수 : 11314\n"
     ]
    }
   ],
   "source": [
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
    "documents = dataset.data\n",
    "print('총 샘플 수 :',len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.DataFrame({'document':documents})\n",
    "# 특수 문자 제거\n",
    "news_df['clean_doc'] = news_df['document'].str.replace(\"[^a-zA-Z]\", \" \")\n",
    "# 길이가 3이하인 단어는 제거 (길이가 짧은 단어 제거)\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
    "# 전체 단어에 대한 소문자 변환\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플 수 : 11314\n"
     ]
    }
   ],
   "source": [
    "news_df.dropna(inplace=True)\n",
    "print('총 샘플 수 :',len(news_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어를 제거\n",
    "stop_words = stopwords.words('english')\n",
    "tokenized_doc = news_df['clean_doc'].apply(lambda x: x.split())\n",
    "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])\n",
    "tokenized_doc = tokenized_doc.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플 수 : 10940\n"
     ]
    }
   ],
   "source": [
    "# 단어가 1개 이하인 샘플의 인덱스를 찾아서 저장하고, 해당 샘플들은 제거.\n",
    "drop_train = [index for index, sentence in enumerate(tokenized_doc) if len(sentence) <= 1]\n",
    "tokenized_doc = np.delete(tokenized_doc, drop_train, axis=0)\n",
    "print('총 샘플 수 :',len(tokenized_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(tokenized_doc)\n",
    "\n",
    "word2idx = tokenizer.word_index\n",
    "idx2word = {v:k for k, v in word2idx.items()}\n",
    "encoded = tokenizer.texts_to_sequences(tokenized_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 64277\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word2idx) + 1 \n",
    "print('단어 집합의 크기 :', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import skipgrams\n",
    "# 네거티브 샘플링\n",
    "skip_grams = [skipgrams(sample, vocabulary_size=vocab_size, window_size=10) for sample in encoded[:10]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(atrocities (4406), existance (4865)) -> 1\n",
      "(commited (7837), daily (1920)) -> 1\n",
      "(ignore (1979), subsidizing (15228)) -> 1\n",
      "(soldiers (957), aohonj (55777)) -> 0\n",
      "(sure (59), rediculous (15227)) -> 1\n"
     ]
    }
   ],
   "source": [
    "# 첫번째 샘플인 skip_grams[0] 내 skipgrams로 형성된 데이터셋 확인\n",
    "# 윈도우 크기 내에서 중심 단어, 주변 단어의 관계를 가지는 경우에는 1의 레이블을 갖도록 하고, 그렇지 않은 경우는 0의 레이블\n",
    "pairs, labels = skip_grams[0][0], skip_grams[0][1]\n",
    "for i in range(5):\n",
    "    print(\"({:s} ({:d}), {:s} ({:d})) -> {:d}\".format(\n",
    "          idx2word[pairs[i][0]], pairs[i][0], \n",
    "          idx2word[pairs[i][1]], pairs[i][1], \n",
    "          labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 10\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플 수 :',len(skip_grams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2220\n",
      "2220\n"
     ]
    }
   ],
   "source": [
    "# 첫번째 뉴스그룹 샘플에 대해서 생긴 pairs와 labels의 개수\n",
    "print(len(pairs))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding, Reshape, Activation, Input\n",
    "from tensorflow.keras.layers import Dot\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중심 단어를 위한 임베딩 테이블\n",
    "w_inputs = Input(shape=(1, ), dtype='int32')\n",
    "word_embedding = Embedding(vocab_size, embed_size)(w_inputs)\n",
    "\n",
    "# 주변 단어를 위한 임베딩 테이블\n",
    "c_inputs = Input(shape=(1, ), dtype='int32')\n",
    "context_embedding  = Embedding(vocab_size, embed_size)(c_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_product = Dot(axes=2)([word_embedding, context_embedding])\n",
    "dot_product = Reshape((1,), input_shape=(1, 1))(dot_product)\n",
    "output = Activation('sigmoid')(dot_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 100)       6427700     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 100)       6427700     input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1, 1)         0           embedding_2[0][0]                \n",
      "                                                                 embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1)            0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1)            0           reshape_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 12,855,400\n",
      "Trainable params: 12,855,400\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[w_inputs, c_inputs], outputs=output)\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_train_function.<locals>.train_function at 0x0000016D02980A68> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_train_function.<locals>.train_function at 0x0000016D02980A68> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 8 calls to <function Model.make_train_function.<locals>.train_function at 0x0000016D02980A68> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:8 out of the last 9 calls to <function Model.make_train_function.<locals>.train_function at 0x0000016D02980A68> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:9 out of the last 10 calls to <function Model.make_train_function.<locals>.train_function at 0x0000016D02980A68> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "Epoch : 1 Loss : 6.931243658065796\n",
      "Epoch : 2 Loss : 6.906789422035217\n",
      "Epoch : 3 Loss : 6.881309747695923\n",
      "Epoch : 4 Loss : 6.850980281829834\n",
      "Epoch : 5 Loss : 6.813310325145721\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 6):\n",
    "    loss = 0\n",
    "    for _, elem in enumerate(skip_grams):\n",
    "        first_elem = np.array(list(zip(*elem[0]))[0], dtype='int32')\n",
    "        second_elem = np.array(list(zip(*elem[0]))[1], dtype='int32')\n",
    "        labels = np.array(elem[1], dtype='int32')\n",
    "        X = [first_elem, second_elem]\n",
    "        Y = labels\n",
    "        loss += model.train_on_batch(X,Y)  \n",
    "    print('Epoch :',epoch, 'Loss :',loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('vectors.txt' ,'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-1, embed_size))\n",
    "vectors = model.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write('{} {}\\n'.format(word, ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = gensim.models.KeyedVectors.load_word2vec_format('./vectors.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ugvug', 0.4456321597099304),\n",
       " ('periphery', 0.43874552845954895),\n",
       " ('vjpwuo', 0.42627042531967163),\n",
       " ('exiled', 0.4121643602848053),\n",
       " ('rainouts', 0.38186800479888916),\n",
       " ('andrus', 0.38043490052223206),\n",
       " ('veins', 0.3791557550430298),\n",
       " ('gliding', 0.3790082335472107),\n",
       " ('borealous', 0.37637829780578613),\n",
       " ('mypeu', 0.37071192264556885)]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.most_similar(positive=['soldiers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('predicatbaly', 0.40517616271972656),\n",
       " ('azjjp', 0.38339585065841675),\n",
       " ('someonepost', 0.37462979555130005),\n",
       " ('integers', 0.3693121075630188),\n",
       " ('mcilvaine', 0.35764047503471375),\n",
       " ('kirnkh', 0.3530123233795166),\n",
       " ('adherents', 0.3482312560081482),\n",
       " ('unscathed', 0.3480411171913147),\n",
       " ('compounded', 0.3469890356063843),\n",
       " ('kalpa', 0.3459509313106537)]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.most_similar(positive=['doctor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('opportunity', 0.39234161376953125),\n",
       " ('mclean', 0.3864136040210724),\n",
       " ('others', 0.3811820447444916),\n",
       " ('vagarshakovich', 0.3790912628173828),\n",
       " ('katzke', 0.3775111138820648),\n",
       " ('cowgirls', 0.37122857570648193),\n",
       " ('medics', 0.3593009114265442),\n",
       " ('xtpeekevent', 0.35763442516326904),\n",
       " ('tmhx', 0.3555253744125366),\n",
       " ('organized', 0.35362446308135986)]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.most_similar(positive=['police'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install glove_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glove import Corpus, Glove\n",
    "\n",
    "corpus = Corpus() \n",
    "corpus.fit(result, window=5)\n",
    "# 훈련 데이터로부터 GloVe에서 사용할 동시 등장 행렬 생성\n",
    "\n",
    "glove = Glove(no_components=100, learning_rate=0.05)\n",
    "glove.fit(corpus.matrix, epochs=20, no_threads=4, verbose=True)\n",
    "glove.add_dictionary(corpus.dictionary)\n",
    "# 학습에 이용할 쓰레드의 개수는 4로 설정, 에포크는 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result1=glove.most_similar(\"man\")\n",
    "print(model_result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result2=glove.most_similar(\"boy\")\n",
    "print(model_result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result6=glove.most_similar(\"muscle\")\n",
    "print(model_result6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
