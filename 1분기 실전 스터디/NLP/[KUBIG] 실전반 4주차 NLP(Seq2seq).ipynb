{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Review\n",
    "이 코드는 https://wikidocs.net/21667 사이트의 코드를 가져와 리뷰한 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib3\n",
    "import zipfile\n",
    "import shutil\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "http = urllib3.PoolManager()\n",
    "url ='http://www.manythings.org/anki/fra-eng.zip'\n",
    "filename = 'fra-eng.zip'\n",
    "path = os.getcwd()\n",
    "zipfilename = os.path.join(path, filename)\n",
    "with http.request('GET', url, preload_content=False) as r, open(zipfilename, 'wb') as out_file:       \n",
    "    shutil.copyfileobj(r, out_file)\n",
    "\n",
    "with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
    "    zip_ref.extractall(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178009"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines= pd.read_csv('fra.txt', names=['src', 'tar'], sep='\\t')\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I'm sorry.</th>\n",
       "      <td>Excusez-moi.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I'm full.</th>\n",
       "      <td>Je suis rassasié !</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>It's work.</th>\n",
       "      <td>C'est du boulot.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I'll live.</th>\n",
       "      <td>Je vivrai.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Who's he?</th>\n",
       "      <td>Qui est-il ?</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Let me go.</th>\n",
       "      <td>Laisse-moi m'en aller !</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Get lost!</th>\n",
       "      <td>Va au diable !</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I've lost.</th>\n",
       "      <td>J'ai perdu.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I saw you.</th>\n",
       "      <td>Je te vis.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Am I late?</th>\n",
       "      <td>Suis-je en retard ?</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                src  \\\n",
       "I'm sorry.             Excusez-moi.   \n",
       "I'm full.        Je suis rassasié !   \n",
       "It's work.         C'est du boulot.   \n",
       "I'll live.               Je vivrai.   \n",
       "Who's he?              Qui est-il ?   \n",
       "Let me go.  Laisse-moi m'en aller !   \n",
       "Get lost!            Va au diable !   \n",
       "I've lost.              J'ai perdu.   \n",
       "I saw you.               Je te vis.   \n",
       "Am I late?      Suis-je en retard ?   \n",
       "\n",
       "                                                          tar  \n",
       "I'm sorry.  CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
       "I'm full.   CC-BY 2.0 (France) Attribution: tatoeba.org #4...  \n",
       "It's work.  CC-BY 2.0 (France) Attribution: tatoeba.org #4...  \n",
       "I'll live.  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "Who's he?   CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "Let me go.  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "Get lost!   CC-BY 2.0 (France) Attribution: tatoeba.org #6...  \n",
       "I've lost.  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "I saw you.  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "Am I late?  CC-BY 2.0 (France) Attribution: tatoeba.org #3...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines.loc[:, 'src':'tar']\n",
    "lines = lines[0:1000] # 6만개만 저장\n",
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.tar=lines.src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Go away.</th>\n",
       "      <td>Go away.</td>\n",
       "      <td>Pars !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No way!</th>\n",
       "      <td>No way!</td>\n",
       "      <td>En aucune manière !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Can we go?</th>\n",
       "      <td>Can we go?</td>\n",
       "      <td>Pouvons-nous partir ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Of course!</th>\n",
       "      <td>Of course!</td>\n",
       "      <td>Pour sûr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>May I go?</th>\n",
       "      <td>May I go?</td>\n",
       "      <td>Puis-je partir ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Move over.</th>\n",
       "      <td>Move over.</td>\n",
       "      <td>Poussez-vous.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I've won.</th>\n",
       "      <td>I've won.</td>\n",
       "      <td>J'ai gagné.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I was new.</th>\n",
       "      <td>I was new.</td>\n",
       "      <td>J'étais nouveau.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Welcome.</th>\n",
       "      <td>Welcome.</td>\n",
       "      <td>Bienvenue !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Get out.</th>\n",
       "      <td>Get out.</td>\n",
       "      <td>Sors.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   src                    tar\n",
       "Go away.      Go away.                 Pars !\n",
       "No way!        No way!    En aucune manière !\n",
       "Can we go?  Can we go?  Pouvons-nous partir ?\n",
       "Of course!  Of course!              Pour sûr.\n",
       "May I go?    May I go?       Puis-je partir ?\n",
       "Move over.  Move over.          Poussez-vous.\n",
       "I've won.    I've won.            J'ai gagné.\n",
       "I was new.  I was new.       J'étais nouveau.\n",
       "Welcome.      Welcome.            Bienvenue !\n",
       "Get out.      Get out.                  Sors."
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.src=lines.index\n",
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I hurried.</th>\n",
       "      <td>I hurried.</td>\n",
       "      <td>\\t Je me suis dépêchée. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I'm cold.</th>\n",
       "      <td>I'm cold.</td>\n",
       "      <td>\\t J'ai froid. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Take mine.</th>\n",
       "      <td>Take mine.</td>\n",
       "      <td>\\t Prends la mienne. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I retired.</th>\n",
       "      <td>I retired.</td>\n",
       "      <td>\\t J'ai pris ma retraite. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I try.</th>\n",
       "      <td>I try.</td>\n",
       "      <td>\\t J'essaye. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Call Tom.</th>\n",
       "      <td>Call Tom.</td>\n",
       "      <td>\\t Appelez Tom. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hi.</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>\\t Salut. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>He's mine.</th>\n",
       "      <td>He's mine.</td>\n",
       "      <td>\\t Il est à moi. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>She's hot.</th>\n",
       "      <td>She's hot.</td>\n",
       "      <td>\\t Elle est très attirante. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Get a job.</th>\n",
       "      <td>Get a job.</td>\n",
       "      <td>\\t Trouve un emploi ! \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   src                             tar\n",
       "I hurried.  I hurried.      \\t Je me suis dépêchée. \\n\n",
       "I'm cold.    I'm cold.               \\t J'ai froid. \\n\n",
       "Take mine.  Take mine.         \\t Prends la mienne. \\n\n",
       "I retired.  I retired.    \\t J'ai pris ma retraite. \\n\n",
       "I try.          I try.                 \\t J'essaye. \\n\n",
       "Call Tom.    Call Tom.              \\t Appelez Tom. \\n\n",
       "Hi.                Hi.                    \\t Salut. \\n\n",
       "He's mine.  He's mine.             \\t Il est à moi. \\n\n",
       "She's hot.  She's hot.  \\t Elle est très attirante. \\n\n",
       "Get a job.  Get a job.        \\t Trouve un emploi ! \\n"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.tar = lines.tar.apply(lambda x : '\\t '+ x + ' \\n')\n",
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Go.</th>\n",
       "      <td>Go.</td>\n",
       "      <td>\\t Va ! \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hi.</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>\\t Salut ! \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hi.</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>\\t Salut. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run!</th>\n",
       "      <td>Run!</td>\n",
       "      <td>\\t Cours ! \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run!</th>\n",
       "      <td>Run!</td>\n",
       "      <td>\\t Courez ! \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       src             tar\n",
       "Go.    Go.      \\t Va ! \\n\n",
       "Hi.    Hi.   \\t Salut ! \\n\n",
       "Hi.    Hi.    \\t Salut. \\n\n",
       "Run!  Run!   \\t Cours ! \\n\n",
       "Run!  Run!  \\t Courez ! \\n"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 글자 집합 구축\n",
    "src_vocab=set()\n",
    "for line in lines.src: # 1줄씩 읽음\n",
    "    for char in line: # 1개의 글자씩 읽음\n",
    "        src_vocab.add(char)\n",
    "\n",
    "tar_vocab=set()\n",
    "for line in lines.tar:\n",
    "    for char in line:\n",
    "        tar_vocab.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "78\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size = len(src_vocab)+1\n",
    "tar_vocab_size = len(tar_vocab)+1\n",
    "print(src_vocab_size)\n",
    "print(tar_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "['j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'x', 'y', 'z', '\\xa0', 'À', 'Ç', 'É', 'à', 'â', 'ç', 'è', 'é', 'ê', 'î', 'ô', 'û', '\\u2009']\n"
     ]
    }
   ],
   "source": [
    "src_vocab = sorted(list(src_vocab))\n",
    "tar_vocab = sorted(list(tar_vocab))\n",
    "print(src_vocab[45:75])\n",
    "print(tar_vocab[45:75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 1, '!': 2, '$': 3, \"'\": 4, ',': 5, '.': 6, '0': 7, '1': 8, '3': 9, '5': 10, '8': 11, '9': 12, ':': 13, '?': 14, 'A': 15, 'B': 16, 'C': 17, 'D': 18, 'E': 19, 'F': 20, 'G': 21, 'H': 22, 'I': 23, 'J': 24, 'K': 25, 'L': 26, 'M': 27, 'N': 28, 'O': 29, 'P': 30, 'R': 31, 'S': 32, 'T': 33, 'U': 34, 'V': 35, 'W': 36, 'Y': 37, 'a': 38, 'b': 39, 'c': 40, 'd': 41, 'e': 42, 'f': 43, 'g': 44, 'h': 45, 'i': 46, 'j': 47, 'k': 48, 'l': 49, 'm': 50, 'n': 51, 'o': 52, 'p': 53, 'q': 54, 'r': 55, 's': 56, 't': 57, 'u': 58, 'v': 59, 'w': 60, 'x': 61, 'y': 62, 'z': 63}\n",
      "{'\\t': 1, '\\n': 2, ' ': 3, '!': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '0': 9, '1': 10, '3': 11, '8': 12, '9': 13, '?': 14, 'A': 15, 'B': 16, 'C': 17, 'D': 18, 'E': 19, 'F': 20, 'G': 21, 'H': 22, 'I': 23, 'J': 24, 'K': 25, 'L': 26, 'M': 27, 'N': 28, 'O': 29, 'P': 30, 'Q': 31, 'R': 32, 'S': 33, 'T': 34, 'U': 35, 'V': 36, 'a': 37, 'b': 38, 'c': 39, 'd': 40, 'e': 41, 'f': 42, 'g': 43, 'h': 44, 'i': 45, 'j': 46, 'k': 47, 'l': 48, 'm': 49, 'n': 50, 'o': 51, 'p': 52, 'q': 53, 'r': 54, 's': 55, 't': 56, 'u': 57, 'v': 58, 'x': 59, 'y': 60, 'z': 61, '\\xa0': 62, 'À': 63, 'Ç': 64, 'É': 65, 'à': 66, 'â': 67, 'ç': 68, 'è': 69, 'é': 70, 'ê': 71, 'î': 72, 'ô': 73, 'û': 74, '\\u2009': 75, '’': 76, '\\u202f': 77}\n"
     ]
    }
   ],
   "source": [
    "src_to_index = dict([(word, i+1) for i, word in enumerate(src_vocab)])\n",
    "tar_to_index = dict([(word, i+1) for i, word in enumerate(tar_vocab)])\n",
    "print(src_to_index)\n",
    "print(tar_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_to_index['\\t']=tar_to_index[' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tar_to_index[' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21, 52, 6], [22, 46, 6], [22, 46, 6], [31, 58, 51, 2], [31, 58, 51, 2]]\n"
     ]
    }
   ],
   "source": [
    "encoder_input = []\n",
    "for line in lines.src: #입력 데이터에서 1줄씩 문장을 읽음\n",
    "    temp_X = []\n",
    "    for w in line: #각 줄에서 1개씩 글자를 읽음\n",
    "      temp_X.append(src_to_index[w]) # 글자를 해당되는 정수로 변환\n",
    "    encoder_input.append(temp_X)\n",
    "print(encoder_input[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 36, 37, 3, 4, 3, 2], [1, 3, 33, 37, 48, 57, 56, 3, 4, 3, 2], [1, 3, 33, 37, 48, 57, 56, 8, 3, 2], [1, 3, 17, 51, 57, 54, 55, 77, 4, 3, 2], [1, 3, 17, 51, 57, 54, 41, 61, 77, 4, 3, 2]]\n"
     ]
    }
   ],
   "source": [
    "decoder_input = []\n",
    "for line in lines.tar:\n",
    "    temp_X = []\n",
    "    for w in line:\n",
    "      temp_X.append(tar_to_index[w])\n",
    "    decoder_input.append(temp_X)\n",
    "print(decoder_input[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 36, 37, 3, 4, 3, 2], [3, 33, 37, 48, 57, 56, 3, 4, 3, 2], [3, 33, 37, 48, 57, 56, 8, 3, 2], [3, 17, 51, 57, 54, 55, 77, 4, 3, 2], [3, 17, 51, 57, 54, 41, 61, 77, 4, 3, 2]]\n"
     ]
    }
   ],
   "source": [
    "decoder_target = []\n",
    "for line in lines.tar:\n",
    "    t=0\n",
    "    temp_X = []\n",
    "    for w in line:\n",
    "      if t>0:\n",
    "        temp_X.append(tar_to_index[w])\n",
    "      t=t+1\n",
    "    decoder_target.append(temp_X)\n",
    "print(decoder_target[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "max_src_len = max([len(line) for line in lines.src])\n",
    "max_tar_len = max([len(line) for line in lines.tar])\n",
    "print(max_src_len)\n",
    "print(max_tar_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = pad_sequences(encoder_input, maxlen=max_src_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen=max_tar_len, padding='post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen=max_tar_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = to_categorical(encoder_input)\n",
    "decoder_input = to_categorical(decoder_input)\n",
    "decoder_target = to_categorical(decoder_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(len(encoder_input[0]))\n",
    "print(encoder_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None, src_vocab_size))\n",
    "encoder_lstm = LSTM(units=256, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "# encoder_outputs도 같이 리턴받기는 했지만 여기서는 필요없으므로 이 값은 버림.\n",
    "encoder_states = [state_h, state_c]\n",
    "# LSTM은 바닐라 RNN과는 달리 상태가 두 개. 바로 은닉 상태와 셀 상태."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, tar_vocab_size))\n",
    "decoder_lstm = LSTM(units=256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _= decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "# 디코더의 첫 상태를 인코더의 은닉 상태, 셀 상태로 합니다.\n",
    "decoder_softmax_layer = Dense(tar_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 28s 36ms/sample - loss: 2.4131 - val_loss: 1.9179\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 7s 9ms/sample - loss: 1.6487 - val_loss: 1.9536\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 1.5201 - val_loss: 1.7782\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 1.4645 - val_loss: 1.8822\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 4s 5ms/sample - loss: 1.4514 - val_loss: 1.5768\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 5s 7ms/sample - loss: 1.3886 - val_loss: 1.5211\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 1.3514 - val_loss: 1.4909\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 5s 7ms/sample - loss: 1.3345 - val_loss: 1.4547\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 4s 5ms/sample - loss: 1.2827 - val_loss: 1.4384\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 1.2510 - val_loss: 1.4020\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 1.2038 - val_loss: 1.3899\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 4s 5ms/sample - loss: 1.1846 - val_loss: 1.3364\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 4s 6ms/sample - loss: 1.1296 - val_loss: 1.2946\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 1.1058 - val_loss: 1.2686\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 4s 5ms/sample - loss: 1.0503 - val_loss: 1.2785\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 4s 5ms/sample - loss: 1.0238 - val_loss: 1.2916\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 4s 5ms/sample - loss: 0.9842 - val_loss: 1.2058\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 4s 5ms/sample - loss: 0.9576 - val_loss: 1.1909\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.9298 - val_loss: 1.1557\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 4s 5ms/sample - loss: 0.9028 - val_loss: 1.1203\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 4s 5ms/sample - loss: 0.8766 - val_loss: 1.1244\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 4s 5ms/sample - loss: 0.8509 - val_loss: 1.1243\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 4s 5ms/sample - loss: 0.8340 - val_loss: 1.1333\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 4s 5ms/sample - loss: 0.8153 - val_loss: 1.0816\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 4s 5ms/sample - loss: 0.7985 - val_loss: 1.0648\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.7775 - val_loss: 1.0456\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 4s 6ms/sample - loss: 0.7634 - val_loss: 1.0257\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.7465 - val_loss: 1.0294\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.7295 - val_loss: 1.0456\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.7151 - val_loss: 1.0314\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 4s 6ms/sample - loss: 0.7009 - val_loss: 1.0042\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 4s 6ms/sample - loss: 0.6822 - val_loss: 0.9976\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.6701 - val_loss: 0.9754\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.6535 - val_loss: 1.0160\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 4s 6ms/sample - loss: 0.6427 - val_loss: 0.9877\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 4s 5ms/sample - loss: 0.6269 - val_loss: 0.9707\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 4s 5ms/sample - loss: 0.6120 - val_loss: 1.0035\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 4s 5ms/sample - loss: 0.6071 - val_loss: 1.0085\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 4s 5ms/sample - loss: 0.5842 - val_loss: 1.0046\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 4s 5ms/sample - loss: 0.5755 - val_loss: 0.9907\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.5662 - val_loss: 1.0102\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 6s 7ms/sample - loss: 0.5525 - val_loss: 0.9755\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 6s 7ms/sample - loss: 0.5370 - val_loss: 1.0083\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 5s 7ms/sample - loss: 0.5238 - val_loss: 0.9724\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 4s 5ms/sample - loss: 0.5146 - val_loss: 0.9814\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 4s 5ms/sample - loss: 0.5002 - val_loss: 1.0328\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 4s 5ms/sample - loss: 0.4934 - val_loss: 1.0014\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 4s 5ms/sample - loss: 0.4754 - val_loss: 0.9922\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 5s 7ms/sample - loss: 0.4616 - val_loss: 1.0250\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.4561 - val_loss: 1.0116\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xd6f0dfeb38>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[encoder_input, decoder_input], y=decoder_target, batch_size=64, epochs=50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "decoder_states = [state_h, state_c]\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_src = dict((i, char) for char, i in src_to_index.items())\n",
    "index_to_tar = dict((i, char) for char, i in tar_to_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # <SOS>에 해당하는 원-핫 벡터 생성\n",
    "    target_seq = np.zeros((1, 1, tar_vocab_size))\n",
    "    target_seq[0, 0, tar_to_index['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 문자로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = index_to_tar[sampled_token_index]\n",
    "\n",
    "        # 현재 시점의 예측 문자를 예측 문장에 추가\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_tar_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "        target_seq = np.zeros((1, 1, tar_vocab_size))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
