{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥드림\n",
    "\n",
    "CNN이 학습한 표현을 사용하여 예술적으로 이미지를 조작하는 기법\n",
    "\n",
    "컨브넷을 거꾸로 실행하는 컨브넷 필터 시각화 기법과 동일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inception_v3 모델을 사용\n",
    "\n",
    "from tensorflow.keras.applications import inception_v3\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow as tf\n",
    "K.set_learning_phase(0) #이 명령은 모든 훈련 연산을 비활성화합니다.\n",
    "\n",
    "model = inception_v3.InceptionV3(weights='imagenet', include_top=False) #conv_base층만 사용한 인셉션 V3 네트워크를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, None, None, 3 864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, None, None, 3 96          conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, None, None, 3 0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, None, None, 3 9216        activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, None, None, 3 96          conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, None, None, 3 0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, None, None, 6 18432       activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, None, None, 6 192         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, None, None, 6 0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, None, None, 6 0           activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, None, None, 8 5120        max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, None, None, 8 240         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, None, None, 8 0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, None, None, 1 138240      activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, None, None, 1 576         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, None, None, 1 0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, None, None, 1 0           activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, None, None, 6 12288       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, None, None, 6 192         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, None, None, 6 0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, None, None, 4 9216        max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, None, None, 9 55296       activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, None, None, 4 144         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, None, None, 9 288         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, None, None, 4 0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, None, None, 9 0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePo (None, None, None, 1 0           max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, None, None, 6 12288       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, None, None, 6 76800       activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, None, None, 9 82944       activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, None, None, 3 6144        average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, None, None, 6 192         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, None, None, 6 192         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, None, None, 9 288         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, None, None, 3 96          conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, None, None, 6 0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, None, None, 6 0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, None, None, 9 0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, None, None, 3 0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, None, None, 2 0           activation_193[0][0]             \n",
      "                                                                 activation_195[0][0]             \n",
      "                                                                 activation_198[0][0]             \n",
      "                                                                 activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, None, None, 6 192         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, None, None, 6 0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, None, None, 4 12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, None, None, 9 55296       activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, None, None, 4 144         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, None, None, 9 288         conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, None, None, 4 0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, None, None, 9 0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_19 (AveragePo (None, None, None, 2 0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, None, None, 6 76800       activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, None, None, 9 82944       activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, None, None, 6 16384       average_pooling2d_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, None, None, 6 192         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, None, None, 6 192         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, None, None, 9 288         conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, None, None, 6 192         conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, None, None, 6 0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, None, None, 6 0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, None, None, 9 0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, None, None, 6 0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, None, None, 2 0           activation_200[0][0]             \n",
      "                                                                 activation_202[0][0]             \n",
      "                                                                 activation_205[0][0]             \n",
      "                                                                 activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, None, None, 6 192         conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, None, None, 6 0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, None, None, 4 13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, None, None, 9 55296       activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, None, None, 4 144         conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, None, None, 9 288         conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, None, None, 4 0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, None, None, 9 0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_20 (AveragePo (None, None, None, 2 0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, None, None, 6 76800       activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, None, None, 9 82944       activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, None, None, 6 18432       average_pooling2d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, None, None, 6 192         conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, None, None, 6 192         conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, None, None, 9 288         conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, None, None, 6 192         conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, None, None, 6 0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, None, None, 6 0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, None, None, 9 0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, None, None, 6 0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, None, None, 2 0           activation_207[0][0]             \n",
      "                                                                 activation_209[0][0]             \n",
      "                                                                 activation_212[0][0]             \n",
      "                                                                 activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, None, None, 6 18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, None, None, 6 192         conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, None, None, 6 0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, None, None, 9 55296       activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, None, None, 9 288         conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, None, None, 9 0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, None, None, 3 995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, None, None, 9 82944       activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, None, None, 3 1152        conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, None, None, 9 288         conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, None, None, 3 0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, None, None, 9 0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, None, None, 2 0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, None, None, 7 0           activation_214[0][0]             \n",
      "                                                                 activation_217[0][0]             \n",
      "                                                                 max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, None, None, 1 384         conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, None, None, 1 0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, None, None, 1 114688      activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, None, None, 1 384         conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, None, None, 1 0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, None, None, 1 114688      activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, None, None, 1 384         conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, None, None, 1 384         conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, None, None, 1 0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, None, None, 1 0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, None, None, 1 114688      activation_219[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, None, None, 1 114688      activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, None, None, 1 384         conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, None, None, 1 384         conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, None, None, 1 0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, None, None, 1 0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_21 (AveragePo (None, None, None, 7 0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, None, None, 1 147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, None, None, 1 172032      activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, None, None, 1 172032      activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_21[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, None, None, 1 576         conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, None, None, 1 576         conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, None, None, 1 576         conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, None, None, 1 576         conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, None, None, 1 0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, None, None, 1 0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, None, None, 1 0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, None, None, 1 0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, None, None, 7 0           activation_218[0][0]             \n",
      "                                                                 activation_221[0][0]             \n",
      "                                                                 activation_226[0][0]             \n",
      "                                                                 activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, None, None, 1 480         conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, None, None, 1 0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, None, None, 1 179200      activation_232[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, None, None, 1 480         conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, None, None, 1 0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, None, None, 1 179200      activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, None, None, 1 480         conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, None, None, 1 480         conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, None, None, 1 0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, None, None, 1 0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, None, None, 1 179200      activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, None, None, 1 179200      activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, None, None, 1 480         conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, None, None, 1 480         conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, None, None, 1 0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, None, None, 1 0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_22 (AveragePo (None, None, None, 7 0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, None, None, 1 147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, None, None, 1 215040      activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, None, None, 1 215040      activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, None, None, 1 576         conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, None, None, 1 576         conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, None, None, 1 576         conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, None, None, 1 576         conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, None, None, 1 0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, None, None, 1 0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, None, None, 1 0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, None, None, 1 0           batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, None, None, 7 0           activation_228[0][0]             \n",
      "                                                                 activation_231[0][0]             \n",
      "                                                                 activation_236[0][0]             \n",
      "                                                                 activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, None, None, 1 480         conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, None, None, 1 0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, None, None, 1 179200      activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, None, None, 1 480         conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, None, None, 1 0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, None, None, 1 179200      activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, None, None, 1 480         conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, None, None, 1 480         conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, None, None, 1 0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, None, None, 1 0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, None, None, 1 179200      activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, None, None, 1 179200      activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, None, None, 1 480         conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, None, None, 1 480         conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, None, None, 1 0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, None, None, 1 0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_23 (AveragePo (None, None, None, 7 0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, None, None, 1 147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, None, None, 1 215040      activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, None, None, 1 215040      activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_23[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, None, None, 1 576         conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, None, None, 1 576         conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, None, None, 1 576         conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, None, None, 1 576         conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, None, None, 1 0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, None, None, 1 0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, None, None, 1 0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, None, None, 1 0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, None, None, 7 0           activation_238[0][0]             \n",
      "                                                                 activation_241[0][0]             \n",
      "                                                                 activation_246[0][0]             \n",
      "                                                                 activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, None, None, 1 576         conv2d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, None, None, 1 0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, None, None, 1 258048      activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, None, None, 1 576         conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, None, None, 1 0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, None, None, 1 258048      activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, None, None, 1 576         conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, None, None, 1 576         conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, None, None, 1 0           batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, None, None, 1 0           batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, None, None, 1 258048      activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, None, None, 1 258048      activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, None, None, 1 576         conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, None, None, 1 576         conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, None, None, 1 0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, None, None, 1 0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_24 (AveragePo (None, None, None, 7 0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, None, None, 1 258048      activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, None, None, 1 258048      activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, None, None, 1 576         conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, None, None, 1 576         conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, None, None, 1 576         conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, None, None, 1 576         conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, None, None, 1 0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, None, None, 1 0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, None, None, 1 0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, None, None, 1 0           batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, None, None, 7 0           activation_248[0][0]             \n",
      "                                                                 activation_251[0][0]             \n",
      "                                                                 activation_256[0][0]             \n",
      "                                                                 activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_260 (Conv2D)             (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_260 (BatchN (None, None, None, 1 576         conv2d_260[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, None, None, 1 0           batch_normalization_260[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_261 (Conv2D)             (None, None, None, 1 258048      activation_260[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_261 (BatchN (None, None, None, 1 576         conv2d_261[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, None, None, 1 0           batch_normalization_261[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_258 (Conv2D)             (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_262 (Conv2D)             (None, None, None, 1 258048      activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_258 (BatchN (None, None, None, 1 576         conv2d_258[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_262 (BatchN (None, None, None, 1 576         conv2d_262[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, None, None, 1 0           batch_normalization_258[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, None, None, 1 0           batch_normalization_262[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_259 (Conv2D)             (None, None, None, 3 552960      activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_263 (Conv2D)             (None, None, None, 1 331776      activation_262[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_259 (BatchN (None, None, None, 3 960         conv2d_259[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_263 (BatchN (None, None, None, 1 576         conv2d_263[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, None, None, 3 0           batch_normalization_259[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, None, None, 1 0           batch_normalization_263[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, None, None, 7 0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, None, None, 1 0           activation_259[0][0]             \n",
      "                                                                 activation_263[0][0]             \n",
      "                                                                 max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_268 (Conv2D)             (None, None, None, 4 573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_268 (BatchN (None, None, None, 4 1344        conv2d_268[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_268 (Activation)     (None, None, None, 4 0           batch_normalization_268[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_265 (Conv2D)             (None, None, None, 3 491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_269 (Conv2D)             (None, None, None, 3 1548288     activation_268[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_265 (BatchN (None, None, None, 3 1152        conv2d_265[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_269 (BatchN (None, None, None, 3 1152        conv2d_269[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_265 (Activation)     (None, None, None, 3 0           batch_normalization_265[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_269 (Activation)     (None, None, None, 3 0           batch_normalization_269[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_266 (Conv2D)             (None, None, None, 3 442368      activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_267 (Conv2D)             (None, None, None, 3 442368      activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_270 (Conv2D)             (None, None, None, 3 442368      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_271 (Conv2D)             (None, None, None, 3 442368      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_25 (AveragePo (None, None, None, 1 0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_264 (Conv2D)             (None, None, None, 3 409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_266 (BatchN (None, None, None, 3 1152        conv2d_266[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_267 (BatchN (None, None, None, 3 1152        conv2d_267[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_270 (BatchN (None, None, None, 3 1152        conv2d_270[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_271 (BatchN (None, None, None, 3 1152        conv2d_271[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_272 (Conv2D)             (None, None, None, 1 245760      average_pooling2d_25[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_264 (BatchN (None, None, None, 3 960         conv2d_264[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_266 (Activation)     (None, None, None, 3 0           batch_normalization_266[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_267 (Activation)     (None, None, None, 3 0           batch_normalization_267[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_270 (Activation)     (None, None, None, 3 0           batch_normalization_270[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_271 (Activation)     (None, None, None, 3 0           batch_normalization_271[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_272 (BatchN (None, None, None, 1 576         conv2d_272[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, None, None, 3 0           batch_normalization_264[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, None, None, 7 0           activation_266[0][0]             \n",
      "                                                                 activation_267[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, None, None, 7 0           activation_270[0][0]             \n",
      "                                                                 activation_271[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_272 (Activation)     (None, None, None, 1 0           batch_normalization_272[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, None, None, 2 0           activation_264[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_4[0][0]              \n",
      "                                                                 activation_272[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_277 (Conv2D)             (None, None, None, 4 917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_277 (BatchN (None, None, None, 4 1344        conv2d_277[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, None, None, 4 0           batch_normalization_277[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_274 (Conv2D)             (None, None, None, 3 786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_278 (Conv2D)             (None, None, None, 3 1548288     activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_274 (BatchN (None, None, None, 3 1152        conv2d_274[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_278 (BatchN (None, None, None, 3 1152        conv2d_278[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_274 (Activation)     (None, None, None, 3 0           batch_normalization_274[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, None, None, 3 0           batch_normalization_278[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_275 (Conv2D)             (None, None, None, 3 442368      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_276 (Conv2D)             (None, None, None, 3 442368      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_279 (Conv2D)             (None, None, None, 3 442368      activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_280 (Conv2D)             (None, None, None, 3 442368      activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_26 (AveragePo (None, None, None, 2 0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_273 (Conv2D)             (None, None, None, 3 655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_275 (BatchN (None, None, None, 3 1152        conv2d_275[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_276 (BatchN (None, None, None, 3 1152        conv2d_276[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_279 (BatchN (None, None, None, 3 1152        conv2d_279[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_280 (BatchN (None, None, None, 3 1152        conv2d_280[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_281 (Conv2D)             (None, None, None, 1 393216      average_pooling2d_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_273 (BatchN (None, None, None, 3 960         conv2d_273[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, None, None, 3 0           batch_normalization_275[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_276 (Activation)     (None, None, None, 3 0           batch_normalization_276[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, None, None, 3 0           batch_normalization_279[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, None, None, 3 0           batch_normalization_280[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_281 (BatchN (None, None, None, 1 576         conv2d_281[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_273 (Activation)     (None, None, None, 3 0           batch_normalization_273[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, None, None, 7 0           activation_275[0][0]             \n",
      "                                                                 activation_276[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, None, None, 7 0           activation_279[0][0]             \n",
      "                                                                 activation_280[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, None, None, 1 0           batch_normalization_281[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, None, None, 2 0           activation_273[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_5[0][0]              \n",
      "                                                                 activation_281[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_contributions = {\n",
    "    'mixed2':0.2,\n",
    "    'mixed3':3.,\n",
    "    'mixed4':2.,\n",
    "    'mixed5':1.5,\n",
    "} #층 이름과 계수를 맵핑한 딕셔너리입니다. 최대화하려는 손실에 층의 활성화가 기여할 양을 정합니다. 층 이름은 인셉션V3에 하드코딩되어 있는 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그 다음은 손실을 계산 - 경사상승법으로 최대화할 값\n",
    "\n",
    "손실 텐서를 정의합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "\n",
    "loss = K.variable(0.) #손실을 정의하고, 각 층의 기여 분을 이 스칼라 변수에 추가할 것입니다.\n",
    "\n",
    "for layer_name in layer_contributions:\n",
    "    coeff = layer_contributions[layer_name]\n",
    "    activation = layer_dict[layer_name].output\n",
    "    \n",
    "    scaling = K.prod(K.cast(K.shape(activation), 'float32'))\n",
    "    loss = loss + (coeff * K.sum(K.square(activation[:, 2:-2, 2:-2, :]))/scaling) # 층 특성의 L2 norm을 loss에 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#경사 상승법 사용\n",
    "\n",
    "dream = model.input # 이 텐서는 생성된 딥드림 이미지를 저장\n",
    "\n",
    "grads = K.gradients(loss, dream)[0] #loss에 대한 딥드림의 그래디언트를 계산\n",
    "\n",
    "grads /= K.maximum(K.mean(K.abs(grads)), 1e-7) #그래디언트를 정규화\n",
    "\n",
    "outputs = [loss, grads]\n",
    "fetch_loss_and_grads = K.function([dream], outputs) #주어진 input 이미지에서 loss와 gradient를 계산할 케라스 function객체를 만듭니다.\n",
    "\n",
    "def eval_loss_and_grads(x):\n",
    "    outs = fetch_loss_and_grads([x])\n",
    "    loss_value = outs[0]\n",
    "    grad_values = outs[1]\n",
    "    return loss_value, grad_values\n",
    "\n",
    "def gradient_ascent(x, iterations, steps, max_loss=None):\n",
    "    for i in range(iterations):\n",
    "        loss_value, grad_values = eval_loss_and_grads(x)\n",
    "        if max_loss is not None and loss_value > max_loss:\n",
    "            break\n",
    "        print('...',i,'번째 손실: ', loss_value)\n",
    "        x += step * grad_values\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_img(img, size):\n",
    "    img = np.copy(img)\n",
    "    factors = (1, float(size[0])/img.shape[1], float(size[1])/img.shape[2],1)\n",
    "    return scipy.ndimage.zoom(img, factors, order=1)\n",
    "\n",
    "def save_img(img, fname):\n",
    "    pil_img = deprocess_image(np.copy(img))\n",
    "    image.save_img(fname, pil_img)\n",
    "    \n",
    "def preprocess_image(image_path):\n",
    "    img = image.load_img(image_path)\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = inception_v3.preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "def deprocess_image(x):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.reshape((3, x.shape[2], x.shape[3]))\n",
    "        x = x.transpose((1,2,0))\n",
    "    else:\n",
    "        x = x.reshape((x.shape[1], x.shape[2], 3))\n",
    "    x /= 2.\n",
    "    x += 0.5\n",
    "    x *= 255.\n",
    "    x = np.clip(x, 0, 255)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지를 처리하기 위한 스케일(옥타브) 리스트를 정의합니다.\n",
    "\n",
    "스케일은 이전 스케일보다 104배 커지게, 작은 이미지로 시작해서 점점 크기를 키웁니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "step = 0.01\n",
    "num_octave = 3\n",
    "octave_scale = 1.4\n",
    "iterations = 20\n",
    "\n",
    "max_loss = 10.\n",
    "\n",
    "base_image_path = './train/dog.12499.jpg'\n",
    "\n",
    "img = preprocess_image(base_image_path)\n",
    "\n",
    "original_shape = img.shape[1:3]\n",
    "successive_shapes = [original_shape]\n",
    "for i in range(1, num_octave):\n",
    "    shape = tuple([int(dim / (octave_scale ** i)) for dim in original_shape])\n",
    "    successive_shapes.append(shape)\n",
    "    \n",
    "successive_shapes = successive_shapes[::-1]\n",
    "\n",
    "original_img = np.copy(img)\n",
    "shrunk_original_img = resize_img(img, successive_shapes[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처리할 이미지 크기 (204, 153)\n",
      "... 0 번째 손실:  1.5846369\n",
      "... 1 번째 손실:  2.1007843\n",
      "... 2 번째 손실:  2.862856\n",
      "... 3 번째 손실:  3.476365\n",
      "... 4 번째 손실:  4.070114\n",
      "... 5 번째 손실:  4.440911\n",
      "... 6 번째 손실:  5.021138\n",
      "... 7 번째 손실:  5.6168666\n",
      "... 8 번째 손실:  6.1207914\n",
      "... 9 번째 손실:  6.6547823\n",
      "... 10 번째 손실:  7.102113\n",
      "... 11 번째 손실:  7.5338445\n",
      "... 12 번째 손실:  7.940491\n",
      "... 13 번째 손실:  8.503634\n",
      "... 14 번째 손실:  8.946257\n",
      "... 15 번째 손실:  9.330797\n",
      "... 16 번째 손실:  9.810503\n",
      "처리할 이미지 크기 (285, 214)\n",
      "... 0 번째 손실:  2.6667328\n",
      "... 1 번째 손실:  3.9742994\n",
      "... 2 번째 손실:  5.007021\n",
      "... 3 번째 손실:  5.9207215\n",
      "... 4 번째 손실:  6.750062\n",
      "... 5 번째 손실:  7.4744854\n",
      "... 6 번째 손실:  8.184249\n",
      "... 7 번째 손실:  8.875222\n",
      "... 8 번째 손실:  9.503553\n",
      "처리할 이미지 크기 (400, 300)\n",
      "... 0 번째 손실:  2.8255305\n",
      "... 1 번째 손실:  3.9660401\n",
      "... 2 번째 손실:  5.14983\n",
      "... 3 번째 손실:  6.1900244\n",
      "... 4 번째 손실:  7.2778306\n",
      "... 5 번째 손실:  8.242529\n",
      "... 6 번째 손실:  9.531812\n"
     ]
    }
   ],
   "source": [
    "for shape in successive_shapes:\n",
    "    print('처리할 이미지 크기', shape)\n",
    "    img  = resize_img(img, shape)\n",
    "    \n",
    "    img = gradient_ascent(img, iterations=iterations, steps = step,  max_loss=max_loss)\n",
    "    \n",
    "    upscaled_shrunk_original_img = resize_img(shrunk_original_img, shape)\n",
    "    same_size_original = resize_img(original_img, shape)\n",
    "    lost_detail = same_size_original - upscaled_shrunk_original_img\n",
    "    img += lost_detail\n",
    "    shrunk_original_img = resize_img(original_img, shape)\n",
    "    save_img(img, fname='dream_at_scale_' + str(shape) + '.png')\n",
    "    \n",
    "save_img(img, fname='./train/dog.12499.deepdream.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 뉴럴 스타일 트랜스퍼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 스타일 참조 이미지, 타깃 이미지, 생성된 이미지를 위해 VGG19의 층 활성화를 동시에 계산하는 네트워크를 설정합니다.\n",
    "\n",
    "\n",
    "\n",
    "2. 세 이미지에서 계산한 층 활성화를 사용하여 앞서 설명한 손실 함수를 정의합니다. 이 손실을 최소화하여 스타일 트랜스퍼를 구현할 것입니다.\n",
    "\n",
    "\n",
    "3. 손실 함수를 최소화할 경사 하강법 과정을 설정합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Neural_Style_Transfer](캡처.JPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모두 높이가 400픽셀이 되도록 크기를 변경\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, save_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_image_path = './style_transfer/target.jpg'\n",
    "style_reference_image_path = './style_transfer/style2.jpg'\n",
    "\n",
    "width, height = load_img(target_image_path).size\n",
    "img_height = 400\n",
    "img_width = int(width * img_height / height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications import vgg19\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(img_height, img_width))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = vgg19.preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "def deprocess_image(x):\n",
    "    x[:, :, 0] += 103.939\n",
    "    x[:, :, 1] += 116.779\n",
    "    x[:, :, 2] += 123.68\n",
    "    x = x[:, :, ::-1]\n",
    "    x = np.clip(x,0,255).astype('uint8')\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 로드 완료\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "target_image = K.constant(preprocess_image(target_image_path))\n",
    "style_reference_image = K.constant(preprocess_image(style_reference_image_path))\n",
    "combination_image = K.placeholder((1, img_height, img_width, 3)) # 생성된 이미지를 담은 place holder\n",
    "\n",
    "input_tensor = K.concatenate([target_image, style_reference_image, combination_image], axis=0) # 세개의 이미지를 하나의 배치로 합칩니다.\n",
    "\n",
    "model = vgg19.VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
    "#세 이미지의 배치를 입력으로 받는 VGG네트워크를 만듭니다. 이 모델은 사전 훈련된 ImageNet 가중치를 로드합니다.\n",
    "\n",
    "print('모델 로드 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_loss(base, combination):\n",
    "    return K.sum(K.square(combination - base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    features = K.batch_flatten(K.permute_dimensions(x, (2,0,1)))\n",
    "    gram = K.dot(features, K.transpose(features))\n",
    "    return gram\n",
    "\n",
    "def style_loss(style, combination):\n",
    "    S = gram_matrix(style)\n",
    "    C = gram_matrix(combination)\n",
    "    channels = 3\n",
    "    size = img_height * img_width\n",
    "    return K.sum(K.square(S - C)) / (4. * (channels ** 2) * (size ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_variation_loss(x):\n",
    "    a = K.square( x[:, :img_height - 1, :img_width -1, :] - x[:, 1:, :img_width -1, :])\n",
    "    b = K.square( x[:, :img_height - 1, :img_width -1, :] - x[:, :img_height -1, 1:,:])\n",
    "    return K.sum(K.pow(a+b, 1.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(3, 400, 533, 3)]        0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (3, 400, 533, 64)         1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (3, 400, 533, 64)         36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (3, 200, 266, 64)         0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (3, 200, 266, 128)        73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (3, 200, 266, 128)        147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (3, 100, 133, 128)        0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (3, 100, 133, 256)        295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (3, 100, 133, 256)        590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (3, 100, 133, 256)        590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (3, 100, 133, 256)        590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (3, 50, 66, 256)          0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (3, 50, 66, 512)          1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (3, 50, 66, 512)          2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (3, 50, 66, 512)          2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (3, 50, 66, 512)          2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (3, 25, 33, 512)          0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (3, 25, 33, 512)          2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (3, 25, 33, 512)          2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (3, 25, 33, 512)          2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (3, 25, 33, 512)          2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (3, 12, 16, 512)          0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_dict = dict([(layer.name, layer.output) for layer in model.layers]) # 층 이름과 활성화할 텐서를 매핑할 딕셔너리\n",
    "\n",
    "content_layer = 'block5_conv2'\n",
    "style_layers = ['block1_conv1','block2_conv1','block3_conv1','block4_conv1','block5_conv1']\n",
    "\n",
    "total_variation_weight = 1e-4\n",
    "style_weight = 1.\n",
    "content_weight = 0.025\n",
    "\n",
    "\n",
    "loss = K.variable(0.)\n",
    "layer_features = outputs_dict[content_layer]\n",
    "target_image_features = layer_features[0,:,:,:]\n",
    "combination_features = layer_features[2,:,:,:]\n",
    "loss = loss + content_weight * content_loss(target_image_features, combination_features)\n",
    "\n",
    "for layer_name in style_layers:\n",
    "    layer_features = outputs_dict[layer_name]\n",
    "    style_reference_features = layer_features[1, :,:,:]\n",
    "    combination_features = layer_features[2,:,:,:]\n",
    "    sl = style_loss(style_reference_features, combination_features)\n",
    "    loss += (style_weight / len(style_layers)) * sl\n",
    "    \n",
    "loss += total_variation_weight * total_variation_loss(combination_image)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "import tensorflow as tf\n",
    "graph = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = K.gradients(loss, combination_image)[0]\n",
    "output=[loss,grads]\n",
    "fetch_loss_and_grads = K.function([combination_image], output)\n",
    "\n",
    "class Evaluator(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.loss_value = None\n",
    "        self.grads_values = None\n",
    "        \n",
    "    def loss(self, x):\n",
    "        assert self.loss_value is None\n",
    "        x = x.reshape((1, img_height, img_width, 3))\n",
    "        outs = fetch_loss_and_grads([x])\n",
    "        loss_value = outs[0]\n",
    "        grad_values = outs[1].flatten().astype('float64')\n",
    "        self.loss_value = loss_value\n",
    "        self.grad_values = grad_values\n",
    "        return self.loss_value\n",
    "    \n",
    "    def grads(self, x):\n",
    "        assert self.loss_value is not None\n",
    "        grad_values = np.copy(self.grad_values)\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "        return grad_values\n",
    "    \n",
    "evaluator = Evaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_prefix = 'style_transfer_result'\n",
    "iterations = 20\n",
    "\n",
    "x = preprocess_image(target_image_path)\n",
    "x = x.flatten()\n",
    "for i in range(iterations):\n",
    "    print('반복 횟수:',i)\n",
    "    start_time = time.time()\n",
    "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x, fprime=evaluator.grads, maxfun=20)\n",
    "    \n",
    "    print('현재 손실 값:', min_val)\n",
    "    img = x.copy().reshape((img_height, img_width, 3))\n",
    "    img = deprocess_image(img)\n",
    "    fname = result_prefix + '_at_iterations_%d.png' % i\n",
    "    save_img(fname, img)\n",
    "    print('저장 이미지:', fname)\n",
    "    end_time = time.time()\n",
    "    print('%d 번째 반복 완료: %ds' % (i, end_time - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
